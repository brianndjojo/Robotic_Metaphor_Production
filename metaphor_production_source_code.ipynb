{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c56895f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n",
      "Requirement already satisfied: torch==1.10.1+cu113 in d:\\anaconda3\\lib\\site-packages (1.10.1+cu113)\n",
      "Requirement already satisfied: torchvision==0.11.2+cu113 in d:\\anaconda3\\lib\\site-packages (0.11.2+cu113)\n",
      "Requirement already satisfied: torchaudio===0.10.1+cu113 in d:\\anaconda3\\lib\\site-packages (0.10.1+cu113)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda3\\lib\\site-packages (from torch==1.10.1+cu113) (3.10.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in d:\\anaconda3\\lib\\site-packages (from torchvision==0.11.2+cu113) (8.4.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (from torchvision==0.11.2+cu113) (1.20.3)\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch\n",
    "!pip install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862ccfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\anaconda3\\lib\\site-packages (4.15.0)\n",
      "Requirement already satisfied: requests in d:\\anaconda3\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: pandas in d:\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (1.20.3)\n",
      "Requirement already satisfied: filelock in d:\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: sacremoses in d:\\anaconda3\\lib\\site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in d:\\anaconda3\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in d:\\anaconda3\\lib\\site-packages (from transformers) (0.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda3\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests) (3.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.2.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: joblib in d:\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in d:\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (8.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers requests beautifulsoup4 pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c5ee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysimplegui in d:\\anaconda3\\lib\\site-packages (4.56.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pysimplegui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bce74180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in d:\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in d:\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "# NLTK: Natural Language Toolkit used for Natural Language Processing\n",
    "# https://studymachinelearning.com/an-introduction-to-n-grams/\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6ac4668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version\n",
      "---------------------------------- --------------------\n",
      "absl-py                            0.12.0\n",
      "aiohttp                            3.8.1\n",
      "aiosignal                          1.2.0\n",
      "alabaster                          0.7.12\n",
      "anaconda-client                    1.9.0\n",
      "anaconda-navigator                 2.1.1\n",
      "anaconda-project                   0.10.1\n",
      "anyio                              2.2.0\n",
      "appdirs                            1.4.4\n",
      "argh                               0.26.2\n",
      "argon2-cffi                        20.1.0\n",
      "arrow                              0.13.1\n",
      "asn1crypto                         1.4.0\n",
      "astroid                            2.6.6\n",
      "astropy                            4.3.1\n",
      "astunparse                         1.6.3\n",
      "async-generator                    1.10\n",
      "async-timeout                      4.0.2\n",
      "atomicwrites                       1.4.0\n",
      "attrs                              21.2.0\n",
      "autopep8                           1.5.7\n",
      "Babel                              2.9.1\n",
      "backcall                           0.2.0\n",
      "backports.functools-lru-cache      1.6.4\n",
      "backports.shutil-get-terminal-size 1.0.0\n",
      "backports.tempfile                 1.0\n",
      "backports.weakref                  1.0.post1\n",
      "bcrypt                             3.2.0\n",
      "beautifulsoup4                     4.10.0\n",
      "binaryornot                        0.4.4\n",
      "bitarray                           2.3.0\n",
      "bkcharts                           0.2\n",
      "black                              19.10b0\n",
      "bleach                             4.0.0\n",
      "bokeh                              2.4.1\n",
      "boto                               2.49.0\n",
      "Bottleneck                         1.3.2\n",
      "brotlipy                           0.7.0\n",
      "cached-property                    1.5.2\n",
      "cachetools                         4.2.4\n",
      "certifi                            2021.10.8\n",
      "cffi                               1.14.6\n",
      "chardet                            4.0.0\n",
      "charset-normalizer                 2.0.4\n",
      "click                              8.0.3\n",
      "cloudpickle                        2.0.0\n",
      "clyent                             1.2.2\n",
      "colorama                           0.4.4\n",
      "comtypes                           1.1.10\n",
      "conda                              4.10.3\n",
      "conda-build                        3.21.6\n",
      "conda-content-trust                0+unknown\n",
      "conda-pack                         0.6.0\n",
      "conda-package-handling             1.7.3\n",
      "conda-repo-cli                     1.0.4\n",
      "conda-token                        0.3.0\n",
      "conda-verify                       3.4.2\n",
      "contextlib2                        0.6.0.post1\n",
      "cookiecutter                       1.7.2\n",
      "cryptography                       3.4.8\n",
      "cycler                             0.10.0\n",
      "Cython                             0.29.24\n",
      "cytoolz                            0.11.0\n",
      "daal4py                            2021.3.0\n",
      "dask                               2021.10.0\n",
      "datasets                           2.0.0\n",
      "debugpy                            1.4.1\n",
      "decorator                          5.1.0\n",
      "defusedxml                         0.7.1\n",
      "diff-match-patch                   20200713\n",
      "dill                               0.3.4\n",
      "distributed                        2021.10.0\n",
      "docutils                           0.17.1\n",
      "entrypoints                        0.3\n",
      "et-xmlfile                         1.1.0\n",
      "fastcache                          1.1.0\n",
      "filelock                           3.3.1\n",
      "flake8                             3.9.2\n",
      "Flask                              1.1.2\n",
      "flatbuffers                        2.0\n",
      "fonttools                          4.25.0\n",
      "frozenlist                         1.3.0\n",
      "fsspec                             2021.10.1\n",
      "future                             0.18.2\n",
      "gast                               0.4.0\n",
      "gevent                             21.8.0\n",
      "glob2                              0.7\n",
      "google-auth                        2.3.3\n",
      "google-auth-oauthlib               0.4.6\n",
      "google-pasta                       0.2.0\n",
      "googleapis-common-protos           1.54.0\n",
      "greenlet                           1.1.1\n",
      "grpcio                             1.43.0\n",
      "h11                                0.13.0\n",
      "h5py                               3.2.1\n",
      "HeapDict                           1.0.1\n",
      "html5lib                           1.1\n",
      "huggingface-hub                    0.2.1\n",
      "idna                               3.2\n",
      "imagecodecs                        2021.8.26\n",
      "imageio                            2.9.0\n",
      "imagesize                          1.2.0\n",
      "importlib-metadata                 4.8.1\n",
      "inflection                         0.5.1\n",
      "iniconfig                          1.1.1\n",
      "intervaltree                       3.1.0\n",
      "ipykernel                          6.4.1\n",
      "ipython                            7.29.0\n",
      "ipython-genutils                   0.2.0\n",
      "ipywidgets                         7.6.5\n",
      "isort                              5.9.3\n",
      "itsdangerous                       2.0.1\n",
      "jdcal                              1.4.1\n",
      "jedi                               0.18.0\n",
      "Jinja2                             2.11.3\n",
      "jinja2-time                        0.2.0\n",
      "joblib                             1.1.0\n",
      "json5                              0.9.6\n",
      "jsonschema                         3.2.0\n",
      "jupyter                            1.0.0\n",
      "jupyter-client                     6.1.12\n",
      "jupyter-console                    6.4.0\n",
      "jupyter-core                       4.8.1\n",
      "jupyter-server                     1.4.1\n",
      "jupyterlab                         3.2.1\n",
      "jupyterlab-pygments                0.1.2\n",
      "jupyterlab-server                  2.8.2\n",
      "jupyterlab-widgets                 1.0.0\n",
      "keras                              2.7.0\n",
      "Keras-Preprocessing                1.1.2\n",
      "keyring                            23.1.0\n",
      "kiwisolver                         1.3.1\n",
      "lazy-object-proxy                  1.6.0\n",
      "libarchive-c                       2.9\n",
      "libclang                           12.0.0\n",
      "llvmlite                           0.37.0\n",
      "locket                             0.2.1\n",
      "lxml                               4.6.3\n",
      "Markdown                           3.3.6\n",
      "MarkupSafe                         1.1.1\n",
      "matplotlib                         3.4.3\n",
      "matplotlib-inline                  0.1.2\n",
      "mccabe                             0.6.1\n",
      "menuinst                           1.4.18\n",
      "mistune                            0.8.4\n",
      "mkl-fft                            1.3.1\n",
      "mkl-random                         1.2.2\n",
      "mkl-service                        2.4.0\n",
      "mock                               4.0.3\n",
      "more-itertools                     8.10.0\n",
      "mpmath                             1.2.1\n",
      "msgpack                            1.0.2\n",
      "multidict                          6.0.2\n",
      "multipledispatch                   0.6.0\n",
      "multiprocess                       0.70.12.2\n",
      "munkres                            1.1.4\n",
      "mypy-extensions                    0.4.3\n",
      "navigator-updater                  0.2.1\n",
      "nbclassic                          0.2.6\n",
      "nbclient                           0.5.3\n",
      "nbconvert                          6.1.0\n",
      "nbformat                           5.1.3\n",
      "nest-asyncio                       1.5.1\n",
      "networkx                           2.6.3\n",
      "nltk                               3.6.5\n",
      "nose                               1.3.7\n",
      "notebook                           6.4.5\n",
      "numba                              0.54.1\n",
      "numexpr                            2.7.3\n",
      "numpy                              1.20.3\n",
      "numpydoc                           1.1.0\n",
      "oauthlib                           3.1.1\n",
      "olefile                            0.46\n",
      "openpyxl                           3.0.9\n",
      "opt-einsum                         3.3.0\n",
      "outcome                            1.1.0\n",
      "packaging                          21.0\n",
      "pandas                             1.3.4\n",
      "pandocfilters                      1.4.3\n",
      "paramiko                           2.7.2\n",
      "parso                              0.8.2\n",
      "partd                              1.2.0\n",
      "path                               16.0.0\n",
      "pathlib2                           2.3.6\n",
      "pathspec                           0.7.0\n",
      "patsy                              0.5.2\n",
      "pep8                               1.7.1\n",
      "pexpect                            4.8.0\n",
      "pickleshare                        0.7.5\n",
      "Pillow                             8.4.0\n",
      "pip                                21.2.4\n",
      "pkginfo                            1.7.1\n",
      "pluggy                             0.13.1\n",
      "ply                                3.11\n",
      "poyo                               0.5.0\n",
      "prometheus-client                  0.11.0\n",
      "promise                            2.3\n",
      "prompt-toolkit                     3.0.20\n",
      "protobuf                           3.19.1\n",
      "psutil                             5.8.0\n",
      "ptyprocess                         0.7.0\n",
      "py                                 1.10.0\n",
      "pyarrow                            7.0.0\n",
      "pyasn1                             0.4.8\n",
      "pyasn1-modules                     0.2.8\n",
      "pycodestyle                        2.7.0\n",
      "pycosat                            0.6.3\n",
      "pycparser                          2.20\n",
      "pycurl                             7.44.1\n",
      "pydocstyle                         6.1.1\n",
      "pyerfa                             2.0.0\n",
      "pyflakes                           2.3.1\n",
      "Pygments                           2.10.0\n",
      "PyJWT                              2.1.0\n",
      "pylint                             2.9.6\n",
      "pyls-spyder                        0.4.0\n",
      "pymongo                            4.0.1\n",
      "PyNaCl                             1.4.0\n",
      "pyodbc                             4.0.0-unsupported\n",
      "pyOpenSSL                          21.0.0\n",
      "pyparsing                          3.0.4\n",
      "pyreadline                         2.1\n",
      "pyrsistent                         0.18.0\n",
      "PySimpleGUI                        4.56.0\n",
      "PySocks                            1.7.1\n",
      "pytest                             6.2.4\n",
      "python-dateutil                    2.8.2\n",
      "python-lsp-black                   1.0.0\n",
      "python-lsp-jsonrpc                 1.0.0\n",
      "python-lsp-server                  1.2.4\n",
      "python-slugify                     5.0.2\n",
      "pytz                               2021.3\n",
      "PyWavelets                         1.1.1\n",
      "pywin32                            228\n",
      "pywin32-ctypes                     0.2.0\n",
      "pywinpty                           0.5.7\n",
      "PyYAML                             6.0\n",
      "pyzmq                              22.2.1\n",
      "QDarkStyle                         3.0.2\n",
      "qstylizer                          0.1.10\n",
      "QtAwesome                          1.0.2\n",
      "qtconsole                          5.1.1\n",
      "QtPy                               1.10.0\n",
      "regex                              2021.8.3\n",
      "requests                           2.26.0\n",
      "requests-oauthlib                  1.3.0\n",
      "responses                          0.18.0\n",
      "rope                               0.19.0\n",
      "rsa                                4.8\n",
      "Rtree                              0.9.7\n",
      "ruamel-yaml-conda                  0.15.100\n",
      "sacremoses                         0.0.46\n",
      "scikit-image                       0.18.3\n",
      "scikit-learn                       0.24.2\n",
      "scikit-learn-intelex               2021.20210714.120553\n",
      "scipy                              1.7.1\n",
      "seaborn                            0.11.2\n",
      "selenium                           4.1.0\n",
      "Send2Trash                         1.8.0\n",
      "setuptools                         58.0.4\n",
      "simplegeneric                      0.8.1\n",
      "singledispatch                     3.7.0\n",
      "sip                                4.19.13\n",
      "six                                1.16.0"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500e0631",
   "metadata": {},
   "source": [
    "# Assumptions Made"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39992201",
   "metadata": {},
   "source": [
    "## Theory for Determing Metaphor\n",
    "\n",
    "**Metahpors** \n",
    "\n",
    "- can be used to open up meanings that would otherwise go unnoticed. \n",
    "\n",
    "- can be used to describe first-time observations in terms familiar to the observer. By linking up with known concepts, the new entity can be better understood.\n",
    "\n",
    "-  First time encounter of a new phenomenon often stimulates metaphor-production.\n",
    "\n",
    "## Assumptions made\n",
    "\n",
    "- According to Dr Johan, sufficient if the exemplars/words evoke a number of features which are related to a degree.\n",
    "\n",
    "- The said features can have a wide description. In this paper, **the features will be a simple attribute.** The features of this paper will be retrieved from both a semantic network for experimental purposes.\n",
    "\n",
    "- However, for Proof Of Concept to show how the code will work as intended, this paper will also use pre-defined features retrieved from human assumptions.\n",
    "\n",
    "## Types of Features\n",
    "\n",
    "- **Literal Feature:** plainly descirbes an **aspect of the entity that the word refers to.** (e.g a feautre of a man is his nose.) **Feature is taken literally** in the eye of the observer.\n",
    "\n",
    "- **Figurative Feature:** refers to **something else than the plain description of things as they supposedly are.** Figurative Features are connected to almost any concept or word, whether they are part of a metaphoric construction or not. **Figurative in the sense is anything that is not a literal description** of the entity the word refers to. (e.g 'Rose' not only activates 'flower' but also 'passion'.)\n",
    "\n",
    "## Three Main Arguments\n",
    "\n",
    "- **Metaphor**: Metaphors state that **A** is **B** or **Noun1 is Noun2** under the condition that **nouns are out-of-category.\n",
    "    - Out-Of-Category, Large Intersection.\n",
    "\n",
    "- **Literal-Statements**: Statement is in Category.\n",
    "    - In-category, Large Intersection.\n",
    "    \n",
    "- **Anomalies**: Statement is out-of-category but also nonseniscal.\n",
    "    - Out of Category, Small Intersection\n",
    "\n",
    "## How to Identify a Metaphor\n",
    "\n",
    "- **Restriction & Assumption**: \n",
    "    - Metaphor will be treated as **Noun1 is Noun2** (According to Johan, more complex metaphors are built from such basic comparisons)\n",
    "    - Whether comparisons are treated as literal, metaphoric or amaomalous, number of literal & figurative features are activated when people encounter a noun-noun construction.\n",
    "    \n",
    "- **Literal Context**: Figurative Features suppressed more compared to Literal Features. **Figuaritive Context** is the opposite.\n",
    "\n",
    "- **Seen as a race between Literal & Figurative information sources** but **division in a literal and figurative set for each word is not unchallenged.**\n",
    "\n",
    "- Metaphor will take into account all possible combinations between the undifferentiated features of Noun1 & Noun2:\n",
    "    \n",
    "    -**Noun1 literal - Noun2 literal**\n",
    "    \n",
    "    -**Noun1 Figurative - Noun2 Figurative**\n",
    "    \n",
    "    -**Noun1 Literal - Noun2 Figurative**\n",
    "    \n",
    "    -**Noun1 Figurative - Noun2 Literal**\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7371500c",
   "metadata": {},
   "source": [
    "# Experiment 1: Robotic Metaphor Production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1fa024",
   "metadata": {},
   "source": [
    "# Take User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5b2089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaphor Threshold:0.2\n",
      "Literal Threshold:0.9\n"
     ]
    }
   ],
   "source": [
    "class Error(Exception):\n",
    "    \"\"\"Base class for other exceptions\"\"\"\n",
    "    pass\n",
    "\n",
    "class MetaphorOutofRange(Error):\n",
    "    \"\"\"Raised when the Metaphor Threshold is not between 0 or 1\"\"\"\n",
    "    pass\n",
    "\n",
    "class LiteralOutofRange(Error):\n",
    "    \"\"\"Raised when the Literal Threshold is not between 0 or 1 or is less than the Metaphor Threshold\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "# Metaphor Threshold\n",
    "while True:\n",
    "    try:\n",
    "        metaphor_threshold = float(input(\"Metaphor Threshold:\"))\n",
    "        \n",
    "        if(metaphor_threshold < 0.0 or metaphor_threshold > 1.0):\n",
    "            raise MetaphorOutofRange\n",
    "        break\n",
    "        \n",
    "    except MetaphorOutofRange:\n",
    "        print('\\nThreshold needs to be between 0 or 1 to determine whether it is a metaphor.')\n",
    "        \n",
    "\n",
    "# Literal Threshold\n",
    "while True:\n",
    "    try:\n",
    "        literal_threshold = float(input(\"Literal Threshold:\"))\n",
    "        \n",
    "        if(literal_threshold < 0.0 or literal_threshold > 1.0 or literal_threshold < metaphor_threshold):\n",
    "            raise LiteralOutofRange\n",
    "        break\n",
    "        \n",
    "    except LiteralOutofRange:\n",
    "        print('\\nThreshold needs to be between 0 or 1 to & must be greater than the Metaphor_Threshold.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb48cafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@time [catg] ', 'clock l +clock-dial l +clock-hands l ', 'duration l ', 'fast l +quick l ', 'slow l +tardy l ', 'past l +history l ', 'future l ', 'now l ', 'century l +decade l +year l +month l +week l +day l +hour l +minute l +second l ', 'era l +epoch l ', 'long-due l', 'of-yore l ', 'eternity f ', 'wings f +fly f ', '# ', '@state-of-being [catg] ', 'life l +live l +alive l +living l ', 'full-of-energy l + vivacity f ', 'creature l ', 'existence l +survive l +be l +being l ', 'ill l ', 'decay l ', 'lifeless l ', 'not-alive l ', 'die l +dead l +death l +deceased l +departed l ', 'lifecycle f ', 'eternity f ', '# ', '@plant [catg] ', 'flower l ', 'leafs l ', 'stem l ', 'petals l ', 'thorns l ', 'fruit l ', 'water l ', 'photosynthesis l ', 'forest l ', 'trees l ', 'soil l ', 'natural-life f ', '# ', '@emotion [catg] ', 'love l ', 'anger l ', 'rage l ', 'joy l ', 'sad l ', 'kind l ', 'engaged l ', 'cheerful l ', 'happy l ', 'scared l ', 'fulfilled l +satisfied l ', 'unkind l ', 'rage l ', 'fury l ', 'unhappy l ', 'dissatisfied l ', 'heart f ', '# ', '@animal [catg] ', 'mammal l +land l +lactation l ', 'bird l +air l +wings l +eggs l +hollow-bones l ', 'insect l +air l +wings l +exoskeleton l ', 'fish l +water l +gills l +scales l ', 'reptile l +land l +eggs l ', 'amphibious l +water l +land l ambiguous f ', 'eyes l ', 'ears l ', 'legs l ', 'nose l ', 'tail l ', 'metabolism l ', 'ferocious f ', '# ', '@body [catg] ', 'physique l ', 'intestines l ', 'eyes l ', 'ears l ', 'arms l +hands l ', 'legs l ', 'nose l ', 'mouth l ', 'metabolism l ', 'muscles l ', 'hair l ', 'head l ', 'heart l ', 'lungs l ', 'spleen l ', 'kidneys l ', 'skin l ', 'sinful f ', '@ ', '@monkey [exm>animal] ', 'mammal l ', 'eyes l ', 'ears l ', 'legs l ', 'nose l ', 'tree l +climbing l ', 'long-tail l ', 'metabolism l ', 'fool f ', '# ', '@heart [exm>body] ', 'red l +color l +warmth f ', 'body l ', 'love f +red f +warmth f ', 'blood l +blood-red l +passionate f +warmth f ', 'bosom friend f ', 'heart-shape f +fruit heart l +food l +sweet-taste l +sweetheart f +kind l +valentine l ', 'spear l +stab l +pain l +death l ', 'sword l +stab l +pain l +death l ', 'fight l +pain l +death l ', 'war l +pain l +death l ', \"cow's-heart l +food l +dog l \", '# ', '@love [exm>emotion] ', 'emotion l ', 'kind l ', 'engaged l ', 'cheerful l ', 'beautiful f ', 'happy l ', 'fulfilled l +satisfied l ', 'warmth f ', 'red l +color l +warmth f ', 'lover l +body l ', 'spiritual l soul-mates f ', 'cupid f ', 'marriage l ', 'divorce l mental-pain f ', 'separation l mental-pain f ', 'thorn-in-my-side f ', '# ', '@rose [exm>plant] ', 'plant l ', 'flower l ', 'leaf l ', 'stem l ', 'petal l ', 'beautiful l ', 'thorn l +body-pain l ', 'water l +thirst f ', 'red l +color l +warmth f ', 'pink l +color l +innocent f ', 'white l +color l +pure f ', 'gift l +lover l +love f +emotion l +kind l ', '# ', '@lily [exm>plant] ', 'plant l ', 'flower l ', 'leaf l ', 'stem l ', 'petal l ', 'beautiful l ', 'white l +color l +pure f +virginity f +immaculate f +serene f ', 'name l +girl l ', 'gift l +lover l +love f +emotion l +kind l +funeral l +grave l +death f ', '# ', '@death [exm>state-of-being] ', 'not alive l ', 'deceased l ', 'grim-reaper f ', 'illness l +decay f +black f ', 'accident l ', 'fight l +war l ', 'silent l +still l +pure f +serene f ', 'white-face l +pale l +no-blood l ', 'buried l +funeral l ', '# ', '@mouth [exm>body] ', 'lips l ', 'red l +color l +warmth f ', 'smile l +kind l +warmth f ', 'lipstick l +red l +color l +beautiful l +artificial f ', 'eat l +food l ', 'teeth l ', 'tongue l +lick l +taste l +bitter l +sweet l ', 'kiss l +greeting l +kind l +friend f +lips-emoji f ', 'love f +body l ', 'speak l +whisper l +kind l +love-talk f +secret f ', 'shout l +scream l +anger f +painful f ', '# ', '@anger [exm>emotion] ', 'emotion l ', 'unkind l ', 'rage l ', 'fury l ', 'fire f +heat l +warmth l +red f +alarm f ', 'unhappy l ', 'dissatisfied l ', 'argue l +fight l +pain l +black f +color l +death f ', 'dagger f mental-pain f ', 'opponent l +enemy l +war l ', 'shout l +scream l +painful f ', '# ', ' ', '@yore [exm>time] ', 'time l ', 'past l +history l ', 'long-due l ', 'phrase l +of-yore l ', 'oldfashioned f +outdated f ', '# ']\n"
     ]
    }
   ],
   "source": [
    "with open (\"metaphor_data.txt\", \"r\") as myfile:\n",
    "    data = myfile.read().splitlines()\n",
    "    \n",
    "myfile.close()\n",
    "\n",
    "# Remove all empty-space elements\n",
    "for i in data: \n",
    "    if(i == ''): \n",
    "        data.remove('')\n",
    "        \n",
    "for i in data:\n",
    "    if(i == ' '):\n",
    "        data.remove(' ')\n",
    "        \n",
    "# Remove Trailing Space and Leading Space of each element\n",
    "for i in data:\n",
    "    i.strip()\n",
    "   \n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a696908",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "categories = []\n",
    "exemplars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c8c7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from more_itertools import locate\n",
    "# Retrieve Categories\n",
    "\n",
    "indexes = list(locate(data, lambda x: x == '# '))\n",
    "\n",
    "offset = 0\n",
    "for i in indexes:\n",
    "    data_list.append(data[offset:i+1])\n",
    "    offset = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ce5397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data_list:\n",
    "    \n",
    "    if('[catg]' in item[0]):\n",
    "        category = item[0].replace('@', '')\n",
    "        \n",
    "        cat = category.split(' ')\n",
    "        \n",
    "        categories.append(cat[0])\n",
    "        \n",
    "    elif('[catg]' in item[1]):\n",
    "        category = item[1].replace('@', '')\n",
    "        \n",
    "        cat = category.split(' ')\n",
    "        \n",
    "        categories.append(cat[0])\n",
    "        \n",
    "    if('[exm>' in item[0] or '[exm>' in item[1]):\n",
    "        exemplars.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d185c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exemplar in exemplars:\n",
    "    if(' ' in exemplar):\n",
    "        exemplar.remove(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09115171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time', 'state-of-being', 'plant', 'emotion', 'animal', 'body']\n"
     ]
    }
   ],
   "source": [
    "print(categories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb64a6d",
   "metadata": {},
   "source": [
    "# HeapSort to sort the Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "204ca47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program for implementation of heap Sort\n",
    " \n",
    "# To heapify subtree rooted at index i.\n",
    "# n is size of heap\n",
    " \n",
    " \n",
    "def heapifyCosine(arr, n, i):\n",
    "    largest = i  # Initialize largest as root\n",
    "    l = 2 * i + 1     # left = 2*i + 1\n",
    "    r = 2 * i + 2     # right = 2*i + 2\n",
    " \n",
    "    # See if left child of root exists and is\n",
    "    # greater than root\n",
    "    if l < n and arr[largest]['cosine_score'] < arr[l]['cosine_score']:\n",
    "        largest = l\n",
    " \n",
    "    # See if right child of root exists and is\n",
    "    # greater than root\n",
    "    if r < n and arr[largest]['cosine_score'] < arr[r]['cosine_score']:\n",
    "        largest = r\n",
    " \n",
    "    # Change root, if needed\n",
    "    if largest != i:\n",
    "        arr[i], arr[largest] = arr[largest], arr[i]  # swap\n",
    " \n",
    "        # Heapify the root.\n",
    "        heapifyCosine(arr, n, largest)\n",
    " \n",
    "# The main function to sort an array of given size\n",
    " \n",
    " \n",
    "def heapSortCosine(arr):\n",
    "    n = len(arr)\n",
    " \n",
    "    # Build a maxheap.\n",
    "    for i in range(n//2 - 1, -1, -1):\n",
    "        heapifyCosine(arr, n, i)\n",
    " \n",
    "    # One by one extract elements\n",
    "    for i in range(n-1, 0, -1):\n",
    "        arr[i], arr[0] = arr[0], arr[i]  # swap\n",
    "        heapifyCosine(arr, i, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54fd68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heapifyJaccard(arr, n, i):\n",
    "    largest = i  # Initialize largest as root\n",
    "    l = 2 * i + 1     # left = 2*i + 1\n",
    "    r = 2 * i + 2     # right = 2*i + 2\n",
    " \n",
    "    # See if left child of root exists and is\n",
    "    # greater than root\n",
    "    if l < n and arr[largest]['jaccard_score'] < arr[l]['jaccard_score']:\n",
    "        largest = l\n",
    " \n",
    "    # See if right child of root exists and is\n",
    "    # greater than root\n",
    "    if r < n and arr[largest]['jaccard_score'] < arr[r]['jaccard_score']:\n",
    "        largest = r\n",
    " \n",
    "    # Change root, if needed\n",
    "    if largest != i:\n",
    "        arr[i], arr[largest] = arr[largest], arr[i]  # swap\n",
    " \n",
    "        # Heapify the root.\n",
    "        heapifyJaccard(arr, n, largest)\n",
    " \n",
    "# The main function to sort an array of given size\n",
    " \n",
    " \n",
    "def heapSortJaccard(arr):\n",
    "    n = len(arr)\n",
    " \n",
    "    # Build a maxheap.\n",
    "    for i in range(n//2 - 1, -1, -1):\n",
    "        heapifyJaccard(arr, n, i)\n",
    " \n",
    "    # One by one extract elements\n",
    "    for i in range(n-1, 0, -1):\n",
    "        arr[i], arr[0] = arr[0], arr[i]  # swap\n",
    "        heapifyJaccard(arr, i, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8651a042",
   "metadata": {},
   "source": [
    "# Three Conditions for Each Result\n",
    "\n",
    "- Metaphors = Out Of Category Associations, Large Intersection of Features\n",
    "\n",
    "- Anomaly = Out of Category Associations, Small Intersection of Features\n",
    "\n",
    "- Literal = In Category Associations, Large Intersection of Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52d5ba4",
   "metadata": {},
   "source": [
    "# Assumptions Made:\n",
    "\n",
    "- Set-Theory/Fuzzy-Matching is done between Nouns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec5535",
   "metadata": {},
   "source": [
    "# To determine Metaphor, Anomaly, Literal:\n",
    "\n",
    "- significant **difference between literal statements and metaphors** was in the size of the **intersection between features that were literal for the one noun and figurative** for the other **(Noun1 literal-Noun2 figurative and Noun1 figurative - Noun2 literal)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e04e1",
   "metadata": {},
   "source": [
    "# Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6afd682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def tfid_vectorize_cosine(featurelist1, featurelist2):\n",
    "    \n",
    "\n",
    "    Tfidf_vect = TfidfVectorizer()\n",
    "    \n",
    "    # Stringify List to String to vectorize\n",
    "    emotion_features_str = ' '.join(featurelist1)\n",
    "    exemplar_features_str = ' '.join(featurelist2)\n",
    "    \n",
    "    # Convert to list to vectorize\n",
    "    data = [emotion_features_str, exemplar_features_str]\n",
    "    \n",
    "    vector_matrix = Tfidf_vect.fit_transform(data)\n",
    "    \n",
    "     # Convert Vector Matrix to arrayc\n",
    "    vector_matrix.toarray()\n",
    "    \n",
    "    tokens = Tfidf_vect.get_feature_names()\n",
    "    \n",
    "\n",
    "    # Generate Cosine Similarity score\n",
    "    cosine_similarity_matrix = cosine_similarity(vector_matrix)\n",
    "    \n",
    "  \n",
    "    \n",
    "    return [cosine_similarity_matrix, tokens, vector_matrix]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63492a7",
   "metadata": {},
   "source": [
    "# Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d8eae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(doc1, doc2): \n",
    "    \n",
    "    # List the unique words in a document\n",
    "    words_doc1 = set(doc1) \n",
    "    words_doc2 = set(doc2)\n",
    "    \n",
    "    # Find the intersection of words list of doc1 & doc2\n",
    "    intersection = words_doc1.intersection(words_doc2)\n",
    "\n",
    "    # Find the union of words list of doc1 & doc2\n",
    "    union = words_doc1.union(words_doc2)\n",
    "        \n",
    "    # Calculate Jaccard similarity score \n",
    "    # using length of intersection set divided by length of union set\n",
    "    return float(len(intersection)) / len(union)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aea10eb",
   "metadata": {},
   "source": [
    "# Fuzzy Matching of Matching Features (Cosine Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3658d68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'exemplar1': '@heart [exm>body] ', 'exemplar2': '@heart [exm>body] ', 'cosine_score': 1.0, 'jaccard_score': 1.0}, {'exemplar1': '@heart [exm>body] ', 'exemplar2': '@love [exm>emotion] ', 'cosine_score': 0.2259438995424407, 'jaccard_score': 0.03571428571428571}, {'exemplar1': '@heart [exm>body] ', 'exemplar2': '@rose [exm>plant] ', 'cosine_score': 0.19187760886358848, 'jaccard_score': 0.041666666666666664}, {'exemplar1': '@heart [exm>body] ', 'exemplar2': '@lily [exm>plant] ', 'cosine_score': 0.08565876226028779, 'jaccard_score': 0.0}, {'exemplar1': '@heart [exm>body] ', 'exemplar2': '@death [exm>state-of-being] ', 'cosine_score': 0.09715902064418518, 'jaccard_score': 0.0}, {'exemplar1': '@heart [exm>body] ', 'exemplar2': '@mouth [exm>body] ', 'cosine_score': 0.24551676966169794, 'jaccard_score': 0.043478260869565216}, {'exemplar1': '@heart [exm>body] ', 'exemplar2': '@anger [exm>emotion] ', 'cosine_score': 0.2460206176207249, 'jaccard_score': 0.0}, {'exemplar1': '@heart [exm>body] ', 'exemplar2': '@yore [exm>time] ', 'cosine_score': 0.012429086536250132, 'jaccard_score': 0.0}, {'exemplar1': '@love [exm>emotion] ', 'exemplar2': '@heart [exm>body] ', 'cosine_score': 0.22594389954244073, 'jaccard_score': 0.03571428571428571}, {'exemplar1': '@love [exm>emotion] ', 'exemplar2': '@love [exm>emotion] ', 'cosine_score': 1.0000000000000002, 'jaccard_score': 1.0}, {'exemplar1': '@love [exm>emotion] ', 'exemplar2': '@rose [exm>plant] ', 'cosine_score': 0.30931969920821156, 'jaccard_score': 0.034482758620689655}, {'exemplar1': '@love [exm>emotion] ', 'exemplar2': '@lily [exm>plant] ', 'cosine_score': 0.1409585277208146, 'jaccard_score': 0.0}, {'exemplar1': '@love [exm>emotion] ', 'exemplar2': '@death [exm>state-of-being] ', 'cosine_score': 0.015644183345665145, 'jaccard_score': 0.0}, {'exemplar1': '@love [exm>emotion] ', 'exemplar2': '@mouth [exm>body] ', 'cosine_score': 0.22144130526801162, 'jaccard_score': 0.03571428571428571}, {'exemplar1': '@love [exm>emotion] ', 'exemplar2': '@anger [exm>emotion] ', 'cosine_score': 0.26617738054111806, 'jaccard_score': 0.03571428571428571}, {'exemplar1': '@love [exm>emotion] ', 'exemplar2': '@yore [exm>time] ', 'cosine_score': 0.019824528302927247, 'jaccard_score': 0.0}, {'exemplar1': '@rose [exm>plant] ', 'exemplar2': '@heart [exm>body] ', 'cosine_score': 0.19187760886358854, 'jaccard_score': 0.041666666666666664}, {'exemplar1': '@rose [exm>plant] ', 'exemplar2': '@love [exm>emotion] ', 'cosine_score': 0.30931969920821145, 'jaccard_score': 0.034482758620689655}, {'exemplar1': '@rose [exm>plant] ', 'exemplar2': '@rose [exm>plant] ', 'cosine_score': 1.0000000000000002, 'jaccard_score': 1.0}, {'exemplar1': '@rose [exm>plant] ', 'exemplar2': '@lily [exm>plant] ', 'cosine_score': 0.49432288244614064, 'jaccard_score': 0.35294117647058826}, {'exemplar1': '@rose [exm>plant] ', 'exemplar2': '@death [exm>state-of-being] ', 'cosine_score': 0.051171029771728035, 'jaccard_score': 0.0}, {'exemplar1': '@rose [exm>plant] ', 'exemplar2': '@mouth [exm>body] ', 'cosine_score': 0.2745063019238161, 'jaccard_score': 0.041666666666666664}, {'exemplar1': '@rose [exm>plant] ', 'exemplar2': '@anger [exm>emotion] ', 'cosine_score': 0.18039464569574265, 'jaccard_score': 0.0}, {'exemplar1': '@rose [exm>plant] ', 'exemplar2': '@yore [exm>time] ', 'cosine_score': 0.020911412399213552, 'jaccard_score': 0.0}, {'exemplar1': '@lily [exm>plant] ', 'exemplar2': '@heart [exm>body] ', 'cosine_score': 0.08565876226028779, 'jaccard_score': 0.0}, {'exemplar1': '@lily [exm>plant] ', 'exemplar2': '@love [exm>emotion] ', 'cosine_score': 0.1409585277208146, 'jaccard_score': 0.0}, {'exemplar1': '@lily [exm>plant] ', 'exemplar2': '@rose [exm>plant] ', 'cosine_score': 0.4943228824461407, 'jaccard_score': 0.35294117647058826}, {'exemplar1': '@lily [exm>plant] ', 'exemplar2': '@lily [exm>plant] ', 'cosine_score': 0.9999999999999993, 'jaccard_score': 1.0}, {'exemplar1': '@lily [exm>plant] ', 'exemplar2': '@death [exm>state-of-being] ', 'cosine_score': 0.1263637396650437, 'jaccard_score': 0.0}, {'exemplar1': '@lily [exm>plant] ', 'exemplar2': '@mouth [exm>body] ', 'cosine_score': 0.13059314839931468, 'jaccard_score': 0.0}, {'exemplar1': '@lily [exm>plant] ', 'exemplar2': '@anger [exm>emotion] ', 'cosine_score': 0.09309160847585263, 'jaccard_score': 0.0}, {'exemplar1': '@lily [exm>plant] ', 'exemplar2': '@yore [exm>time] ', 'cosine_score': 0.02420257852540868, 'jaccard_score': 0.0}, {'exemplar1': '@death [exm>state-of-being] ', 'exemplar2': '@heart [exm>body] ', 'cosine_score': 0.09715902064418518, 'jaccard_score': 0.0}, {'exemplar1': '@death [exm>state-of-being] ', 'exemplar2': '@love [exm>emotion] ', 'cosine_score': 0.015644183345665145, 'jaccard_score': 0.0}, {'exemplar1': '@death [exm>state-of-being] ', 'exemplar2': '@rose [exm>plant] ', 'cosine_score': 0.051171029771728035, 'jaccard_score': 0.0}, {'exemplar1': '@death [exm>state-of-being] ', 'exemplar2': '@lily [exm>plant] ', 'cosine_score': 0.12636373966504363, 'jaccard_score': 0.0}, {'exemplar1': '@death [exm>state-of-being] ', 'exemplar2': '@death [exm>state-of-being] ', 'cosine_score': 0.9999999999999991, 'jaccard_score': 1.0}, {'exemplar1': '@death [exm>state-of-being] ', 'exemplar2': '@mouth [exm>body] ', 'cosine_score': 0.012855372308615798, 'jaccard_score': 0.0}, {'exemplar1': '@death [exm>state-of-being] ', 'exemplar2': '@anger [exm>emotion] ', 'cosine_score': 0.09249073209783297, 'jaccard_score': 0.0}, {'exemplar1': '@death [exm>state-of-being] ', 'exemplar2': '@yore [exm>time] ', 'cosine_score': 0.049610031776959565, 'jaccard_score': 0.0}, {'exemplar1': '@mouth [exm>body] ', 'exemplar2': '@heart [exm>body] ', 'cosine_score': 0.2455167696616979, 'jaccard_score': 0.043478260869565216}, {'exemplar1': '@mouth [exm>body] ', 'exemplar2': '@love [exm>emotion] ', 'cosine_score': 0.22144130526801162, 'jaccard_score': 0.03571428571428571}, {'exemplar1': '@mouth [exm>body] ', 'exemplar2': '@rose [exm>plant] ', 'cosine_score': 0.274506301923816, 'jaccard_score': 0.041666666666666664}, {'exemplar1': '@mouth [exm>body] ', 'exemplar2': '@lily [exm>plant] ', 'cosine_score': 0.13059314839931466, 'jaccard_score': 0.0}, {'exemplar1': '@mouth [exm>body] ', 'exemplar2': '@death [exm>state-of-being] ', 'cosine_score': 0.012855372308615798, 'jaccard_score': 0.0}, {'exemplar1': '@mouth [exm>body] ', 'exemplar2': '@mouth [exm>body] ', 'cosine_score': 1.0, 'jaccard_score': 1.0}, {'exemplar1': '@mouth [exm>body] ', 'exemplar2': '@anger [exm>emotion] ', 'cosine_score': 0.14523731190027891, 'jaccard_score': 0.0}, {'exemplar1': '@mouth [exm>body] ', 'exemplar2': '@yore [exm>time] ', 'cosine_score': 0.016290507886909805, 'jaccard_score': 0.0}, {'exemplar1': '@anger [exm>emotion] ', 'exemplar2': '@heart [exm>body] ', 'cosine_score': 0.2460206176207249, 'jaccard_score': 0.0}, {'exemplar1': '@anger [exm>emotion] ', 'exemplar2': '@love [exm>emotion] ', 'cosine_score': 0.26617738054111806, 'jaccard_score': 0.03571428571428571}, {'exemplar1': '@anger [exm>emotion] ', 'exemplar2': '@rose [exm>plant] ', 'cosine_score': 0.1803946456957427, 'jaccard_score': 0.0}, {'exemplar1': '@anger [exm>emotion] ', 'exemplar2': '@lily [exm>plant] ', 'cosine_score': 0.09309160847585263, 'jaccard_score': 0.0}, {'exemplar1': '@anger [exm>emotion] ', 'exemplar2': '@death [exm>state-of-being] ', 'cosine_score': 0.09249073209783304, 'jaccard_score': 0.0}, {'exemplar1': '@anger [exm>emotion] ', 'exemplar2': '@mouth [exm>body] ', 'cosine_score': 0.14523731190027891, 'jaccard_score': 0.0}, {'exemplar1': '@anger [exm>emotion] ', 'exemplar2': '@anger [exm>emotion] ', 'cosine_score': 1.0, 'jaccard_score': 1.0}, {'exemplar1': '@anger [exm>emotion] ', 'exemplar2': '@yore [exm>time] ', 'cosine_score': 0.02185507685681808, 'jaccard_score': 0.0}, {'exemplar1': '@yore [exm>time] ', 'exemplar2': '@heart [exm>body] ', 'cosine_score': 0.012429086536250132, 'jaccard_score': 0.0}, {'exemplar1': '@yore [exm>time] ', 'exemplar2': '@love [exm>emotion] ', 'cosine_score': 0.019824528302927247, 'jaccard_score': 0.0}, {'exemplar1': '@yore [exm>time] ', 'exemplar2': '@rose [exm>plant] ', 'cosine_score': 0.020911412399213552, 'jaccard_score': 0.0}, {'exemplar1': '@yore [exm>time] ', 'exemplar2': '@lily [exm>plant] ', 'cosine_score': 0.02420257852540868, 'jaccard_score': 0.0}, {'exemplar1': '@yore [exm>time] ', 'exemplar2': '@death [exm>state-of-being] ', 'cosine_score': 0.049610031776959565, 'jaccard_score': 0.0}, {'exemplar1': '@yore [exm>time] ', 'exemplar2': '@mouth [exm>body] ', 'cosine_score': 0.016290507886909805, 'jaccard_score': 0.0}, {'exemplar1': '@yore [exm>time] ', 'exemplar2': '@anger [exm>emotion] ', 'cosine_score': 0.02185507685681808, 'jaccard_score': 0.0}, {'exemplar1': '@yore [exm>time] ', 'exemplar2': '@yore [exm>time] ', 'cosine_score': 1.0, 'jaccard_score': 1.0}]\n"
     ]
    }
   ],
   "source": [
    "# Fuzzy Matching\n",
    "associations = []\n",
    "\n",
    "for exemplar1 in exemplars:\n",
    "\n",
    "    noun1List = []\n",
    "    \n",
    "    for i in range(0, len(exemplar1)):\n",
    "        \n",
    "        if('#' in exemplar1[i]):\n",
    "            continue\n",
    "        \n",
    "        noun1List.append(exemplar1[i])\n",
    "    \n",
    "    for exemplar2 in exemplars:\n",
    "        \n",
    "        noun2List = []\n",
    "        \n",
    "        for j in range(0, len(exemplar2)):\n",
    "            \n",
    "            if('#' in exemplar2[j]):\n",
    "                continue\n",
    "            \n",
    "            noun2List.append(exemplar2[j])\n",
    "                \n",
    "            \n",
    "        cosine_similarity_results = tfid_vectorize_cosine(noun1List, noun2List)\n",
    "        \n",
    "        cosine_similarity_score = cosine_similarity_results[0][0][1]\n",
    "        cosine_features = cosine_similarity_results[1]\n",
    "        cos_matrix = cosine_similarity_results[2]\n",
    "        \n",
    "        jaccard_similarity_score = jaccard_similarity(noun1List, noun2List)\n",
    "        \n",
    "        \n",
    "        \n",
    "        associations.append(\n",
    "            dict( \n",
    "                exemplar1 = noun1List[0], \n",
    "                exemplar2 = noun2List[0], \n",
    "                cosine_score = cosine_similarity_score, \n",
    "                jaccard_score = jaccard_similarity_score, \n",
    "                \n",
    "            ))\n",
    "\n",
    "\n",
    "print(associations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f6d7f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaphor-Threshold: 0.2 Literal-Threshold 0.9 \n",
      "\n",
      "64\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@heart [exm>body]  @yore [exm>time]  is Anomaly\n",
      "0.012429086536250132\n",
      "\n",
      "\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@yore [exm>time]  @heart [exm>body]  is Anomaly\n",
      "0.012429086536250132\n",
      "\n",
      "\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@death [exm>state-of-being]  @mouth [exm>body]  is Anomaly\n",
      "0.012855372308615798\n",
      "\n",
      "\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@mouth [exm>body]  @death [exm>state-of-being]  is Anomaly\n",
      "0.012855372308615798\n",
      "\n",
      "\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@love [exm>emotion]  @death [exm>state-of-being]  is Anomaly\n",
      "0.015644183345665145\n",
      "\n",
      "\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@death [exm>state-of-being]  @love [exm>emotion]  is Anomaly\n",
      "0.015644183345665145\n",
      "\n",
      "\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@yore [exm>time]  @mouth [exm>body]  is Anomaly\n",
      "0.016290507886909805\n",
      "\n",
      "\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@mouth [exm>body]  @yore [exm>time]  is Anomaly\n",
      "0.016290507886909805\n",
      "\n",
      "\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@yore [exm>time]  @love [exm>emotion]  is Anomaly\n",
      "0.019824528302927247\n",
      "\n",
      "\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@love [exm>emotion]  @yore [exm>time]  is Anomaly\n",
      "0.019824528302927247\n",
      "\n",
      "\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@rose [exm>plant]  @yore [exm>time]  is Anomaly\n",
      "0.020911412399213552\n",
      "\n",
      "\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@yore [exm>time]  @rose [exm>plant]  is Anomaly\n",
      "0.020911412399213552\n",
      "\n",
      "\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@anger [exm>emotion]  @yore [exm>time]  is Anomaly\n",
      "0.02185507685681808\n",
      "\n",
      "\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@yore [exm>time]  @anger [exm>emotion]  is Anomaly\n",
      "0.02185507685681808\n",
      "\n",
      "\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@yore [exm>time]  @lily [exm>plant]  is Anomaly\n",
      "0.02420257852540868\n",
      "\n",
      "\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@lily [exm>plant]  @yore [exm>time]  is Anomaly\n",
      "0.02420257852540868\n",
      "\n",
      "\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@yore [exm>time]  @death [exm>state-of-being]  is Anomaly\n",
      "0.049610031776959565\n",
      "\n",
      "\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@death [exm>state-of-being]  @yore [exm>time]  is Anomaly\n",
      "0.049610031776959565\n",
      "\n",
      "\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@rose [exm>plant]  @death [exm>state-of-being]  is Anomaly\n",
      "0.051171029771728035\n",
      "\n",
      "\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@death [exm>state-of-being]  @rose [exm>plant]  is Anomaly\n",
      "0.051171029771728035\n",
      "\n",
      "\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@lily [exm>plant]  @heart [exm>body]  is Anomaly\n",
      "0.08565876226028779\n",
      "\n",
      "\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@heart [exm>body]  @lily [exm>plant]  is Anomaly\n",
      "0.08565876226028779\n",
      "\n",
      "\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@death [exm>state-of-being]  @anger [exm>emotion]  is Anomaly\n",
      "0.09249073209783297\n",
      "\n",
      "\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@anger [exm>emotion]  @death [exm>state-of-being]  is Anomaly\n",
      "0.09249073209783304\n",
      "\n",
      "\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@lily [exm>plant]  @anger [exm>emotion]  is Anomaly\n",
      "0.09309160847585263\n",
      "\n",
      "\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@anger [exm>emotion]  @lily [exm>plant]  is Anomaly\n",
      "0.09309160847585263\n",
      "\n",
      "\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@heart [exm>body]  @death [exm>state-of-being]  is Anomaly\n",
      "0.09715902064418518\n",
      "\n",
      "\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@death [exm>state-of-being]  @heart [exm>body]  is Anomaly\n",
      "0.09715902064418518\n",
      "\n",
      "\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@death [exm>state-of-being]  @lily [exm>plant]  is Anomaly\n",
      "0.12636373966504363\n",
      "\n",
      "\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@lily [exm>plant]  @death [exm>state-of-being]  is Anomaly\n",
      "0.1263637396650437\n",
      "\n",
      "\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@mouth [exm>body]  @lily [exm>plant]  is Anomaly\n",
      "0.13059314839931466\n",
      "\n",
      "\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@lily [exm>plant]  @mouth [exm>body]  is Anomaly\n",
      "0.13059314839931468\n",
      "\n",
      "\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@lily [exm>plant]  @love [exm>emotion]  is Anomaly\n",
      "0.1409585277208146\n",
      "\n",
      "\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@love [exm>emotion]  @lily [exm>plant]  is Anomaly\n",
      "0.1409585277208146\n",
      "\n",
      "\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@mouth [exm>body]  @anger [exm>emotion]  is Anomaly\n",
      "0.14523731190027891\n",
      "\n",
      "\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@anger [exm>emotion]  @mouth [exm>body]  is Anomaly\n",
      "0.14523731190027891\n",
      "\n",
      "\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@rose [exm>plant]  @anger [exm>emotion]  is Anomaly\n",
      "0.18039464569574265\n",
      "\n",
      "\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@anger [exm>emotion]  @rose [exm>plant]  is Anomaly\n",
      "0.1803946456957427\n",
      "\n",
      "\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@heart [exm>body]  @rose [exm>plant]  is Anomaly\n",
      "0.19187760886358848\n",
      "\n",
      "\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@rose [exm>plant]  @heart [exm>body]  is Anomaly\n",
      "0.19187760886358854\n",
      "\n",
      "\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@love [exm>emotion]  @mouth [exm>body]  is Metaphor\n",
      "0.22144130526801162\n",
      "\n",
      "\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@mouth [exm>body]  @love [exm>emotion]  is Metaphor\n",
      "0.22144130526801162\n",
      "\n",
      "\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@heart [exm>body]  @love [exm>emotion]  is Metaphor\n",
      "0.2259438995424407\n",
      "\n",
      "\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@love [exm>emotion]  @heart [exm>body]  is Metaphor\n",
      "0.22594389954244073\n",
      "\n",
      "\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@mouth [exm>body]  @heart [exm>body]  is Anomaly\n",
      "0.2455167696616979\n",
      "\n",
      "\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@heart [exm>body]  @mouth [exm>body]  is Anomaly\n",
      "0.24551676966169794\n",
      "\n",
      "\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@heart [exm>body]  @anger [exm>emotion]  is Metaphor\n",
      "0.2460206176207249\n",
      "\n",
      "\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@anger [exm>emotion]  @heart [exm>body]  is Metaphor\n",
      "0.2460206176207249\n",
      "\n",
      "\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@love [exm>emotion]  @anger [exm>emotion]  is Anomaly\n",
      "0.26617738054111806\n",
      "\n",
      "\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@anger [exm>emotion]  @love [exm>emotion]  is Anomaly\n",
      "0.26617738054111806\n",
      "\n",
      "\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@mouth [exm>body]  @rose [exm>plant]  is Metaphor\n",
      "0.274506301923816\n",
      "\n",
      "\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@rose [exm>plant]  @mouth [exm>body]  is Metaphor\n",
      "0.2745063019238161\n",
      "\n",
      "\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@rose [exm>plant]  @love [exm>emotion]  is Metaphor\n",
      "0.30931969920821145\n",
      "\n",
      "\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@love [exm>emotion]  @rose [exm>plant]  is Metaphor\n",
      "0.30931969920821156\n",
      "\n",
      "\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@rose [exm>plant]  @lily [exm>plant]  is Anomaly\n",
      "0.49432288244614064\n",
      "\n",
      "\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@lily [exm>plant]  @rose [exm>plant]  is Anomaly\n",
      "0.4943228824461407\n",
      "\n",
      "\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@death [exm>state-of-being]  @death [exm>state-of-being]  is Literal\n",
      "0.9999999999999991\n",
      "Tautology.\n",
      "\n",
      "\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@lily [exm>plant]  @lily [exm>plant]  is Literal\n",
      "0.9999999999999993\n",
      "Tautology.\n",
      "\n",
      "\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@anger [exm>emotion]  @anger [exm>emotion]  is Literal\n",
      "1.0\n",
      "Tautology.\n",
      "\n",
      "\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@mouth [exm>body]  @mouth [exm>body]  is Literal\n",
      "1.0\n",
      "Tautology.\n",
      "\n",
      "\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@heart [exm>body]  @heart [exm>body]  is Literal\n",
      "1.0\n",
      "Tautology.\n",
      "\n",
      "\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@yore [exm>time]  @yore [exm>time]  is Literal\n",
      "1.0\n",
      "Tautology.\n",
      "\n",
      "\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@love [exm>emotion]  @love [exm>emotion]  is Literal\n",
      "1.0000000000000002\n",
      "Tautology.\n",
      "\n",
      "\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@rose [exm>plant]  @rose [exm>plant]  is Literal\n",
      "1.0000000000000002\n",
      "Tautology.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for Cosine Similarity\n",
    "heapSortCosine(associations)\n",
    "\n",
    "print('Metaphor-Threshold:', metaphor_threshold, 'Literal-Threshold', literal_threshold, '\\n')\n",
    "\n",
    "print(len(associations))\n",
    "\n",
    "for association in associations:\n",
    "    \n",
    "    exemplar1_noun = association['exemplar1'].split(' ')[0]\n",
    "    exemplar2_noun = association['exemplar2'].split(' ')[0]\n",
    "    \n",
    "    exemplar1_noun = exemplar1_noun.replace('@', '')\n",
    "    exemplar2_noun = exemplar2_noun.replace('@', '')\n",
    "    \n",
    "    for category in categories:\n",
    "        \n",
    "        if(category in association['exemplar1']):\n",
    "           \n",
    "            noun1Category = category\n",
    "            \n",
    "        if(category in association['exemplar2']):\n",
    "            \n",
    "            noun2Category = category\n",
    "    \n",
    "    # Print out the Category Associations\n",
    "    print(association['exemplar1'], 'means', exemplar1_noun,'is an exemplar in', noun1Category)\n",
    "    print(association['exemplar2'], 'means', exemplar2_noun,'is an exemplar in', noun2Category)\n",
    "    \n",
    "    # Literal when the Similarity of the Association is beyond the Metaphor Threshold\n",
    "    if(association['cosine_score'] > literal_threshold):\n",
    "        print(association['exemplar1'], association['exemplar2'],'is Literal')\n",
    "    \n",
    "    # Anomaly is when the Simiilarity of the Association is below the Metaphor Threshold\n",
    "    elif(association['cosine_score'] < metaphor_threshold):\n",
    "         print(association['exemplar1'], association['exemplar2'],'is Anomaly')\n",
    "    \n",
    "    # Metaphor must be Out of Category Associations! Meets the Metaphor Threshold\n",
    "    elif(noun1Category != noun2Category):\n",
    "        print(association['exemplar1'], association['exemplar2'],'is Metaphor')\n",
    "    \n",
    "    # Meets the Metaphor Threshold but the Association is In-Category..\n",
    "    else:\n",
    "        print(association['exemplar1'], association['exemplar2'],'is Anomaly')\n",
    "        \n",
    "    print(association['cosine_score'])\n",
    "    \n",
    "    if(association['cosine_score'] >= 0.99):\n",
    "        print('Tautology.')\n",
    "        \n",
    "    #print(association['matching_features'])\n",
    "    \n",
    "   \n",
    "    print('\\n')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca365060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaphor-Threshold: 0.2 Literal-Threshold 0.9 \n",
      "\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@death [exm>state-of-being]  @anger [exm>emotion]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@lily [exm>plant]  @heart [exm>body]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@anger [exm>emotion]  @yore [exm>time]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@heart [exm>body]  @anger [exm>emotion]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@death [exm>state-of-being]  @love [exm>emotion]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@death [exm>state-of-being]  @heart [exm>body]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@mouth [exm>body]  @death [exm>state-of-being]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@yore [exm>time]  @heart [exm>body]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@anger [exm>emotion]  @death [exm>state-of-being]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@anger [exm>emotion]  @heart [exm>body]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@yore [exm>time]  @rose [exm>plant]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@rose [exm>plant]  @yore [exm>time]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@yore [exm>time]  @mouth [exm>body]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@lily [exm>plant]  @death [exm>state-of-being]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@mouth [exm>body]  @yore [exm>time]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@yore [exm>time]  @death [exm>state-of-being]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@death [exm>state-of-being]  @yore [exm>time]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@yore [exm>time]  @love [exm>emotion]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@heart [exm>body]  @death [exm>state-of-being]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@anger [exm>emotion]  @lily [exm>plant]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@heart [exm>body]  @yore [exm>time]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@love [exm>emotion]  @death [exm>state-of-being]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@death [exm>state-of-being]  @lily [exm>plant]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@lily [exm>plant]  @anger [exm>emotion]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@yore [exm>time]  @anger [exm>emotion]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@heart [exm>body]  @lily [exm>plant]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@lily [exm>plant]  @mouth [exm>body]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@death [exm>state-of-being]  @mouth [exm>body]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@mouth [exm>body]  @lily [exm>plant]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@yore [exm>time]  @lily [exm>plant]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@lily [exm>plant]  @yore [exm>time]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@lily [exm>plant]  @love [exm>emotion]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@love [exm>emotion]  @lily [exm>plant]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@mouth [exm>body]  @anger [exm>emotion]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@anger [exm>emotion]  @mouth [exm>body]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@rose [exm>plant]  @anger [exm>emotion]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@anger [exm>emotion]  @rose [exm>plant]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@rose [exm>plant]  @death [exm>state-of-being]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@death [exm>state-of-being]  @rose [exm>plant]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@love [exm>emotion]  @yore [exm>time]  is Anomaly\n",
      "0.0\n",
      "\n",
      "\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@love [exm>emotion]  @rose [exm>plant]  is Anomaly\n",
      "0.034482758620689655\n",
      "\n",
      "\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@rose [exm>plant]  @love [exm>emotion]  is Anomaly\n",
      "0.034482758620689655\n",
      "\n",
      "\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@anger [exm>emotion]  @love [exm>emotion]  is Anomaly\n",
      "0.03571428571428571\n",
      "\n",
      "\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@love [exm>emotion]  @anger [exm>emotion]  is Anomaly\n",
      "0.03571428571428571\n",
      "\n",
      "\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@love [exm>emotion]  @heart [exm>body]  is Anomaly\n",
      "0.03571428571428571\n",
      "\n",
      "\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@heart [exm>body]  @love [exm>emotion]  is Anomaly\n",
      "0.03571428571428571\n",
      "\n",
      "\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@mouth [exm>body]  @love [exm>emotion]  is Anomaly\n",
      "0.03571428571428571\n",
      "\n",
      "\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@love [exm>emotion]  @mouth [exm>body]  is Anomaly\n",
      "0.03571428571428571\n",
      "\n",
      "\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@rose [exm>plant]  @mouth [exm>body]  is Anomaly\n",
      "0.041666666666666664\n",
      "\n",
      "\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@mouth [exm>body]  @rose [exm>plant]  is Anomaly\n",
      "0.041666666666666664\n",
      "\n",
      "\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@rose [exm>plant]  @heart [exm>body]  is Anomaly\n",
      "0.041666666666666664\n",
      "\n",
      "\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@heart [exm>body]  @rose [exm>plant]  is Anomaly\n",
      "0.041666666666666664\n",
      "\n",
      "\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@heart [exm>body]  @mouth [exm>body]  is Anomaly\n",
      "0.043478260869565216\n",
      "\n",
      "\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@mouth [exm>body]  @heart [exm>body]  is Anomaly\n",
      "0.043478260869565216\n",
      "\n",
      "\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@lily [exm>plant]  @rose [exm>plant]  is Literal\n",
      "0.35294117647058826\n",
      "\n",
      "\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@rose [exm>plant]  @lily [exm>plant]  is Literal\n",
      "0.35294117647058826\n",
      "\n",
      "\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@yore [exm>time]  means yore is an exemplar in time\n",
      "@yore [exm>time]  @yore [exm>time]  is Literal\n",
      "1.0\n",
      "\n",
      "\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@heart [exm>body]  means heart is an exemplar in body\n",
      "@heart [exm>body]  @heart [exm>body]  is Literal\n",
      "1.0\n",
      "\n",
      "\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@mouth [exm>body]  means mouth is an exemplar in body\n",
      "@mouth [exm>body]  @mouth [exm>body]  is Literal\n",
      "1.0\n",
      "\n",
      "\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@anger [exm>emotion]  means anger is an exemplar in emotion\n",
      "@anger [exm>emotion]  @anger [exm>emotion]  is Literal\n",
      "1.0\n",
      "\n",
      "\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@lily [exm>plant]  means lily is an exemplar in plant\n",
      "@lily [exm>plant]  @lily [exm>plant]  is Literal\n",
      "1.0\n",
      "\n",
      "\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@love [exm>emotion]  means love is an exemplar in emotion\n",
      "@love [exm>emotion]  @love [exm>emotion]  is Literal\n",
      "1.0\n",
      "\n",
      "\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@death [exm>state-of-being]  means death is an exemplar in state-of-being\n",
      "@death [exm>state-of-being]  @death [exm>state-of-being]  is Literal\n",
      "1.0\n",
      "\n",
      "\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@rose [exm>plant]  means rose is an exemplar in plant\n",
      "@rose [exm>plant]  @rose [exm>plant]  is Literal\n",
      "1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for Jaccard Similarity\n",
    "heapSortJaccard(associations)\n",
    "\n",
    "print('Metaphor-Threshold:', metaphor_threshold, 'Literal-Threshold', literal_threshold, '\\n')\n",
    "\n",
    "for association in associations:\n",
    "    \n",
    "\n",
    "    exemplar1_noun = association['exemplar1'].split(' ')[0]\n",
    "    exemplar2_noun = association['exemplar2'].split(' ')[0]\n",
    "    \n",
    "    exemplar1_noun = exemplar1_noun.replace('@', '')\n",
    "    exemplar2_noun = exemplar2_noun.replace('@', '')\n",
    "    \n",
    "    for category in categories:\n",
    "        \n",
    "        if(category in association['exemplar1']):\n",
    "           \n",
    "            noun1Category = category\n",
    "            \n",
    "        if(category in association['exemplar2']):\n",
    "            \n",
    "            noun2Category = category\n",
    "    \n",
    "    # Print out the Category Associations\n",
    "    print(association['exemplar1'], 'means', exemplar1_noun,'is an exemplar in', noun1Category)\n",
    "    print(association['exemplar2'], 'means', exemplar2_noun,'is an exemplar in', noun2Category)\n",
    "    \n",
    "    # Literal when the Similarity of the Association is beyond the Metaphor Threshold\n",
    "    if(association['jaccard_score'] > literal_threshold):\n",
    "        print(association['exemplar1'], association['exemplar2'], 'is Literal')\n",
    "    \n",
    "    # Anomaly is when the Simiilarity of the Association is below the Metaphor Threshold\n",
    "    elif(association['jaccard_score'] < metaphor_threshold):\n",
    "         print(association['exemplar1'], association['exemplar2'], 'is Anomaly')\n",
    "    \n",
    "    # Metaphor must be Out of Category Associations! Meets the Metaphor Threshold\n",
    "    elif(noun1Category != noun2Category):\n",
    "        print(association['exemplar1'], association['exemplar2'], 'is Metaphor')\n",
    "    \n",
    "    # Meets the Metaphor Threshold but the Association is In-Category..\n",
    "    else:\n",
    "        print(association['exemplar1'], association['exemplar2'], 'is Literal')\n",
    "        \n",
    "    print(association['jaccard_score'])\n",
    "    print('\\n')\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14c921d",
   "metadata": {},
   "source": [
    "# Based on Fuzzy Matching Sets, determine the amount of Associations between Literals & Figuratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c60b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associations between Literal-Literal\n",
    "lit2lit = []\n",
    "\n",
    "# Associations between Figurative-Figurative\n",
    "fig2fig = []\n",
    "\n",
    "# Associations between Literal-Figurative\n",
    "lit2fig = []\n",
    "\n",
    "# Associations between Figurative-Literal\n",
    "fig2lit = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb28c24",
   "metadata": {},
   "source": [
    "# Experiment 2: Emotion-Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81dd7e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Input value of Criterion Q:30\n",
      "Criterion Q: 30\n"
     ]
    }
   ],
   "source": [
    "# Criterion Q determines the number of features as a threshold to compare to.\n",
    "# Exemplar to compare must also be a noun!\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        criterionQ = int(input(\"Please Input value of Criterion Q:\"))\n",
    "        break\n",
    "        \n",
    "    except ValueError:\n",
    "        print('Criterion Q needs to be an Integer!')\n",
    "\n",
    "print(\"Criterion Q:\", criterionQ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217026c6",
   "metadata": {},
   "source": [
    "# User Input to determine 2nd Category (must be a noun) to compare to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "203435bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines Second Exemplar to associate our concepts with.\n",
    "\n",
    "# Definition of a Noun: A person, place, thing or \"idea\"\n",
    "\n",
    "# Nouns are basically used to convey words that could potentially represent concepts.\n",
    "# Thus, nouns would be suitable as our exemplar to compare to.\n",
    "\n",
    "\n",
    "# Import from NLTK corpus that has Wordnet\n",
    "from nltk.corpus import wordnet as wn\n",
    "# retrieve nouns from Wordnet Corpus\n",
    "nouns = {x.name().split('.', 1)[0] for x in wn.all_synsets('n')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "173373e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input a Category Noun to compare to:weather\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "   \n",
    "        exemplar = input(\"Please input a Category Noun to compare to:\")\n",
    "        if(exemplar in nouns):\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            print(\"exemplar needs to be a noun!\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1f3bc4",
   "metadata": {},
   "source": [
    "# Necessary libraries for BERT & NLP Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f3f0dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "# Import Trnasformer model to be used in our BERT model\n",
    "# AutoTokenizer tokenizes the string..\n",
    "# AutoModelForSequenceClassification loads in the architecture from Transformers to load our NLP model.\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Argmax function from Torch to filter out the highest-sequence result..\n",
    "import torch\n",
    "\n",
    "# Natural Language Processing Tools\n",
    "import nltk\n",
    "\n",
    "# requests used to grab data from Yelp\n",
    "import requests\n",
    "# BeautifulSoup allows us to traverse and scrape data from AskNature\n",
    "from bs4 import BeautifulSoup\n",
    "# Regex functions\n",
    "import re\n",
    "\n",
    "import string\n",
    "\n",
    "# Downloading stopwords for English from NLTK \n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords, words\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "print(len(stopWords))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef99398",
   "metadata": {},
   "source": [
    "# Text-Cleaning (Data-Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "465532ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://studymachinelearning.com/text-data-cleaning-preprocessing/\n",
    "# Handles Emojis\n",
    "emojis = \"\"\n",
    "\n",
    "def remove_emojis(text):\n",
    "    for emoji in emojis:\n",
    "        text = text.replace(emoji, '')\n",
    "    return text\n",
    "\n",
    "# Handles URLS\n",
    "def remove_url(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'www\\S+', '', text)    \n",
    "    return text\n",
    "\n",
    "# Handles Contractions\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
    "\n",
    "def clean_contractions(text, mapping):\n",
    "    specials = [\"\", \"\", \"\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n",
    "    return text\n",
    "\n",
    "# Handles Punctuations\n",
    "regular_punct = list(string.punctuation)\n",
    "extra_punct = [\n",
    "    ',', '.', '\"', ':', ')', '(', '!', '?', '|', ';', \"'\", '$', '&',\n",
    "    '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '',  '~', '@', '',\n",
    "    '', '_', '{', '}', '', '^', '', '`',  '<', '', '', '', '', '',\n",
    "    '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
    "    '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
    "    '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
    "    '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
    "    '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
    "    '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
    "    '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
    "\n",
    "all_punct = list(set(regular_punct + extra_punct))\n",
    "def spacing_punctuation(text):\n",
    "    for punc in all_punct:\n",
    "        if punc in text:\n",
    "            text = text.replace(punc, f' {punc} ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0035489e",
   "metadata": {},
   "source": [
    "# Enquire user to input any sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d346d5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence, and I will determine how you are feeling:I feel kind of tired\n",
      "User-Input: I feel kind of tired\n"
     ]
    }
   ],
   "source": [
    "# User Input\n",
    "token_sentence = input(\"Enter a sentence, and I will determine how you are feeling:\")\n",
    "\n",
    "print(\"User-Input:\", token_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acccdba6",
   "metadata": {},
   "source": [
    "# Preprocess User Input before passing to the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5745a93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "feel\n",
      "kind\n",
      "tired\n",
      "['I', 'feel', 'kind', 'tired']\n"
     ]
    }
   ],
   "source": [
    "# Cleans the Text\n",
    "\n",
    "token_list = []\n",
    "token_sentence = remove_emojis(token_sentence)\n",
    "token_sentence = remove_url(token_sentence)\n",
    "token_sentence = clean_contractions(token_sentence, contraction_mapping)\n",
    "token_sentence = spacing_punctuation(token_sentence)\n",
    "\n",
    "words = token_sentence.split()\n",
    "\n",
    "# Remove Stop Words from Tokenized List (removing words that don't add context)\n",
    "for word in words:\n",
    "    if word not in stopWords:\n",
    "        print(word)\n",
    "        token_list.append(word)\n",
    "\n",
    "print(token_list)\n",
    "\n",
    "token_sentence = \" \".join(str(x) for x in token_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78792eeb",
   "metadata": {},
   "source": [
    "# Pass the User-Input Sentence through the model # bhadresh-savani/distilbert-base-uncased-emotion to detect overall emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95f217ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'sadness', 'score': 0.9988258481025696}, {'label': 'joy', 'score': 0.00035554246278479695}, {'label': 'love', 'score': 0.00017273869889322668}, {'label': 'anger', 'score': 0.00028570712311193347}, {'label': 'fear', 'score': 0.0002502078714314848}, {'label': 'surprise', 'score': 0.00010984244727296755}]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\",model='bhadresh-savani/distilbert-base-uncased-emotion', return_all_scores=True)\n",
    "prediction = classifier(token_sentence, )\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62560f55",
   "metadata": {},
   "source": [
    "# Retrieve Emotion with highest score. Retrieved Emotion will be treated as the First Category of the association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42a3ee2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'sadness', 'score': 0.9988258481025696}\n"
     ]
    }
   ],
   "source": [
    "emotions = prediction[0]\n",
    "predicted_emotion = {'label': '', 'score': 0}\n",
    "\n",
    "for item in emotions:\n",
    "    \n",
    "    if  predicted_emotion['score'] < item['score']:\n",
    "        predicted_emotion = item\n",
    "\n",
    "print(predicted_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c95a1b",
   "metadata": {},
   "source": [
    "# Link to Semantic Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd49ffc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in d:\\anaconda3\\lib\\site-packages (4.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "320ee9b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'botticello', 'conceptnet', 'config', 'local']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "client.list_database_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f5727",
   "metadata": {},
   "source": [
    "# Query Conceptnet to retrieve exemplars/nouns of retrieved Emotion Category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221ff81b",
   "metadata": {},
   "source": [
    "### Connect to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2ce3dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #Regular Expression\n",
    "\n",
    "conceptnetDB = client[\"conceptnet\"] #ConceptNet DB\n",
    "edges = conceptnetDB[\"edges\"] # RELATIONSHIPS\n",
    "nodes = conceptnetDB[\"nodes\"] # EDGES\n",
    "query_format = \"/c/en/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6691dacc",
   "metadata": {},
   "source": [
    "### Retrieve Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64c4e3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadness\n"
     ]
    }
   ],
   "source": [
    "search_word = predicted_emotion['label']\n",
    "print(search_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c94ca0",
   "metadata": {},
   "source": [
    "### Define Dictionary to hold Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2c2c6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emotion': 'sadness', 'destination_features': [], 'source_features': []}\n"
     ]
    }
   ],
   "source": [
    "emotionfeatures = dict(emotion=search_word, destination_features=[], source_features=[])\n",
    "print(emotionfeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb9bef7",
   "metadata": {},
   "source": [
    "### Query ConceptNet to retrieve Features of retrieved emotion (1st Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3db71b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " /c/en/sadness\n",
      "<pymongo.cursor.Cursor object at 0x0000019F5AABEDF0>\n",
      "\n",
      "Retrieved Property: {'emotion': 'sadness', 'destination_features': ['blue', 'blues', 'cry', 'depression', 'depressive_disorder', 'despair', 'disappointment', 'dolefulness', 'downheartedness', 'dump', 'forlornness', 'frown', 'frown', 'gloom', 'grief', 'heaviness', 'lament', 'melancholic', 'melancholy', 'melancholy', 'melancholy', 'misery', 'moroseness', 'sigh', 'sob', 'sorrow', 'unhappiness', 'woe', 'woe'], 'source_features': []}\n"
     ]
    }
   ],
   "source": [
    "# Filter Pattern to only retrieve English Elements\n",
    "filterStr = '/c/en/'\n",
    "\n",
    "# Create the query with proper format w/ the Negative_Feature retrieved.\n",
    "query = query_format + search_word\n",
    "print('\\n',query)\n",
    "    \n",
    "# Pre-Processing below does Stemming for ConceptNet. Basically if the word doesn't exist, remove a character.\n",
    "cursor = nodes.find({\"_id\": query})\n",
    "\n",
    "if(len(cursor[0]) > 0):\n",
    "    \n",
    "    # In the case there is no destination node, keep deleting characters and search again until there is a destination node.\n",
    "    while('isd' not in cursor[0]):\n",
    "        query = query[:-1]\n",
    "        cursor = nodes.find({\"_id\": query})\n",
    "        if(len(query) == 0):\n",
    "            break\n",
    "\n",
    "    print(cursor)\n",
    "\n",
    "    # compile regular expression to match any query with '/c/en' when querying MongoDB\n",
    "    r = re.compile(\".*/c/en/\")\n",
    "\n",
    "    # Retrieve the relations & features.\n",
    "    for doc in cursor: \n",
    "        \n",
    "\n",
    "        # HAS-PROPERTY\n",
    "        \n",
    "        # Destination Node\n",
    "        hasPropertyIsd = doc.get('isd').get('/r/RelatedTo')\n",
    "        \n",
    "        # Checks if Destination Node is empty\n",
    "        if(hasPropertyIsd is not None):\n",
    "            #hasPropertyEn.append(list(filter(r.match, hasProperty)))\n",
    "            for featureIsd in hasPropertyIsd:\n",
    "               \n",
    "                if(filterStr in featureIsd):\n",
    "                    retrieved_feature = featureIsd.split('/')\n",
    "                    \n",
    "                    if(retrieved_feature[3] in nouns):\n",
    "                        emotionfeatures['destination_features'].append(retrieved_feature[3])\n",
    "       \n",
    "        \n",
    "        \n",
    "        # Source Node\n",
    "        hasPropertyIss = doc.get('iss').get('/r/RelatedTo')\n",
    "        \n",
    "        # Checks if Source Node is empty\n",
    "        if(hasPropertyIss is not None):\n",
    "            #hasPropertyEn.append(list(filter(r.match, hasProperty)))\n",
    "            for featureIss in hasPropertyIss:\n",
    "                if(filterStr in featureIss):\n",
    "                    \n",
    "                    retrieved_feature = featureIss.split('/')\n",
    "                    if(retrieved_feature[3] in nouns):\n",
    "                        emotionfeatures['source_features'].append(retrieved_feature[3])\n",
    "                    \n",
    "                    \n",
    "            \n",
    "        \n",
    "        \n",
    " \n",
    "print('\\nRetrieved Property:', emotionfeatures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f82b33",
   "metadata": {},
   "source": [
    "# Query ConceptNet to retrieve features of the 2nd Category set by User."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94278174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'second_exemplar': 'weather', 'destination_features': [], 'source_features': []}\n"
     ]
    }
   ],
   "source": [
    "exemplarfeatures = dict(second_exemplar=exemplar, destination_features=[], source_features=[])\n",
    "print(exemplarfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe092c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " /c/en/weather\n",
      "<pymongo.cursor.Cursor object at 0x0000019F316E54C0>\n",
      "\n",
      "Retrieved Property: {'second_exemplar': 'weather', 'destination_features': ['baking', 'break', 'brunt', 'camber', 'carol', 'clear', 'clemency', 'climate', 'cloud', 'coat', 'cold', 'cold_frame', 'cold_wave', 'convection', 'cyclone', 'elements', 'exposure', 'fair', 'fair_weather', 'fine', 'flash', 'fog', 'foglamp', 'freeze', 'frontal', 'frost', 'growing_season', 'grus', 'hail', 'heat', 'heat_wave', 'heaven', 'hot_spell', 'hovel', 'hurricane', 'indra', 'isogon', 'jacket', 'luff', 'meteorology', 'mist', 'news', 'nip', 'rain', 'saprolite', 'serve', 'slip', 'snow', 'storm', 'storm', 'summer', 'temperature', 'thaw', 'thermometer', 'thunder', 'tornado', 'typhoon', 'typhoon', 'umbrella', 'vane', 'washboard', 'weather_forecast', 'weatherglass', 'wetness', 'whiteout', 'wind', 'windshield', 'winter'], 'source_features': ['action', 'activity', 'air', 'atmosphere', 'atmospheric_phenomenon', 'bad', 'boring', 'change', 'channel', 'circumstances', 'climate', 'cloud', 'cold', 'cold_front', 'collective', 'condition', 'conditions', 'current', 'daily', 'day', 'description', 'effects', 'elements', 'environment', 'fog', 'forecaster', 'four', 'front', 'general', 'hail', 'happening', 'humidity', 'hurricane', 'lightning', 'like', 'local', 'meteorology', 'name', 'natural', 'natural_phenomenon', 'news', 'nice', 'now', 'outdoors', 'outside', 'overall', 'overcast', 'pattern', 'phenomenon', 'precipitation', 'prediction', 'program', 'rain', 'report', 'season', 'segment', 'sky', 'sleet', 'snow', 'spring', 'state', 'storm', 'study', 'summer', 'sun', 'sunlight', 'system', 'temperature', 'term', 'thunder', 'time', 'today', 'type', 'wind', 'winter']}\n"
     ]
    }
   ],
   "source": [
    "# Filter Pattern to only retrieve English Elements\n",
    "filterStr = '/c/en/'\n",
    "\n",
    "# Create the query with proper format w/ the Negative_Feature retrieved.\n",
    "query = query_format + exemplar\n",
    "print('\\n',query)\n",
    "    \n",
    "# Pre-Processing below does Stemming for ConceptNet. Basically if the word doesn't exist, remove a character.\n",
    "cursor = nodes.find({\"_id\": query})\n",
    "\n",
    "if(len(cursor[0]) > 0):\n",
    "    \n",
    "    # In the case there is no destination node, keep deleting characters and search again until there is a destination node.\n",
    "    while('isd' not in cursor[0]):\n",
    "        query = query[:-1]\n",
    "        cursor = nodes.find({\"_id\": query})\n",
    "        if(len(query) == 0):\n",
    "            break\n",
    "\n",
    "    print(cursor)\n",
    "\n",
    "    # compile regular expression to match any query with '/c/en' when querying MongoDB\n",
    "    r = re.compile(\".*/c/en/\")\n",
    "\n",
    "    # Retrieve the relations & features.\n",
    "    for doc in cursor: \n",
    "        \n",
    "\n",
    "        # HAS-PROPERTY\n",
    "        \n",
    "        # Destination Node\n",
    "        hasPropertyIsd = doc.get('isd').get('/r/RelatedTo')\n",
    "        \n",
    "        # Checks if Destination Node is empty\n",
    "        if(hasPropertyIsd is not None):\n",
    "            #hasPropertyEn.append(list(filter(r.match, hasProperty)))\n",
    "            for featureIsd in hasPropertyIsd:\n",
    "               \n",
    "                if(filterStr in featureIsd):\n",
    "                    \n",
    "                    retrieved_feature = featureIsd.split('/')\n",
    "                    if(retrieved_feature[3] in nouns):\n",
    "                        exemplarfeatures['destination_features'].append(retrieved_feature[3])\n",
    "       \n",
    "        \n",
    "        \n",
    "        # Source Node\n",
    "        hasPropertyIss = doc.get('iss').get('/r/RelatedTo')\n",
    "        \n",
    "        # Checks if Source Node is empty\n",
    "        if(hasPropertyIss is not None):\n",
    "            #hasPropertyEn.append(list(filter(r.match, hasProperty)))\n",
    "            for featureIss in hasPropertyIss:\n",
    "                if(filterStr in featureIss):\n",
    "                    \n",
    "                    retrieved_feature = featureIss.split('/')\n",
    "                    if(retrieved_feature[3] in nouns):\n",
    "                        exemplarfeatures['source_features'].append(retrieved_feature[3])\n",
    "        \n",
    "        \n",
    " \n",
    "print('\\nRetrieved Property:', exemplarfeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a01de3",
   "metadata": {},
   "source": [
    "# Fuzzy Matching Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7847e678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplar to compare to: weather\n",
      "Input-Sentence I feel kind tired\n",
      "Emotion Detected: sadness\n",
      "No of Features to Compare: 30\n"
     ]
    }
   ],
   "source": [
    "# Features Set by User.\n",
    "\n",
    "print('Exemplar to compare to:', exemplar)\n",
    "print('Input-Sentence', token_sentence)\n",
    "print('Emotion Detected:', predicted_emotion['label'])\n",
    "print('No of Features to Compare:', criterionQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b3d3f",
   "metadata": {},
   "source": [
    "# Collect all the Properties for Fuzzy Matching of each Exemplar of retrieved Emotion Category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d194e336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "[{'emotion_feature': 'blue', 'feature_properties': ['altostratus', 'azure', 'azure', 'balloon_flower', 'berry', 'blow', 'blue_moon', 'bluefin', 'bluepoint', 'blues', 'bluestone', 'bluing', 'bluing', 'calypso', 'cloud', 'color', 'convergence', 'cornflower', 'cross', 'cyan', 'cyanosis', 'day', 'delphinium', 'earth', 'error', 'eye', 'factory', 'farmer', 'ferricyanide', 'ferrocyanide', 'first', 'flag', 'green', 'indigo', 'indigo_bunting', 'ink', 'lake', 'lapis_lazuli', 'lapis_lazuli', 'larkspur', 'litmus_paper', 'magenta', 'mold', 'navy', 'navy', 'night', 'ocean', 'orchid', 'ozone', 'plan', 'pornography', 'powder_blue', 'powder_blue', 'purple', 'raspberry', 'rhapsody', 'river', 'roller', 'royal', 'safranine', 'sapphire', 'sapphire', 'sea', 'shock', 'shoe', 'sky', 'smoke', 'steel_blue', 'steel_blue', 'stilton', 'suede', 'tritanopia', 'turquoise', 'ultramarine', 'vein', 'velvet', 'violet', 'vishnu', 'visible_spectrum', 'water', 'yellow', 'aquamarine', 'associate', 'azure', 'baby', 'basic', 'berry', 'boy', 'bruise', 'clear', 'clothing', 'cobalt', 'color', 'colors', 'cool', 'cyan', 'dark', 'depression', 'egg', 'emotion', 'eye', 'feeling', 'fifth', 'flag', 'flute', 'green', 'havasupai', 'hue', 'indigo', 'light', 'like', 'main', 'moo', 'mood', 'navy', 'ocean', 'orange', 'painting', 'pizza', 'primary', 'primary_color', 'prime', 'purple', 'rainbow', 'red', 'royal', 'sadness', 'sea', 'shade', 'shoe', 'short', 'sky', 'teal', 'turquoise', 'violet', 'water', 'wavelength', 'white', 'windows', 'yellow', 'yellow_green']}, {'emotion_feature': 'blues', 'feature_properties': ['americana', 'barrelhouse', 'blue', 'blue_note', 'bluegrass', 'color', 'country_music', 'dejection', 'depressive_disorder', 'jazz', 'music', 'pad', 'rhythm_and_blues', 'rockabilly', 'roll', 'skiffle']}, {'emotion_feature': 'cry', 'feature_properties': ['baa', 'baa', 'baby', 'banzai', 'banzai', 'bleat', 'bray', 'bubble', 'bugle', 'call', 'call', 'caterwaul', 'caw', 'charge', 'cheer', 'chorus', 'clamor', 'crier', 'croak', 'crying', 'eye', 'fly', 'fuss', 'gale', 'geronimo', 'geronimo', 'grizzle', 'hoot', 'hosanna', 'howl', 'howl', 'hue', 'lamentation', 'loon', 'meow', 'neigh', 'neigh', 'onion', 'roar', 'roar', 'scream', 'sky', 'snivel', 'sob', 'sob', 'squall', 'surrender', 'tear', 'tearjerker', 'waterworks', 'whimper', 'whoop', 'why', 'act', 'action', 'activity', 'baby', 'behavior', 'being', 'call', 'communication', 'complaint', 'crocodile_tears', 'depression', 'despair', 'display', 'displeasure', 'do', 'dripping', 'emotion', 'emotional_state', 'exclamation', 'express', 'expression', 'eye', 'eyes', 'face', 'feeling', 'fluid', 'fly', 'form', 'generation', 'give', 'happening', 'hue', 'lament', 'laugh', 'like', 'liquid', 'making', 'message', 'moisture', 'noise', 'outburst', 'pain', 'person', 'pleading', 'pout', 'process', 'produce', 'production', 'rain', 'reaction', 'red', 'release', 'response', 'result', 'sadness', 'scream', 'secretion', 'see', 'shed', 'shedding', 'shy', 'signal', 'sky', 'sob', 'sorrow', 'state', 'sufferance', 'tear', 'unhappiness', 'upset', 'utterance', 'wailing', 'water', 'watering', 'week', 'wetness', 'whimper', 'why']}, {'emotion_feature': 'depression', 'feature_properties': ['adolescence', 'analeptic', 'angst', 'anticyclone', 'antidepressant', 'bankruptcy', 'basin', 'bialy', 'bipolar_disorder', 'blahs', 'blue', 'blues', 'bosom', 'brucellosis', 'cavity', 'cirque', 'clomipramine', 'crash', 'crater', 'cry', 'cyclothymia', 'damp', 'dejection', 'depressive', 'depressive', 'depressive_disorder', 'desipramine', 'despondency', 'detention_basin', 'dimple', 'dimple', 'dysphoria', 'escutcheon', 'fossa', 'funk', 'glen', 'gloom', 'groin', 'groove', 'hibernation', 'hilum', 'horror', 'hypo', 'imipramine', 'impression', 'indentation', 'kettle_hole', 'lacuna', 'loneliness', 'low', 'malaise', 'melancholic', 'melancholy', 'melancholy', 'melancholy', 'nervous_breakdown', 'nortriptyline', 'overcast', 'pan', 'pip', 'profile', 'reboxetine', 'resilience', 'scrape', 'serotonin', 'sink', 'slot', 'slouch', 'slough', 'soak', 'stop', 'swag', 'swale', 'thesis', 'thioridazine', 'valley', 'valley', 'wallow', 'well', 'bad', 'condition', 'deep', 'disease', 'downturn', 'economics', 'great', 'illness', 'market', 'medication', 'mental_illness', 'problem', 'sadness', 'stock', 'upset']}, {'emotion_feature': 'depressive_disorder', 'feature_properties': []}, {'emotion_feature': 'despair', 'feature_properties': ['cold_sweat', 'cry', 'desperate', 'desperation', 'despondency', 'hopelessness', 'woe', 'deep', 'emotion', 'hopelessness', 'poetry', 'sadness']}, {'emotion_feature': 'disappointment', 'feature_properties': ['anger', 'balk', 'bummer', 'chagrin', 'comedown', 'discomfiture', 'frost', 'heartbreaker', 'sell', 'sink', 'washout']}, {'emotion_feature': 'dolefulness', 'feature_properties': []}, {'emotion_feature': 'downheartedness', 'feature_properties': []}, {'emotion_feature': 'dump', 'feature_properties': ['cat', 'chuck', 'slop', 'tip', 'tip', 'trash', 'waste', 'break', 'garbage', 'inside', 'repository', 'trash']}, {'emotion_feature': 'forlornness', 'feature_properties': ['loneliness']}, {'emotion_feature': 'frown', 'feature_properties': ['crowd', 'expression', 'lowering', 'smile', 'disapproval', 'down', 'emotion', 'expression', 'facial', 'facial_expression', 'sadness', 'smile']}, {'emotion_feature': 'frown', 'feature_properties': ['crowd', 'expression', 'lowering', 'smile', 'disapproval', 'down', 'emotion', 'expression', 'facial', 'facial_expression', 'sadness', 'smile']}, {'emotion_feature': 'gloom', 'feature_properties': ['darkness', 'evening', 'melancholia', 'shadow', 'dark', 'darkness', 'depression', 'doom', 'sadness']}, {'emotion_feature': 'grief', 'feature_properties': ['adversity', 'care', 'dole', 'dolor', 'grievance', 'heartbreaker', 'lament', 'morning', 'nepenthes', 'sigh', 'site', 'smart', 'sorrow', 'thanatology', 'woe', 'grievance', 'sadness']}, {'emotion_feature': 'heaviness', 'feature_properties': ['avoirdupois', 'gravity', 'heft', 'mass', 'weight']}, {'emotion_feature': 'lament', 'feature_properties': ['cry', 'funeral_march', 'hone', 'howl', 'jeremiad', 'lamentation', 'lamentations', 'mean', 'plain', 'plaint', 'sigh', 'wailer', 'woe', 'sorrow']}, {'emotion_feature': 'melancholic', 'feature_properties': ['blue', 'depressive', 'gloom', 'longing', 'melancholia', 'melancholy', 'moped', 'pensiveness']}, {'emotion_feature': 'melancholy', 'feature_properties': ['black', 'black_bile', 'brown_study', 'dejection', 'downcast', 'dump', 'homesickness', 'melancholia', 'melancholic', 'melancholic', 'overcast', 'sigh', 'temper', 'deep', 'depression', 'feeling', 'melancholic', 'mood', 'sadness', 'sorrow']}, {'emotion_feature': 'melancholy', 'feature_properties': ['black', 'black_bile', 'brown_study', 'dejection', 'downcast', 'dump', 'homesickness', 'melancholia', 'melancholic', 'melancholic', 'overcast', 'sigh', 'temper', 'deep', 'depression', 'feeling', 'melancholic', 'mood', 'sadness', 'sorrow']}, {'emotion_feature': 'melancholy', 'feature_properties': ['black', 'black_bile', 'brown_study', 'dejection', 'downcast', 'dump', 'homesickness', 'melancholia', 'melancholic', 'melancholic', 'overcast', 'sigh', 'temper', 'deep', 'depression', 'feeling', 'melancholic', 'mood', 'sadness', 'sorrow']}, {'emotion_feature': 'misery', 'feature_properties': ['aggravation', 'bane', 'company', 'dolor', 'gall', 'living_death', 'ruth', 'sufferance', 'woe', 'bad', 'company', 'emotion', 'sadness', 'suffering', 'unhappiness', 'woe']}, {'emotion_feature': 'moroseness', 'feature_properties': ['doggedness']}, {'emotion_feature': 'sigh', 'feature_properties': ['gasp', 'home', 'huff', 'night', 'pant', 'sob', 'society', 'air', 'breath', 'breathing', 'deep', 'exhalation', 'expression', 'gasp', 'love', 'melancholy', 'out', 'sadness', 'whisper']}, {'emotion_feature': 'sob', 'feature_properties': ['cry', 'snub', 'whimper', 'action', 'boss', 'cry', 'crying', 'deep', 'emotion', 'heavy', 'like', 'one', 'sadness', 'sigh']}, {'emotion_feature': 'sorrow', 'feature_properties': ['care', 'commiseration', 'cry', 'dole', 'dolor', 'emotion', 'evil', 'grief', 'heartbreaker', 'lament', 'lament', 'melancholy', 'mourning', 'pain', 'pang', 'pathos', 'penance', 'penitent', 'rue', 'rue', 'ruth', 'shock', 'site', 'sympathy', 'deep', 'emotion', 'feeling', 'sadness']}, {'emotion_feature': 'unhappiness', 'feature_properties': ['cry', 'depression', 'dissatisfaction', 'misery', 'misery', 'sorrow', 'sadness']}, {'emotion_feature': 'woe', 'feature_properties': ['bale', 'misery', 'misery', 'sorrow', 'despair', 'distress', 'grief', 'lament', 'misery', 'sadness', 'suffering']}, {'emotion_feature': 'woe', 'feature_properties': ['bale', 'misery', 'misery', 'sorrow', 'despair', 'distress', 'grief', 'lament', 'misery', 'sadness', 'suffering']}]\n"
     ]
    }
   ],
   "source": [
    "# Collects all the features of each em_feature\n",
    "em_features_collection = []\n",
    "\n",
    "all_emotion_features = emotionfeatures['destination_features'] + emotionfeatures['source_features']\n",
    "\n",
    "#print(emotionfeatures['destination_features'])\n",
    "#print(emotionfeatures['source_features'])\n",
    "\n",
    "#Loop through each feature of the emotion\n",
    "for em_feature in all_emotion_features:\n",
    "    \n",
    "    # Dict for em_feature\n",
    "    em_features = dict(emotion_feature = em_feature, feature_properties = [])\n",
    "    \n",
    "    \n",
    "    # Retrieve features of said em_feature\n",
    "    query = '/c/en/' + em_feature\n",
    "\n",
    "    # Pre-Processing below does Stemming for ConceptNet. Basically if the word doesn't exist, remove a character.\n",
    "    cursor = nodes.find({\"_id\": query})\n",
    "    \n",
    "    # Checks if cursor is not empty\n",
    "    if(len(cursor[0]) > 0):\n",
    "\n",
    "\n",
    "            # Destination Node 'isd'\n",
    "            \n",
    "            # Checks if '/r/RelatedTo' exists in the node\n",
    "            \n",
    "            # Checks if Destination Node exists\n",
    "            if('isd' in cursor[0]):\n",
    "                em_feature_isd = cursor[0]['isd']\n",
    "            \n",
    "                if ('/r/RelatedTo' in em_feature_isd.keys() and em_feature_isd is not None):\n",
    "                    hasPropertyIsd = em_feature_isd.get('/r/RelatedTo')\n",
    "\n",
    "                    # Checks if Destination Node is empty\n",
    "                    if(hasPropertyIsd is not None):\n",
    "\n",
    "                        for featureIsd in hasPropertyIsd:\n",
    "\n",
    "                            if(filterStr in featureIsd):\n",
    "                                \n",
    "                                retrieved_feature = featureIsd.split('/')\n",
    "                                \n",
    "                                # Check if retrieved feature is part of dictionary.\n",
    "                                #if(retrieved_feature[3] in words.words()):\n",
    "                                if(retrieved_feature[3] in nouns):\n",
    "                                    em_features['feature_properties'].append(retrieved_feature[3])\n",
    "                            \n",
    "            \n",
    "            # Checks if Source Node exists.\n",
    "            if('iss' in cursor[0]):\n",
    "                em_feature_iss = cursor[0]['iss']\n",
    "                if('/r/RelatedTo' in em_feature_iss.keys() and em_feature_iss is not None):\n",
    "                    hasPropertyIss = em_feature_iss.get('/r/RelatedTo')\n",
    "\n",
    "                    # Checks if Source Node is empty\n",
    "                    if(hasPropertyIss is not None):\n",
    "\n",
    "                        for featureIss in hasPropertyIss:\n",
    "\n",
    "                            if(filterStr in featureIss):\n",
    "                                \n",
    "                                retrieved_feature = featureIss.split('/')\n",
    "                                if(retrieved_feature[3] in nouns):\n",
    "                                    em_features['feature_properties'].append(retrieved_feature[3])\n",
    "\n",
    "                \n",
    "            em_features_collection.append(em_features)\n",
    "\n",
    "\n",
    "print(len(em_features_collection))\n",
    "print(em_features_collection)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9feea495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue\n",
      "blues\n",
      "cry\n",
      "depression\n",
      "depressive_disorder\n",
      "despair\n",
      "disappointment\n",
      "dolefulness\n",
      "downheartedness\n",
      "dump\n",
      "forlornness\n",
      "frown\n",
      "frown\n",
      "gloom\n",
      "grief\n",
      "heaviness\n",
      "lament\n",
      "melancholic\n",
      "melancholy\n",
      "melancholy\n",
      "melancholy\n",
      "misery\n",
      "moroseness\n",
      "sigh\n",
      "sob\n",
      "sorrow\n",
      "unhappiness\n",
      "woe\n",
      "woe\n"
     ]
    }
   ],
   "source": [
    "for i in em_features_collection:\n",
    "    print(i['emotion_feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710aff38",
   "metadata": {},
   "source": [
    "# Collect all the Properties for Fuzzy Matching of each Exemplar of retrieved User-Input Category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5d87e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n",
      "[{'exemplar_feature': 'baking', 'feature_properties': ['baking_powder', 'batch', 'bread', 'cake', 'cocoa_powder', 'cook', 'cookie_cutter', 'cookie_sheet', 'nutmeg', 'oil', 'oven', 'oven', 'sugar', 'tablespoon']}, {'exemplar_feature': 'break', 'feature_properties': ['bilge', 'bone', 'breach', 'breakage', 'breaker', 'breakwater', 'bridge', 'brit', 'brittle', 'brittleness', 'burst', 'bust', 'buster', 'chalcedony', 'change', 'chine', 'chip', 'chunk', 'collapse', 'colony', 'commercial', 'crack', 'cut', 'decay', 'deduction', 'dinnertime', 'discontinuity', 'division', 'dough', 'drag', 'dump', 'escape', 'fill', 'fix', 'flaw', 'force', 'fracture', 'fragment', 'frail', 'giving', 'glide', 'habit', 'hatch', 'hiatus', 'icebreaker', 'intermission', 'intermission', 'interval', 'law', 'leak', 'lunch', 'lunch', 'morning', 'overlap', 'pause', 'pierce', 'play', 'playoff', 'puncture', 'ram', 'recess', 'rest', 'rift', 'ripple', 'roller', 'ruin', 'rule', 'rupture', 'safebreaker', 'safety_glass', 'salvo', 'semester', 'smash', 'snap', 'snap', 'snap', 'spelt', 'splinter', 'stave', 'stay', 'stretch', 'stuff', 'sucker', 'take', 'tea', 'tear', 'vacation', 'weekender', 'wound', 'accident', 'accidental', 'action', 'actress', 'bad', 'bone', 'bones', 'bust', 'car', 'chocolate', 'cigarette', 'class', 'coffee', 'crack', 'crush', 'damage', 'dance', 'destruction', 'dis', 'discovery', 'dish', 'division', 'fall', 'fifteen', 'first', 'five', 'fracture', 'gap', 'glass', 'half', 'hit', 'hole', 'hour', 'injury', 'intermission', 'interrupt', 'interruption', 'interval', 'kind', 'leg', 'like', 'lunch', 'lunchtime', 'meal', 'mend', 'minutes', 'out', 'past', 'pause', 'pedal', 'period', 'present', 'problem', 'pull', 'purpose', 'recess', 'respite', 'rest', 'ruin', 'school', 'separate', 'separation', 'short', 'siesta', 'smash', 'smashing', 'smoke', 'snap', 'split', 'sprain', 'spring', 'stop', 'stopper', 'stopping', 'summer', 'take', 'tear', 'ten', 'time', 'time_off', 'trauma', 'two', 'vacation', 'wait', 'work', 'working', 'wreck']}, {'exemplar_feature': 'brunt', 'feature_properties': []}, {'exemplar_feature': 'camber', 'feature_properties': ['set']}, {'exemplar_feature': 'carol', 'feature_properties': ['caroling', 'carroll', 'christmas', 'cold', 'cold_weather', 'name', 'song', 'sung', 'time', 'weather']}, {'exemplar_feature': 'clear', 'feature_properties': ['acetic_acid', 'air', 'blue', 'breach', 'broad', 'bus', 'busboy', 'bushwhacker', 'card', 'clarification', 'clarinet', 'clarity', 'clearing', 'clearing', 'collodion', 'crystal', 'cue', 'definition', 'diamond', 'drink', 'enunciation', 'evacuation', 'extractor', 'foul', 'gangway', 'gin', 'glass', 'glass', 'ice', 'imagism', 'kite', 'latex', 'leer', 'net', 'open', 'payment', 'perchloric_acid', 'plain', 'print', 'purge', 'rain', 'ringing', 'river', 'rock_crystal', 'salt', 'slash', 'slash', 'snot', 'tape', 'vitreous_humor', 'vodka', 'waffle', 'water', 'wax', 'whisker', 'wind', 'window', 'windshield_wiper', 'action', 'adjective', 'clarity', 'color', 'concept', 'condition', 'crystal', 'day', 'description', 'empty', 'glass', 'good', 'like', 'making', 'nice', 'nothing', 'perception', 'see', 'sense', 'shampoo', 'sky', 'transparency', 'visibility', 'water', 'weather', 'weather_forecast', 'window', 'windows']}, {'exemplar_feature': 'clemency', 'feature_properties': ['grant', 'judges']}, {'exemplar_feature': 'climate', 'feature_properties': ['climatology', 'cline', 'cold', 'control', 'decline', 'desert', 'desertification', 'dieback', 'dry', 'greenhouse', 'heat', 'heaven', 'oligocene', 'paleocene', 'summer', 'torrid_zone', 'weather', 'climate_change']}, {'exemplar_feature': 'cloud', 'feature_properties': ['altocumulus', 'altostratus', 'arcus', 'atom', 'bank', 'brewing', 'cataract', 'cirrostratus', 'cirrus', 'climate_change', 'clouding', 'cloudlessness', 'clutter', 'coma', 'contrail', 'convection', 'cotton', 'cumulus', 'fog', 'fog', 'haze', 'heaven', 'kachina', 'lightning', 'mackerel_sky', \"mare's_tail\", 'messenger', 'meteor', 'mist', 'nebula', 'nebule', 'nephoscope', 'nimbus', 'overcast', 'overcast', 'pallium', 'plume', 'precipitation', 'rain', 'rain', 'rainmaking', 'rift', 'scud', 'seeder', 'sheep', 'silver', 'sky', 'sky', 'smoke', 'sneeze', 'stardust', 'steam', 'stratus', 'swarm', 'thunder', 'thunderhead', 'tornado', 'tornado', 'vapor', 'weather', 'white', 'above', 'air', 'apparatus', 'appearance', 'atmosphere', 'atmospheric_phenomenon', 'ball', 'bearer', 'billow', 'blemish', 'blocker', 'blue', 'bubble', 'candy', 'cirrus', 'color', 'component', 'condensation', 'condition', 'container', 'cotton', 'cotton_ball', 'cotton_candy', 'cover', 'cumulonimbus', 'cumulus', 'dark', 'days', 'dust', 'effect', 'element', 'feature', 'floating', 'floss', 'fluff', 'fog', 'formation', 'found', 'gathering', 'giver', 'gray', 'grey', 'haze', 'heaven', 'high', 'holder', 'home', 'inside', 'item', 'lining', 'maker', 'making', 'marshmallow', 'mass', 'mist', 'moisture', 'natural', 'nice', 'nimbus', 'nine', 'number', 'object', 'origin', 'overcast', 'phenomenon', 'pillow', 'precipitation', 'producer', 'puff', 'rain', 'shade', 'shape', 'sheep', 'sight', 'silver', 'silver_lining', 'single', 'sky', 'smoke', 'snow', 'source', 'steam', 'stuff', 'sun', 'thunder', 'vapor', 'water', 'water_vapor', 'weather', 'weather_map', 'white', 'whiteness', 'wool']}, {'exemplar_feature': 'coat', 'feature_properties': ['angora', 'apricot', 'batter', 'batter', 'bay', 'beagle', 'benjamin', 'blue', 'boat', 'bran', 'brandenburg', 'brass', 'bread', 'brigandine', 'bulldog', 'button', 'cake', 'candy', 'capote', 'cassock', 'cast', 'chinchilla', 'cloak', 'clothing', 'coatee', 'coating', 'coating', 'coattail', 'court_plaster', 'cutaway', 'dipper', 'doctor', 'dope', 'dress', 'duffel_coat', 'electroplate', 'emery', 'enamel', 'flea', 'fleece', 'flock', 'frock', 'frog', 'fur', 'fur', 'fur_coat', 'furnishing', 'gusset', 'habergeon', 'hallstand', 'hauberk', 'hemline', 'jack', 'jacket', 'lap', 'leopard', 'lint', 'locker', 'locket', 'manx', 'maxi', 'midi', 'mink', 'musk_ox', 'oiler', 'orangutan', 'paint', 'palomino', 'plaster', 'plaster', 'pocket', 'polish', 'poodle', 'prime', 'raincoat', 'roan', 'roe_deer', 'sable', 'sable', 'scale', 'seal', 'sheep', 'shellac', 'siamese_cat', 'silver_plate', 'slicker', 'smooth', 'sputter', 'stain', 'stucco', 'undercoat', 'velvet', 'virino', 'wash', 'wool', 'zoot_suit', 'animal', 'apparel', 'attire', 'boat', 'body', 'closet', 'clothing', 'cold', 'cold_weather', 'covering', 'down', 'dress', 'dressing', 'fabric', 'fur', 'garment', 'gear', 'going', 'heavy', 'hood', 'insulation', 'item', 'jacket', 'keep', 'keeping', 'large', 'layer', 'like', 'lot', 'nice', 'outdoors', 'outerwear', 'outside', 'over', 'paint', 'parka', 'people', 'prevention', 'protection', 'pull', 'rain', 'robe', 'second', 'shirt', 'suit', 'sweater', 'thickness', 'top', 'torso', 'trench', 'type', 'upper', 'vest', 'ware', 'warmth', 'waterproof', 'wear', 'weather', 'winter', 'wool']}, {'exemplar_feature': 'cold', 'feature_properties': ['antipasto', 'arctic', 'baltic', 'blood', 'brass', 'brass_monkey', 'brim', 'burn', 'calorimetry', 'carol', 'cash', 'catarrh', 'chill', 'chill', 'coat', 'cold_cuts', 'complexion', 'cool', 'cool', 'cool', 'cooler', 'cooling', 'cryoanesthesia', 'cryocautery', 'deadeye', 'degree', \"dover's_powder\", 'dressing', 'drink', 'dungeon', 'fish', 'fog', 'freeze', 'freeze', 'freeze', 'freezing_mixture', 'frieze', 'frost', 'hare', 'hay_fever', 'heat', 'ice', 'iced_coffee', 'icicle', 'injection', 'iron', 'lizard', 'lord', 'milk', 'mist', 'moon', 'napkin', 'nip', 'north', 'pilomotor_reflex', 'rain', 'refrigerant', 'refrigerator', 'reptile', 'rheum', 'shrinkage', 'sick', 'sneeze', 'snow', 'snub', 'space', 'steel', 'temperance', 'temperature', 'temperature', 'terrine', 'tin', 'trouble', 'weather', 'whale', 'wind', 'winter', 'winter', 'wool', 'chill', 'climate', 'cool', 'description', 'extra', 'feel', 'feeling', 'fire', 'heat', 'ice', 'illness', 'like', 'little', 'low', 'north', 'north_pole', 'pole', 'relative', 'sickness', 'snow', 'temp', 'temperature', 'weather', 'winter', 'zero']}, {'exemplar_feature': 'cold_frame', 'feature_properties': []}, {'exemplar_feature': 'cold_wave', 'feature_properties': []}, {'exemplar_feature': 'convection', 'feature_properties': ['cell', 'convector', 'cumulus', 'granule', 'radiation', 'reverberatory_furnace', 'troposphere', 'ultracentrifuge', 'wind', 'cloud']}, {'exemplar_feature': 'cyclone', 'feature_properties': ['anticyclone', 'anticyclone', 'bomb', 'dust_devil', 'hurricane', 'seclusion', 'tornado', 'typhoon', 'typhoon', 'wave', 'wind', 'hurricane', 'typhoon']}, {'exemplar_feature': 'elements', 'feature_properties': ['air', 'atom', 'chemistry', 'color', 'communicant', 'corporal', 'exposure', 'fire', 'oil', 'periodic_law', 'scare', 'science', 'stove', 'transactinide', 'weather']}, {'exemplar_feature': 'exposure', 'feature_properties': ['airing', 'bleach', 'bracket', 'bronze', 'bronze', 'burn', 'conspicuousness', 'craze', 'daylight', 'dodge', 'drying_oil', 'gore', 'hedge', 'heliotherapy', 'incubation_period', 'liver_spot', 'oil_paint', 'overexposure', 'pyrophorus', 'roast', 'shock', 'shot', 'steam_bath', 'sunburn', 'sunburn', 'underexposure', 'ventilation', 'wear', 'windburn', 'camera', 'film', 'photography', 'shot']}, {'exemplar_feature': 'fair', 'feature_properties': ['bazaar', 'blake', 'condition', 'cricket', 'damsel', 'fair_ball', 'fair_weather', 'fairground', 'fairness', 'justice', 'market', 'midway', 'pavilion', 'ride', 'rule', 'sideshow', 'sportsmanship', 'square', 'square_shooter', 'sucker_punch', 'trade', 'true', 'worth', 'adjective', 'amusement', 'average', 'carnival', 'celebration', 'coaster', 'college', 'color', 'country', 'countryside', 'county', 'equality', 'event', 'exhibit', 'exhibition', 'experience', 'festival', 'fifty', 'fun', 'gathering', 'good', 'grounds', 'hair', 'justice', 'light', 'like', 'party', 'play', 'roller', 'roller_coaster', 'state', 'type', 'weather']}, {'exemplar_feature': 'fair_weather', 'feature_properties': []}, {'exemplar_feature': 'fine', 'feature_properties': ['adultery', 'aphanite', 'art', 'beauty', 'boot', 'brave', 'byssus', 'cashmere', 'china', 'clarification', 'concord', 'contempt_of_court', 'cut', 'dainty', 'dance', 'detail', 'doom', 'dust', 'dust', 'edge', 'end', 'etiquette', 'filament', 'filing', 'final', 'fine_arts', 'fineness', 'finery', 'foxtail', 'ground', 'hair_stroke', 'hairsplitter', 'hairsplitting', 'ice_fog', 'imperial', 'intelligence', 'issue', 'jigsaw', 'lady', 'levy', 'lint', 'literature', 'mercer', 'mince', 'mince', 'misdemeanor', 'mist', 'needle', 'patent', 'pile', 'point', 'pollard', 'porphyry', 'purchase', 'refinement', 'rum', 'sac', 'salt', 'sand', 'sconce', 'sconce', 'silk', 'spray', 'steel_wool', 'sugar', 'tall', 'tax', 'tidy', 'time', 'tow', 'velvet', 'vernier', 'wool', 'zoysia', 'adjective', 'being', 'better', 'charge', 'condition', 'dandy', 'detail', 'driving', 'enough', 'fee', 'feeling', 'final', 'finance', 'good', 'good_weather', 'great', 'money', 'nice', 'parking', 'parking_ticket', 'payment', 'penalty', 'praise', 'punishment', 'response', 'small', 'smooth', 'status', 'surface', 'texture', 'thinness', 'ticket', 'two', 'weather']}, {'exemplar_feature': 'flash', 'feature_properties': ['blink', 'bolt', 'bone', 'card', 'fancy', 'flare', 'flasher', 'flasher', 'flashing', 'flashing', 'flicker', 'lightning', 'lightning', 'memory', 'metronome', 'pulse', 'redeye', 'report', 'scintilla', 'scintillation', 'scintillation_counter', 'snap', 'spark', 'sprue', 'synchroflash', 'thunder', 'accessory', 'action', 'adobe', 'blouse', 'brief', 'brightness', 'bulb', 'camera', 'content', 'dark', 'explosion', 'eyes', 'fast', 'flare', 'function', 'hero', 'light', 'light_bulb', 'lightening', 'lighter', 'lighting', 'lightning', 'open', 'output', 'passing', 'phenomenon', 'photograph', 'photographer', 'portable', 'quick', 'setting', 'shining', 'software', 'spark', 'speed', 'streak', 'take', 'thunder', 'torch', 'weather']}, {'exemplar_feature': 'fog', 'feature_properties': ['clearing', 'cloud', 'damp', 'drizzle', 'fogbank', 'haze', 'mist', 'offing', 'precipitation', 'rift', 'rook', 'smoke', 'steam', 'weather', 'bad', 'cloud', 'cold', 'cold_weather', 'condition', 'gray', 'ground', 'haze', 'head', 'humidity', 'london', 'low', 'mass', 'mist', 'morning', 'ocean', 'precipitation', 'sight', 'smog', 'smoke', 'steam', 'tea', 'visibility', 'water', 'weather']}, {'exemplar_feature': 'foglamp', 'feature_properties': []}, {'exemplar_feature': 'freeze', 'feature_properties': ['boil', 'cryosurgery', 'deep_freeze', 'freezing_mixture', 'frost', 'ice', 'ice_storm', 'refrigerant', 'sleet', 'snow', 'thaw', 'warp', 'cold', 'ice', 'process', 'state', 'winter']}, {'exemplar_feature': 'frontal', 'feature_properties': ['coronal_suture', 'nasion']}, {'exemplar_feature': 'frost', 'feature_properties': ['boston_cream_pie', 'carry', 'defroster', 'deposition', 'freeze', 'frosting', 'frosting', 'ice', 'meteor', 'poet', 'precipitation', 'snow', 'straw', 'buildup', 'cold', 'cold_weather', 'condensation', 'condition', 'dew', 'grass', 'ground', 'ice', 'material', 'snow', 'stuff', 'weather', 'white', 'windows', 'winter']}, {'exemplar_feature': 'growing_season', 'feature_properties': []}, {'exemplar_feature': 'grus', 'feature_properties': ['grus', 'indus', 'tucana']}, {'exemplar_feature': 'hail', 'feature_properties': ['a', 'call', 'hailstone', 'herald', 'ice', 'meteor', 'precipitation', 'rain', 'salve', 'summer', 'thunderstorm', 'weather', 'ball', 'baseball', 'golf', 'golf_ball', 'ice', 'precipitation', 'rain', 'small', 'storm', 'weather', 'worship']}, {'exemplar_feature': 'heat', 'feature_properties': ['agglomerate', 'albumin', 'ardor', 'at', 'bakelite', 'boil', 'boil', 'boiling', 'brazier', 'bread', 'brew', 'british_thermal_unit', 'burn', 'burn', 'burn', 'burner', 'calorimeter', 'calorimetry', 'cerate', 'chafe', 'charcoal', 'clothing', 'coal', 'cold', 'cold', 'coldness', 'combustion', 'conduction', 'conductor', 'convection', 'convector', 'cook', 'cooking', 'cool', 'coolant', 'craze', 'crown', 'decalescence', 'decrepitation', 'degree', 'desert', 'diathermy', 'digestion', 'dissipation', 'dissociation', 'dryer', 'energy', 'etna', 'fire', 'fire', 'forge', 'forge', 'freezing_mixture', 'frigidity', 'furnace', 'furnace', 'furnace', 'fusion', 'generator', 'geothermal_energy', 'greenhouse', 'grill', 'heat_pump', 'heater', 'heating', 'heating', 'hot_flash', 'hot_pepper', 'imponderable', 'iron', 'joule', 'lamp', 'lid', 'memory', 'metallurgy', 'mull', 'nuclear_reactor', 'oestrus', 'oil', 'oven', 'passion', 'perm', 'permanent_wave', 'place_mat', 'pressurized_water_reactor', 'promise', 'pyrex', 'pyrolysis', 'radiomicrometer', 'reflector', 'refraction', 'refrigeration', 'repechage', 'retort', 'reverberatory_furnace', 'salmon', 'salt', 'scald', 'scorch', 'shade', 'soak', 'soup', 'spontaneous_combustion', 'steam', 'stove', 'stove', 'stove', 'street', 'summer', 'sun', 'sunburn', 'temper', 'temperance', 'temperature', 'therm', 'therm', 'thermal', 'thermal', 'thermal_printer', 'thermoacidophile', 'thermocautery', 'thermocoagulation', 'thermodynamics', 'thermoelectricity', 'thermography', 'thermometer', 'thermotherapy', 'trial', 'vitrification', 'warmth', 'warmth', 'weld', 'action', 'adjective', 'africa', 'air', 'anti', 'basketball', 'basketball_team', 'beat', 'being', 'body', 'boil', 'boiling', 'calorie', 'candle', 'climate', 'cold', 'coldness', 'color', 'condition', 'cook', 'cooking', 'dead', 'description', 'desert', 'energy', 'extreme', 'feel', 'feeling', 'felt', 'fever', 'fire', 'fireplace', 'flatulence', 'food', 'form', 'friction', 'fuel', 'function', 'furnace', 'gas', 'general', 'generic', 'high', 'hot_weather', 'hotness', 'infrared', 'level', 'like', 'maker', 'making', 'means', 'measure', 'measurement', 'meat', 'miami', 'microwave', 'much', 'nice', 'ninety', 'nothing', 'output', 'oven', 'people', 'physical_property', 'power', 'preparation', 'product', 'property', 'purpose', 'quality', 'radiance', 'radiant_energy', 'radiation', 'radiator', 'reason', 'red', 'sensation', 'setting', 'son', 'state', 'steam', 'stove', 'stroke', 'study', 'summer', 'sun', 'survival', 'team', 'temp', 'temperature', 'term', 'thermal', 'thermodynamics', 'thermostat', 'time', 'transfer', 'turn', 'value', 'warmth', 'water', 'wave', 'weather']}, {'exemplar_feature': 'heat_wave', 'feature_properties': ['hot_spell']}, {'exemplar_feature': 'heaven', 'feature_properties': ['above', 'ascension', 'assumption', 'bed', 'cloud', 'earth', 'ether', 'glorification', 'god', 'goddess', 'harp', 'john', 'kingdom_come', 'limbo', 'midgard', 'nammu', 'paradise', 'paradise', 'promised_land', 'purgatory', 'purgatory', 'real_world', 'saint', 'salvation', 'sky', 'sky', 'soul', 'translation', 'upstairs', 'utopia', 'above', 'afterlife', 'air', 'angel', 'belief', 'bible', 'christian', 'cloud', 'death', 'destination', 'die', 'earth', 'eden', 'fairy', 'gates', 'god', 'good', 'haven', 'hell', 'high', 'holy_place', 'home', 'honey', 'house', 'jesus', 'life', 'lord', 'nirvana', 'palace', 'paradise', 'pearl', 'place', 'purgatory', 'refuge', 'religion', 'religious', 'saint', 'sanctuary', 'sky', 'sweet', 'theist', 'there', 'universe', 'white']}, {'exemplar_feature': 'hot_spell', 'feature_properties': ['heat']}, {'exemplar_feature': 'hovel', 'feature_properties': ['crib', 'hole', 'shed']}, {'exemplar_feature': 'hurricane', 'feature_properties': ['anticyclone', 'cyclone', 'depression', 'disaster', 'dust_devil', 'eye', 'landfall', 'monsoon', 'storm', 'storm', 'tornado', 'typhoon', 'typhoon', 'typhoon', 'weather', 'wind', 'wind', 'cyclone', 'destruction', 'disaster', 'event', 'florida', 'force', 'gale', 'high', 'natural', 'ocean', 'rain', 'storm', 'tornado', 'water', 'weather', 'wind']}, {'exemplar_feature': 'indra', 'feature_properties': ['surya', 'vajra', 'vali']}, {'exemplar_feature': 'isogon', 'feature_properties': ['agonic_line', 'isogonic_line']}, {'exemplar_feature': 'jacket', 'feature_properties': ['album', 'blazer', 'blouse', 'bolero', 'bullet', 'camisole', 'clothing', 'coat', 'collar', 'cover', 'dolman', 'doublet', 'down', 'fleece', 'fleece', 'garibaldi', 'hood', 'jerkin', 'jumper', 'kangaroo', 'kirtle', 'norfolk_jacket', 'overcoat', 'parka', 'sack', 'sleeve', 'sleeve', 'slicker', 'slop', 'sontag', 'stomacher', 'straitjacket', 'suit', 'suit', 'sweater', 'tweed', 'vest', 'windjammer', 'wool', 'body', 'chest', 'clothing', 'coat', 'cover', 'covering', 'front', 'garment', 'jumper', 'keeping', 'leather', 'light', 'man', 'outerwear', 'potato', 'rain', 'short', 'small', 'sweatshirt', 'upper', 'vest', 'warmth', 'wear', 'weather', 'winter']}, {'exemplar_feature': 'luff', 'feature_properties': ['cunningham', 'gaff_topsail', 'leech', 'staysail']}, {'exemplar_feature': 'meteorology', 'feature_properties': ['aerology', 'aerology', 'agronomy', 'earth_science', 'geophysics', 'meteor', 'meteoroid', 'meteorologist', 'rain_gauge', 'spring', 'weather', 'aerology', 'beaufort_scale', 'rainbow']}, {'exemplar_feature': 'mist', 'feature_properties': ['cloud', 'cloud_chamber', 'dew', 'drizzle', 'drizzle', 'fog', 'fog', 'gauze', 'gauze', 'haze', 'mister', 'plume', 'rift', 'rook', 'smoke', 'sneeze', 'snow', 'spray', 'spray', 'steam', 'vapor', 'vaporizer', 'aerosol', 'air', 'atmosphere', 'avon', 'breeze', 'cloud', 'cloudiness', 'cold', 'condensation', 'condition', 'cool', 'damp', 'dew', 'do', 'drizzle', 'english', 'faint', 'feel', 'fine', 'fine_spray', 'floating', 'fog', 'forest', 'grey', 'ground', 'harbor', 'haze', 'heavy', 'inside', 'light', 'lightweight', 'like', 'liquid', 'list', 'london', 'low', 'maid', 'moisture', 'morning', 'nice', 'night', 'ocean', 'over', 'particle', 'precipitation', 'rain', 'romantic', 'scotch', 'scottish', 'sea', 'sierra', 'small', 'smog', 'smoke', 'spray', 'steam', 'street', 'type', 'vapor', 'veil', 'water', 'water_vapor', 'waterfall', 'watering', 'weather', 'wetness', 'white']}, {'exemplar_feature': 'news', 'feature_properties': ['article', 'beat', 'break', 'brief', 'bulletin', 'column', 'correspondent', 'current', 'fact', 'feed', 'good_word', 'herald', 'history', 'hook', 'journalism', 'latest', 'local', 'local', 'magazine', 'news_agency', 'newscast', 'newscaster', 'newspaper', 'newspaper', 'newsreel', 'paper', 'post', 'press', 'print', 'propagator', 'report', 'reporter', 'roundup', 'scoop', 'sidebar', 'skeet', 'sound_bite', 'sportscast', 'story', 'syndication', 'think_piece', 'trouble', 'weather', 'word', 'affairs', 'affiliate', 'anagram', 'anchor', 'announcement', 'announcer', 'article', 'bad', 'boring', 'broadcast', 'bulletin', 'category', 'channel', 'chicago', 'clock', 'coffee', 'communication', 'content', 'contents', 'current', 'daily', 'date', 'day', 'days', 'east', 'election', 'evening', 'event', 'few', 'five', 'fodder', 'fox', 'freshness', 'giving', 'gossip', 'grey', 'happening', 'headline', 'information', 'jew', 'journal', 'journalism', 'journalist', 'latest', 'line', 'local', 'magazine', 'major', 'man', 'mass', 'material', 'morning', 'national', 'network', 'newspaper', 'north', 'notice', 'novel', 'now', 'paper', 'passing', 'people', 'periodical', 'pew', 'post', 'presenter', 'press', 'print', 'program', 'public', 'public_knowledge', 'radio', 'read', 'reading', 'relevance', 'report', 'scoop', 'section', 'service', 'show', 'six', 'source', 'south', 'spread', 'stand', 'story', 'stuff', 'tabloid', 'television', 'television_program', 'telling', 'times', 'today', 'type', 'update', 'washington', 'weather', 'weatherman', 'west', 'world', 'writing']}, {'exemplar_feature': 'nip', 'feature_properties': ['bud', 'tuck', 'action', 'at', 'bit', 'bite', 'bud', 'cold', 'cut', 'cutting', 'dog', 'dog_bite', 'drink', 'here', 'japanese', 'little', 'person', 'pin', 'pinch', 'show', 'slang', 'small', 'test', 'tuck']}, {'exemplar_feature': 'rain', 'feature_properties': ['boot', 'bucket', 'cloud', 'coal', 'coat', 'cry', 'downpour', 'downpour', 'draw', 'drip', 'drizzle', 'drizzle', 'drop', 'dry_season', 'flood', 'glaze', 'gutter', 'gutter', 'hail', 'hurricane', 'hurricane', 'ice_storm', 'jacket', 'kachina', 'lithophyte', 'louver', 'malaria', \"mare's_tail\", 'meteor', 'mist', 'moisture', 'monsoon', 'monsoon', 'nitrogen_cycle', 'pain', 'pelter', 'point', 'precipitate', 'precipitate', 'precipitation', 'puddle', 'pula', 'rainbow', 'raincoat', 'rainmaking', 'rainy_season', 'river_basin', 'scat', 'scud', 'seeder', 'shower', 'sleet', 'sleet', 'snow', 'soak', 'soprano', 'storm', 'thunder', 'thundershower', 'thunderstorm', 'umbrella', 'umbrella', 'virga', 'washout', 'water', 'water', 'weather', 'weather_radar', 'windshield_wiper', 'acid_rain', 'bad', 'bad_weather', 'clear', 'cloud', 'cold', 'condensation', 'condition', 'crying', 'down', 'downpour', 'drizzle', 'droplet', 'droppings', 'event', 'fall', 'global_warming', 'hail', 'like', 'liquid', 'making', 'moisture', 'monsoon', 'natural', 'natural_phenomenon', 'nature', 'outside', 'pattern', 'phenomenon', 'precipitation', 'produce', 'product', 'rain_gauge', 'season', 'shower', 'sky', 'sleet', 'snow', 'spring', 'storm', 'summer', 'thunder', 'thunderstorm', 'type', 'water', 'weather', 'weather_forecast', 'weather_radar', 'wetness']}, {'exemplar_feature': 'saprolite', 'feature_properties': []}, {'exemplar_feature': 'serve', 'feature_properties': ['ace', 'attack', 'balk', 'bartender', 'bayonet', 'belt', 'bowl', 'caddy', 'casserole', 'catch', 'caterer', 'certificate', 'cloaca', 'coin', 'company_man', 'convent', 'cupbearer', 'dean', 'dish', 'double_fault', 'drink', 'fault', 'feed', 'fringe', 'impress', 'jug', 'ka', 'krebs_cycle', 'lackey', 'ladle', 'let', 'light', 'lunch_meat', 'mineral', 'nark', 'page', 'partisan', 'plate', 'plate', 'rally', 'rescript', 'reserve', 'restaurant', 'return', 'rota', 'sandwich', 'servant', 'servant', 'server', 'service', 'service', 'service', 'service_line', 'ship', 'smash', 'spoon', 'summons', 'teacake', 'tureen', 'valet', 'veteran', 'worm']}, {'exemplar_feature': 'slip', 'feature_properties': ['bank', 'bowline', 'clove_hitch', 'compact', 'creeper', 'crupper', 'cycloid', 'dock', 'dollar', 'drop', 'epicycloid', 'fall', 'ghost', 'gully', 'hypocycloid', 'joggle', 'lapse', 'macule', 'outfield', 'petticoat', 'rake', 'scape', 'set', 'sgraffito', 'sheet', 'shift', 'slide', 'slope', 'snipe', 'accident', 'accidental', 'action', 'anagram', 'balance', 'banana', 'banana_peel', 'bedroom', 'boat', 'camisole', 'cause', 'clothing', 'cover', 'down', 'dress', 'effect', 'error', 'fall', 'female', 'floor', 'foothold', 'footing', 'form', 'freudian_slip', 'friction', 'garment', 'gown', 'grip', 'ground', 'ice', 'lace', 'lady', 'legs', 'light', 'like', 'loss', 'mistake', 'motion', 'movement', 'nightgown', 'nylon', 'over', 'paper', 'peel', 'perry', 'petticoat', 'piece', 'pink', 'puddle', 'reason', 'result', 'romance', 'short', 'silk', 'skid', 'skin', 'skirt', 'skit', 'slippage', 'small', 'smooth', 'stairs', 'surface', 'tongue', 'toy', 'traction', 'trip', 'type', 'undergarment', 'underwear', 'waist', 'weather', 'while', 'white', 'woman', 'yard']}, {'exemplar_feature': 'snow', 'feature_properties': ['apple', 'avalanche', 'avalanche', 'board', 'cavalcade', 'christmas', 'cloud', 'cold', 'cornice', 'cotton', 'crud', 'deposition', 'dogsled', 'footprint', 'frost', 'ice', 'icehouse', 'igloo', 'leopard', 'meltwater', 'meteor', 'mountain', 'mush', 'mush', 'paper', 'poison', 'posthole', 'powder', 'precipitate', 'precipitate', 'precipitation', 'rain', 'river_basin', 'salt', 'ski', 'ski_slope', 'skiff', 'sleet', 'sleet', 'slope', 'slush', 'slush', 'snowball', 'snowcap', 'snowfield', 'snowflake', 'snowmobile', 'spindrift', 'stall', 'stick', 'sugar', 'thaw', 'thunderstorm', 'virga', 'weather', 'white', 'white', 'winter', 'accumulation', 'alaska', 'base', 'blizzard', 'christmas', 'cocaine', 'cold', 'cold_water', 'cold_weather', 'coldness', 'condensation', 'condition', 'crystal', 'dandruff', 'december', 'drifting', 'event', 'fall', 'fields', 'fluff', 'freeze', 'frost', 'hailstorm', 'ice', 'like', 'liquid', 'making', 'marshmallow', 'material', 'mist', 'mountain', 'north', 'north_pole', 'outside', 'particle', 'people', 'phenomenon', 'pole', 'powder', 'precipitation', 'product', 'raid', 'rain', 'season', 'sight', 'ski', 'skiing', 'sky', 'sledding', 'sleet', 'solid', 'storm', 'stuff', 'surface', 'test', 'thirty', 'time', 'two', 'water', 'weather', 'wetness', 'white', 'white_water', 'whiteness', 'winder', 'winter', 'wonderland']}, {'exemplar_feature': 'storm', 'feature_properties': ['adad', 'baal', 'barber', 'bastille_day', 'brewing', 'gale', 'hail', 'hurricane', 'hurricane', 'invention', 'lightning', 'lilith', 'loose_cannon', 'messenger', 'monsoon', 'operation', 'rain', 'rainstorm', 'rand', 'snow', 'squall', 'storm_cloud', 'storm_door', 'storminess', 'tempest', 'tempest', 'thunder', 'tornado', 'typhoon', 'weather', 'weather', 'wind', 'wind', 'windstorm', 'acid_rain', 'action', 'bad', 'bad_weather', 'blizzard', 'heavy', 'hurricane', 'lightning', 'pattern', 'rain', 'tempest', 'thunder', 'weather', 'wind']}, {'exemplar_feature': 'storm', 'feature_properties': ['adad', 'baal', 'barber', 'bastille_day', 'brewing', 'gale', 'hail', 'hurricane', 'hurricane', 'invention', 'lightning', 'lilith', 'loose_cannon', 'messenger', 'monsoon', 'operation', 'rain', 'rainstorm', 'rand', 'snow', 'squall', 'storm_cloud', 'storm_door', 'storminess', 'tempest', 'tempest', 'thunder', 'tornado', 'typhoon', 'weather', 'weather', 'wind', 'wind', 'windstorm', 'acid_rain', 'action', 'bad', 'bad_weather', 'blizzard', 'heavy', 'hurricane', 'lightning', 'pattern', 'rain', 'tempest', 'thunder', 'weather', 'wind']}, {'exemplar_feature': 'summer', 'feature_properties': ['aquila', 'badminton', 'break', 'breeze', 'cabin', 'caelum', 'camp', 'carina', 'coma_berenices', 'corn', 'cotton', 'cygnus', 'cymling', 'delphinus', 'dog_days', 'fall', 'fall_webworm', 'greenwood', 'halter', 'heat', 'hercules', 'labor_day', 'lemonade', 'lupus', 'lyra', 'madonna_lily', 'mensa', 'monsoon', 'northern_cross', 'ophiuchus', 'pictor', 'rain', 'reticulum', 'roe_deer', 'salad', 'sandal', 'school_day', 'season', 'season', 'seersucker', 'serpens', 'shade', 'sirius', 'soccer', 'spring', 'summer_stock', 'sunburn', 'sundress', 'thunder', 'trip', 'weather', 'winter', 'august', 'beach', 'climate', 'current', 'days', 'elephant', 'fall', 'green', 'hail', 'heat', 'hot_weather', 'hotel', 'hotness', 'july', 'june', 'may', 'middle', 'month', 'ms', 'nice', 'now', 'period', 'season', 'spring', 'sun', 'time', 'time_period', 'two', 'vacation', 'warmth', 'weather', 'winter', 'year']}, {'exemplar_feature': 'temperature', 'feature_properties': ['absolute_zero', 'advection', 'air_conditioner', 'air_mass', 'body_temperature', 'boiling_point', \"boltzmann's_constant\", \"boyle's_law\", 'british_thermal_unit', 'calculus', 'calorie', 'candy_thermometer', 'celsius', 'celsius_scale', 'chill', 'cold', 'cold', 'cold', 'cold_fusion', 'coldness', 'comfort_zone', 'constantan', 'cool', 'cool', 'cooling', 'crucible', 'cryobiology', 'cryogenics', 'cryometer', 'cryostat', 'decalescence', 'deep_freeze', 'degree', 'degree', 'degree_centigrade', 'degree_fahrenheit', 'destructive_distillation', 'dew_point', 'digester', 'ethane', 'ethylene', 'eutectic', 'eutectic', 'fahrenheit', 'fahrenheit_scale', 'fata_morgana', 'ferrimagnetism', 'fever', 'freeze', 'freezing_point', 'front', 'frost', 'global_warming', 'growing_season', 'heat', 'heat_exhaustion', 'heat_pump', 'high', 'homeostasis', 'hot_spring', 'hydrogenation', 'hyperthermia', 'hypothermia', 'interferometer', 'isotherm', 'lapse', 'luminescence', 'mercury', 'metamorphic_rock', 'normothermia', 'oxyacetylene', 'propylene', 'pyroelectricity', 'pyrogen', 'pyrometer', 'pyrostat', 'radiation_pyrometer', 'radiomicrometer', 'red_giant', 'relative_density', 'retort', 'shade', 'solar_wind', 'solidus', 'steam', 'sunspot', 'superstrate', 'sweat', 'telethermometer', 'temp', 'temperance', 'therm', 'thermal', 'thermal', 'thermion', 'thermistor', 'thermocouple', 'thermodynamics', 'thermogram', 'thermograph', 'thermography', 'thermometer', 'thermometer', 'thermometry', 'thermoreceptor', 'thermos', 'thermostat', 'triiodothyronine', 'warmth', 'weather', 'weather', 'white_heat', 'winter', 'celsius', 'cold', 'coldness', 'fever', 'heat', 'hotness', 'measurement', 'number', 'reading', 'thermometer', 'warmth', 'weather']}, {'exemplar_feature': 'thaw', 'feature_properties': ['freeze', 'process', 'river']}, {'exemplar_feature': 'thermometer', 'feature_properties': ['candy_thermometer', 'cryometer', 'degree', 'hygrodeik', 'mercury', 'mercury', 'pyrometer', 'temperature', 'temperature', 'thermograph', 'thermohydrometer', 'thermometry', 'barometer', 'device', 'fever', 'glass', 'heat', 'hygrometer', 'instrument', 'measure', 'measurement', 'mercury', 'mouth', 'numbers', 'pen', 'stick', 'take', 'taker', 'temperature', 'tip', 'tool', 'tube', 'weather', 'weather_forecast', 'windows']}, {'exemplar_feature': 'thunder', 'feature_properties': ['bronte', 'cloud', 'flash', 'fulminate', 'hurricane', 'intonation', 'lightning', 'rain', 'rumble', 'rumble', 'set', 'seth', 'storm', 'thunderbolt', 'thunderer', 'thunderstorm', 'volt', 'weather', 'accompaniment', 'activity', 'air', 'bad', 'bad_weather', 'bang', 'black', 'bolt', 'boom', 'bowling', 'client', 'cloud', 'companion', 'condition', 'cousin', 'cracking', 'crash', 'dark', 'deep', 'disaster', 'downpour', 'echo', 'electric', 'electricity', 'element', 'event', 'feature', 'flash', 'follower', 'following', 'happening', 'heavy', 'light', 'lightening', 'lighting', 'lightning', 'like', 'load', 'natural', 'natural_phenomenon', 'noise', 'nose', 'nothing', 'partner', 'pattern', 'phenomenon', 'rain', 'rainstorm', 'ray', 'roar', 'rolling', 'rumble', 'situation', 'sky', 'slumber', 'spark', 'storm', 'summer', 'then', 'thor', 'thrill', 'type', 'weather', 'white', 'wind', 'zigzag']}, {'exemplar_feature': 'tornado', 'feature_properties': ['cyclone', 'depression', 'disaster', 'dust_devil', 'hurricane', 'storm_cellar', 'storm_door', 'supertwister', 'twist', 'typhoon', 'waterspout', 'whirlwind', 'wind', 'wind', 'cloud', 'cyclone', 'dust_devil', 'funnel', 'high', 'hurricane', 'like', 'spiral', 'storm', 'tsunami', 'typhoon', 'waterspout', 'weather', 'whirl', 'wind', 'wing']}, {'exemplar_feature': 'typhoon', 'feature_properties': ['anticyclone', 'cyclone', 'tornado', 'typhon', 'wind', 'china', 'cyclone', 'extreme', 'hurricane', 'pacific', 'phenomenon', 'phone', 'storm', 'tie', 'tornado', 'tsunami', 'water', 'weather', 'whirlwind', 'wind']}, {'exemplar_feature': 'typhoon', 'feature_properties': ['anticyclone', 'cyclone', 'tornado', 'typhon', 'wind', 'china', 'cyclone', 'extreme', 'hurricane', 'pacific', 'phenomenon', 'phone', 'storm', 'tie', 'tornado', 'tsunami', 'water', 'weather', 'whirlwind', 'wind']}, {'exemplar_feature': 'umbrella', 'feature_properties': ['agaric', 'cover', 'gamp', 'hallstand', 'parasol', 'shade', 'stretcher', 'tee', 'bad', 'bad_weather', 'cover', 'covering', 'protection', 'rain', 'shade', 'shelter', 'stopper', 'weather']}, {'exemplar_feature': 'vane', 'feature_properties': ['barb', 'contour_feather', 'fan', 'fly', 'rudder', 'target', 'windmill', 'chicken', 'direction', 'indicator', 'mirror', 'roof', 'weather', 'wind']}, {'exemplar_feature': 'washboard', 'feature_properties': ['zydeco']}, {'exemplar_feature': 'weather_forecast', 'feature_properties': ['clear', 'rain', 'thermometer']}, {'exemplar_feature': 'weatherglass', 'feature_properties': []}, {'exemplar_feature': 'wetness', 'feature_properties': ['cry', 'dew', 'drink', 'dry', 'fast', 'mist', 'moisture', 'rain', 'snow', 'water']}, {'exemplar_feature': 'whiteout', 'feature_properties': ['blackout', 'blackout']}, {'exemplar_feature': 'wind', 'feature_properties': ['aeolian', 'aeolian_harp', 'aeolic', 'aeolus', 'agglomerate', 'air', 'air', 'anemography', 'anemometer', 'anemometry', 'anticyclone', 'back', 'backstay', 'beat', 'beaufort_scale', 'blanket', 'blow', 'blow', 'bluster', 'boat', 'boreas', 'bottom', 'breath', 'breath', 'breeze', 'breeze', 'bunting', 'buster', 'capful', 'chop', 'clarinet', 'coil', 'corkscrew', 'crosswind', 'current', 'cyclone', 'direction', 'drift_ice', 'east', 'east', 'energy', 'enlil', 'exposure', 'fan', 'fart', 'feather', 'fire', 'firestorm', 'flag', 'flatulence', 'flurry', 'gale', 'ground_swell', 'gust', 'hasp', 'headwind', 'horn', 'hurricane', 'hurricane', 'isogon', 'katabatic_wind', 'khamsin', 'krummhorn', 'lap', 'lees', 'light_air', 'luff', 'lull', 'lute', 'meander', 'meteor', 'monsoon', 'oboe', 'pinwheel', 'pollination', 'reed', 'reel', 'reeler', 'rig', 'ripple_mark', 'room', 'sail', 'sailing', 'sailing_vessel', 'scarlet', 'scud', 'scud', 'serpent', 'skein', 'snake', 'sneeze', 'snowdrift', 'south_wind', 'southeaster', 'southwester', 'spindrift', 'spinning_frame', 'steam', 'storm', 'storm', 'swell', 'swift', 'tempest', 'thunder', 'thunderstorm', 'tongue', 'tornado', 'touch', 'trade', 'trade_wind', 'turban', 'twist', 'twist', 'typhoon', 'typhoon', 'vane', 'variable', 'vayu', 'wave', 'wear', 'weather', 'weather', 'weave', 'west', 'wind_instrument', 'windage', 'windburn', 'winder', 'winder', 'windmill', 'window', 'window', 'windshield', 'windsock', 'windstorm', 'wine', 'wound', 'zephyr', 'air', 'atmospheric_phenomenon', 'atmospheric_pressure', 'blow', 'breath', 'breathing', 'breeze', 'characteristic', 'chicago', 'clear', 'cold', 'condition', 'currant', 'current', 'earth', 'element', 'en', 'energy', 'fast', 'feature', 'flatulence', 'force', 'gale', 'gas', 'gust', 'heavy', 'hurricane', 'kite', 'light', 'light_breeze', 'like', 'mistral', 'motion', 'move', 'movement', 'natural', 'nature', 'nothing', 'outside', 'patter', 'phenomenon', 'power', 'pressure', 'propulsion', 'running', 'rustling', 'sailboat', 'speed', 'storm', 'strong_breeze', 'tornado', 'weather', 'zephyr']}, {'exemplar_feature': 'windshield', 'feature_properties': ['glass', 'plate_glass', 'steep', 'sun_visor', 'windshield_wiper']}, {'exemplar_feature': 'winter', 'feature_properties': ['antlia', 'auriga', 'baldwin', 'bear', 'boot', 'canis_major', 'canis_minor', 'cetus', 'christmas', 'circinus', 'coat', 'cold', 'columba', 'comforter', 'crux', 'eridanus', 'fall', 'flannel', 'fornax', 'freeze', 'frost', 'hydrus', 'icicle', 'jack_frost', 'jacket', 'lepus', 'madonna_lily', 'midwinter', 'perennation', 'produce', 'puppis', 'roe_deer', 'season', 'season', 'sedge_warbler', 'ski', 'slush', 'snow', 'soup', 'southern_cross', 'spring', 'spring', 'sprinter', 'stocker', 'summer', 'telescopium', 'triangulum_australe', 'uta', 'weather', 'white_stork', 'winesap', 'wool', 'yard', 'christmas', 'cold', 'cold_weather', 'coldness', 'december', 'fall', 'ice', 'north', 'outside', 'season', 'snow', 'sow', 'spring', 'station', 'summer', 'time', 'weather', 'white', 'wonderland']}, {'exemplar_feature': 'action', 'feature_properties': ['acceptance', 'act', 'act', 'acting', 'active_voice', 'activism', 'activity', 'actor', 'adventure', 'afterthought', 'agency', 'agent', 'antiviral', 'appeal', 'attack', 'attempt', 'attempt', 'attention', 'auspice', 'austrian', 'bad', 'battle', 'begin', 'beginning', 'berm', 'bid', 'bill_of_particulars', 'bit', 'bite', 'blessing', 'blow', 'blowback', 'boil', 'born', 'bowling', 'brain', 'break', 'bribe', 'burn', 'call', 'camp', 'can_of_worms', 'care', 'carry', 'case', 'case', 'categorical_imperative', 'cause', 'challenge', 'change', 'character', 'charge', 'chew', 'chinaman', 'chop', 'claim', 'clear', 'climb', 'combustion', 'concern', 'concretion', 'congee', 'consequence', 'constancy', 'control', 'cook', 'cope', 'copy', 'count', 'course', 'court', 'cover', 'crawl', 'crop', 'cross', 'crush', 'cry', 'crying', 'cut', 'dance', 'dare', 'deal', 'deal', 'debt', 'deed', 'deed', 'definition', 'demand', 'deposit', 'design', 'dial', 'die', 'dive', 'divide', 'division', 'do', 'docket', 'doll', 'draw', 'dream', 'drink', 'drive', 'drop', 'drove', 'drug', 'effect', 'effort', 'end', 'episode', 'escape', 'exchange', 'exercise', 'experiment', 'extension', 'extenuation', 'extremism', 'fact', 'fall', 'fast', 'feed', 'feel', 'fell', 'fielding', 'fieri_facias', 'fight', 'figure', 'filibuster', 'fill', 'filling', 'fishing', 'fix', 'flash', 'flow', 'flow', 'flush', 'flutter', 'fly', 'force', 'free_will', 'freudian_slip', 'frog_kick', 'function', 'future_perfect', 'game', 'gather', 'get', 'give', 'go', 'graze', 'guess', 'guide', 'guideline', 'habit', 'habit', 'hadith', 'hang', 'haste', 'hearing', 'heat', 'hide', 'hold', 'hop', 'impulse', 'inaction', 'inconstancy', 'increase', 'inertia', 'informed_consent', 'inside_job', 'intent', 'interrupt', 'intervention', 'investigation', 'ion', 'issue', 'itch', 'jolt', 'karma', 'keep', 'kick', 'kill', 'kind', 'kiss', 'knitting', 'land', 'laugh', 'lead', 'leap', 'learning', 'leave', 'leaven', 'lending', 'let', 'libel', 'lie', 'lift', 'limitation', 'look', 'look', 'lunge', 'lure', 'lynching', 'manner', 'manner', 'march', 'masterstroke', 'maverick', 'measure', 'measure', 'meme', 'middle_name', 'might', 'mimesis', 'mimic', 'misbehavior', 'misfeasance', 'mistake', 'mold', 'move', 'move', 'neglect', 'nip', 'nod', 'obligation', 'ode', 'open', 'organization', 'paint', 'park', 'pass', 'passion', 'passive_voice', 'paste', 'pause', 'payment', 'peal', 'peck', 'peel', 'performance', 'perseverance', \"planck's_constant\", 'planning', 'plant', 'play', 'playing', 'pleasure', 'point', 'polish', 'posting', 'practice', 'practice', 'pragmatism', 'preparation', 'present_perfect', 'preserve', 'press', 'print', 'processing', 'produce', 'proportionality', 'prosperity', 'protest', 'pull', 'pump_action', 'punch', 'punishment', 'purpose', 'push', 'quiescence', 'raise', 'rampage', 'reach', 'reach', 'reaction', 'read', 'reading', 'rebel', 'reciprocal', 'reciprocity', 'record', 'reflex', 'reflexive_pronoun', 'refrain', 'reinforcement', 'repeat', 'reply', 'responsibility', 'rest', 'result', 'return', 'review', 'reward', 'reward', 'ride', 'ring', 'rise', 'robbery', 'roll', 'routine', 'rub', 'rubicon', 'rule', 'rule', 'run', 'running', 'ruse', 'rush', 'rust', 'sail', 'sale', 'say', 'scheme', 'script', 'search', 'seek', 'sell', 'selling', 'services', 'settlement', 'shackle', 'shamelessness', 'shielding', 'shock', 'shoot', 'shot', 'siege', 'sin', 'singer', 'slash', 'slash', 'sleep', 'slice', 'slip', 'slope', 'smash', 'smell', 'smile', 'smoke', 'sneeze', 'sob', 'somersault', 'sound_effect', 'spark', 'spoke', 'spring', 'stare', 'start', 'stay', 'steam_shovel', 'step', 'stick', 'stimulation', 'stitch', 'stop', 'storm', 'strategy', 'strength', 'stretch', 'stroke', 'stunt', 'sue', 'surprise', 'surrender', 'suzerainty', 'swallow', 'sweep', 'synchronization', 'tactic', 'talk', 'tap', 'taste', 'telegraph', 'tense', 'think', 'thoughtfulness', 'thrashing', 'throw', 'tickle', 'touch', 'toy', 'trade', 'training', 'travel', 'trial_balloon', 'trick', 'trick', 'trouble', 'tuck', 'tuning', 'turn', 'twist', 'tying', 'type', 'vagary', 'verb', 'view', 'vitrification', 'voice', 'vote', 'wait', 'wait', 'walk', 'walk', 'war', 'warpath', 'wash', 'watch', 'wave', 'wear', 'weather', 'welt', 'wiggle', 'witness', 'word', 'work', 'work', 'working', 'writing', 'yawn']}, {'exemplar_feature': 'activity', 'feature_properties': ['a', 'acromegaly', 'action', 'affair', 'age_limit', 'art', 'art_form', 'artist', 'athletics', 'attack', 'background', 'bath', 'battle', 'becquerel', 'bioassay', 'bite', 'boat', 'boating', 'boondoggle', 'born', 'bowl', 'brain_death', 'breath', 'bribe', 'budget', 'burial', 'business', 'business', 'business_cycle', 'bustle', 'call', 'camp', 'center', 'chew', 'churn', 'churn', 'climb', 'collection', 'community_service', 'conglomerate', 'continence', 'contributor', 'conversation_piece', 'count', 'coven', 'crime', 'cry', 'cryptobiosis', 'cut', 'dance', 'dancer', 'decline', 'deduction', 'dive', 'diversion', 'do', 'domain', 'dominant', 'draw', 'dream', 'dress', 'drink', 'drive', 'duty', 'dynamism', 'effort', 'effortfulness', 'electroencephalogram', 'employment', 'employment', 'energy', 'energy', 'enterprise', 'entrepreneur', 'environmentalism', 'epiphenomenon', 'errand', 'event', 'exercise', 'exercise', 'exercise', 'experience', 'experiment', 'factotum', 'fandom', 'fast_lane', 'fight', 'fishing', 'fits_and_starts', 'flurry', 'fly', 'fraud', 'front', 'fun', 'functional_magnetic_resonance_imaging', 'fuss', 'gambling', 'game', 'game', 'ghost_town', 'go', 'good_time', 'good_time', 'graze', 'growth', 'gymnastics', 'habit', 'hang', 'headquarters', 'hobby', 'hobbyist', 'hormone', 'hot_spot', 'humus', 'hunt', 'hypocrisy', 'icebreaker', 'inaction', 'incidental_expense', 'indian_summer', 'inertness', 'intelligence', 'interview', 'job', 'journalism', 'jump_rope', 'knitting', 'like', 'lime', 'living_room', 'locus', 'loneliness', 'look', 'marathon', 'march', 'masturbation', 'memory', 'middle_name', 'move', 'music', 'napoleon', 'occupation', 'outburst', 'overactivity', 'overhead', 'paint', 'parasailing', 'partner', 'party', 'patron_saint', 'pedophilia', 'plan', 'play', 'play', 'playing', 'plunge', 'point', 'practice', 'praise', 'prayer', 'presence', 'preserve', 'print', 'production', 'production', 'profession', 'program', 'protest', 'province', 'pursuit', 'quantification', 'race', 'rat_race', 'ratiocination', 'read', 'reading', 'recession', 'rest', 'rest', 'rest_day', 'retrospective', 'ride', 'rigmarole', 'ritual', 'robbery', 'rub', 'rule', 'run', 'safe_sex', 'sail', 'sale', 'say', 'schedule', 'scholarship', 'science', 'session', 'sex', 'sex', 'sex_drive', 'shackle', 'shoot', 'shop', 'sin', 'ski', 'sleep', 'slump', 'smash', 'smell', 'smoke', 'song_and_dance', 'sound', 'space_walk', 'spasm', 'spectator_sport', 'start', 'stretch', 'sublimate', 'subtraction', 'swallow', 'swimming', 'task_force', 'think', 'thinker', 'thought', 'thunder', 'tidemark', 'till', 'timeline', 'trade', 'turn', 'type', 'upturn', 'vacation', 'vamp', 'voyeur', 'walk', 'war', 'wash', 'watch', 'wave', 'wear', 'wear', 'weather', 'white_heat', 'work', 'working', 'writing', 'year']}, {'exemplar_feature': 'air', 'feature_properties': ['a', 'aeration', 'aerator', 'aerobiosis', 'aerology', 'aerophile', 'aerosol', 'air_filter', 'air_force', 'air_hole', 'air_mattress', 'air_pump', 'air_traffic', 'airburst', 'aircraft', 'airflow', 'airing', 'airlift', 'airline', 'airliner', 'airmail', 'airs', 'airship', 'airspeed', 'airstream', 'anaximenes', 'army', 'aspirate', 'aspiration', 'atmosphere', 'atmosphere', 'ball', 'balloon', 'balloon', 'ballooning', 'base', 'bellows', 'bessemer_process', 'bird', 'blow', 'blow', 'blowhole', 'breath', 'breathalyzer', 'bubble', 'bunsen_burner', 'calcium_nitrate', 'canvas', 'chicken', 'choke', 'closet', 'cloud', 'cloud', 'coast', 'compression', 'condition', 'cooling_tower', 'cough', 'craft', 'current', 'cut', 'cutter', 'dew_point', 'diesel', 'downdraft', 'drying_oil', 'dust', 'empedocles', 'emphysema', 'ether', 'exhaustion', 'fair', 'fan', 'fan_blade', 'firedamp', 'flight', 'flue_pipe', 'fly', 'fly', 'force', 'gas', 'grill', 'haze', 'heat', 'heaven', 'hovercraft', 'humidity', 'hygrometer', 'hyperbaric_chamber', 'jaffa', 'jet_engine', 'juggler', 'katabatic_wind', 'kite', 'lapse', 'lift', 'lilo', 'lob', 'loft', 'lung', 'lung', 'lungfish', 'malaria', 'mammal', 'market', 'minuet', 'mist', 'mother', 'musette', 'newscast', 'nitrogen_dioxide', 'nitrogen_narcosis', 'oil_paint', 'overdraft', 'oxygen', 'ozone', 'physeter', 'pilot_balloon', 'plane', 'pneumothorax', 'pollen', 'pollution', 'pressure', 'propeller', 'pump', 'pyrophorus', 'quintessence', 'radio', 'rain', 'rainbow', 'refractive_index', 'respiratory_tract', 'reward', 'ridge', 'rise', 'roll', 'scavenger', 'shaft', 'sigh', 'sky', 'smoke', 'smother', 'sneeze', 'sonic_boom', 'sound', 'sound', 'space', 'spiracle', 'spirometer', 'spout', 'sprinkler', 'steam', 'stop', 'stopping', 'stridor', 'supply', 'sylph', 'tarnish', 'thermal', 'throw', 'thunder', 'tongue', 'trapeze', 'upcast', 'updraft', 'vapor', 'vent', 'ventilation', 'ventilator', 'vessel', 'water', 'weather', 'whiff', 'whipped_cream', 'whipping', 'whiz', 'wind', 'wind', 'window', 'wing', 'agent', 'aircraft', 'atmosphere', 'breath', 'breathing', 'breeze', 'cant', 'clear', 'component', 'content', 'element', 'elements', 'four', 'gas', 'general', 'generic', 'greek', 'hydrogen', 'intangible', 'light', 'like', 'living', 'material', 'matter', 'mix', 'molecule', 'nitrogen', 'nothing', 'nothingness', 'oxygen', 'pollution', 'resistance', 'see', 'sky', 'solution', 'source', 'space', 'stuff', 'substance', 'term', 'transparency', 'vapor', 'very_light', 'wind']}, {'exemplar_feature': 'atmosphere', 'feature_properties': ['a', 'advection', 'aerology', 'aerospace', 'air', 'air', 'air_pollution', 'airspace', 'ambiance', 'astronomy', 'atmospheric_pressure', 'aura', 'aurora', 'barometric_pressure', 'bioclimatology', 'biosphere', 'british_thermal_unit', 'carbon_cycle', 'celestial_body', 'cloud', 'corona', 'dasymeter', 'destructive_distillation', 'efflorescence', 'ether', 'exosphere', 'fata_morgana', 'fug', 'genius_loci', 'gloom', 'greenhouse_effect', 'greenhouse_gas', 'halo', 'heaven', 'hydrology', 'hydrosphere', 'inversion', 'ionosphere', 'karma', 'lidar', 'lift', 'lithophyte', 'lithosphere', 'mesosphere', 'meteor', 'meteoroid', 'meteorology', 'miasma', 'micrometeorite', 'millibar', 'mist', 'mood', 'nuclear_winter', 'outer_space', 'oxygen', 'precipitation', 'proterozoic', 'psychrometer', 'saturation', 'scintillation', 'sky', 'sky', 'skylight', 'smoke', 'solar_constant', 'solar_flare', 'sounding_rocket', 'space', 'space_capsule', 'sphere', 'storm', 'stratosphere', 'stratum', 'thermosphere', 'torr', 'train', 'troposphere', 'vibration', 'water_vapor', 'weather', 'weather', 'weather_map', 'weatherglass', 'air', 'aura', 'blanket', 'conditions', 'covering', 'earth', 'layer', 'must', 'outside', 'oxygen', 'ozone', 'planet', 'sky', 'smog', 'space']}, {'exemplar_feature': 'atmospheric_phenomenon', 'feature_properties': ['cloud', 'weather', 'wind']}, {'exemplar_feature': 'bad', 'feature_properties': ['abduction', 'accident', 'affair', 'agent', 'anger', 'appalling', 'average', 'badness', 'bandit', 'bitter', 'black', 'bone', 'brass', 'break', 'catastrophe', 'cheat', 'coal', 'cod', 'corner', 'craft', 'crime', 'curse', 'dab', 'danger', 'debt', 'depression', 'destroyer', 'disease', 'dream', 'dullness', 'emergency', 'empire', 'enemy', 'evil', 'example', 'failing', 'flea', 'fog', 'formaldehyde', 'foul', 'gang', 'good', 'grudge', 'guilt', 'habit', 'homicide', 'iron', 'irritation', 'jerk', 'jonah', 'lemon', 'lie', 'loss', 'mean', 'memory', 'menace', 'misery', 'mistake', 'mole', 'morning', 'negative', 'neglect', 'news', 'nightmare', 'noise', 'omen', 'ordinary', 'out', 'pain', 'paint', 'party', 'patzer', 'peak', 'pest', 'poison', 'pollution', 'predicament', 'prisoner', 'problem', 'protest', 'punishment', 'punk', 'rain', 'rank', 'rap', 'rattlesnake', 'reputation', 'resentment', 'robbery', 'rogue', 'rubbish', 'ruin', 'scare', 'sequel', 'shank', 'shock', 'sickness', 'sin', 'sketch', 'skunk', 'smear', 'smell', 'smoke', 'sock', 'spank', 'stole', 'storm', 'suspect', 'taste', 'terror', 'thief', 'thunder', 'trick', 'trouble', 'tyrant', 'umbrella', 'unpleasantness', 'verse', 'war', 'waste', 'weather', 'weed', 'worse', 'wound', 'wreck', 'wrong', 'action', 'adjective', 'attribute', 'evil', 'good', 'gorse', 'judgment', 'naughtiness', 'negative', 'wrong']}, {'exemplar_feature': 'boring', 'feature_properties': ['basic', 'beat', 'bore', 'boredom', 'boringness', 'cookie_cutter', 'deadliness', 'distraction', 'dullness', 'dump', 'history', 'hookworm', 'news', 'nudnik', 'office', 'plain', 'poetry', 'schlep', 'school', 'snore', 'soporific', 'soporific', 'square', 'unpleasantness', 'vulcan', 'weather', 'white_bread', 'work', 'yawn', 'yawner']}, {'exemplar_feature': 'change', 'feature_properties': ['adaptation', 'adjustment', 'amendment', 'back', 'barnacle', 'boiling', 'brace', 'break', 'break', 'bronze', 'butterfly_effect', 'cast', 'catalyst', 'cent', 'chop', 'coin', 'commutation', 'conservative', 'convert', 'convertible', 'crisis', 'decay', 'delta', 'demography', 'development', 'dime', 'disguise', 'drive', 'dynamism', 'engineer', 'engram', 'epigenesis', 'evolution', 'exchange', 'fall', 'ferment', 'finality', 'finishing_touch', 'flip', 'float', 'flux', 'force', 'freak', 'go', 'gradation', 'gradient', 'historical_linguistics', 'hunt', 'hygroscope', 'immobility', 'increase', 'industrial_revolution', 'inertia', 'inflexibility', 'jerk', 'journal', 'latent_heat', 'locker', 'locker_room', 'luddite', 'magnetograph', 'makeover', 'mangle', 'mathematics', 'matter', 'metaphysis', 'modification', 'money', 'motion', 'move', 'move', 'mutation', 'nomad', 'nuance', 'opportunity', 'panhandler', 'perturbation', 'phase', 'pocket', 'progress', 'protest', 'purse', 'quarter', 'radicalism', 'ramp', 'rate', 'refocusing', 'reformation', 'reset_button', 'reversal', 'revision', 'revolution', 'saltation', 'satellite', 'sensitivity', 'sex_change', 'shift', 'shift', 'shuffle', 'slope', 'spontaneity', 'stability', 'stasis', 'static', 'stay', 'stir', 'substitute', 'sunrise', 'sunset', 'swing', 'swing', 'switch', 'switch', 'symptom', 'take', 'thermostat', 'time', 'toll', 'transformation', 'transformer', 'transition', 'translation', 'transmutation', 'transpose', 'triode', 'turn', 'twist', 'uptick', 'variety', 'vicissitude', 'warp', 'weather', 'action', 'alteration', 'back', 'black', 'break', 'cash', 'circle', 'coin', 'conversion', 'currency', 'development', 'diaper', 'difference', 'dime', 'direction', 'dollar', 'evolution', 'extra', 'flux', 'forward', 'left', 'leftover', 'little', 'metamorphosis', 'modification', 'money', 'movement', 'mutation', 'nickel', 'over', 'penny', 'pocket', 'pocket_money', 'politician', 'president', 'progression', 'purchase', 'rate', 'remainder', 'return', 'round', 'small', 'spare', 'store', 'switch', 'transformation', 'wallet', 'weight']}, {'exemplar_feature': 'channel', 'feature_properties': ['anastomosis', 'aqueduct', 'avulsion', 'barrier_reef', 'bifurcation', 'billabong', 'buoy', 'bypass', 'cable_television', 'canal', 'canal', 'channelization', 'channels', 'channels', 'chase', 'chop', 'chop', 'conduit', 'conical_buoy', 'cullis', 'culvert', 'cutoff', 'data_rate', 'dial', 'discovery', 'drove', 'duct', 'emissary', 'fairway', 'flue', 'flume', 'fuller', 'funnel', 'gate', 'gouge', 'grip', 'groove', 'gully', 'gutter', 'haversian_canal', 'hollow', 'key', 'lake', 'lead', 'levee', 'lymphangitis', 'medium', 'menai_strait', 'module', 'mole', 'much', 'news', 'nyquist_rate', 'operator', 'part', 'pass', 'pipeline', 'rabbet', 'river', 'saddle', 'science', 'shank', 'shuttle', 'side', 'sleeve', 'sow', 'station', 'stool', 'streambed', 'swash', 'television_station', 'thalweg', 'tideway', 'tnt', 'voice', 'voice', 'washout', 'watercourse', 'waterspout', 'waterway', 'weather', 'zap', 'crossing', 'english', 'numbers', 'programming', 'station', 'television', 'television_station', 'type']}, {'exemplar_feature': 'circumstances', 'feature_properties': ['alias', 'tidy', 'trouble', 'weather']}, {'exemplar_feature': 'climate', 'feature_properties': ['climatology', 'cline', 'cold', 'control', 'decline', 'desert', 'desertification', 'dieback', 'dry', 'greenhouse', 'heat', 'heaven', 'oligocene', 'paleocene', 'summer', 'torrid_zone', 'weather', 'climate_change']}, {'exemplar_feature': 'cloud', 'feature_properties': ['altocumulus', 'altostratus', 'arcus', 'atom', 'bank', 'brewing', 'cataract', 'cirrostratus', 'cirrus', 'climate_change', 'clouding', 'cloudlessness', 'clutter', 'coma', 'contrail', 'convection', 'cotton', 'cumulus', 'fog', 'fog', 'haze', 'heaven', 'kachina', 'lightning', 'mackerel_sky', \"mare's_tail\", 'messenger', 'meteor', 'mist', 'nebula', 'nebule', 'nephoscope', 'nimbus', 'overcast', 'overcast', 'pallium', 'plume', 'precipitation', 'rain', 'rain', 'rainmaking', 'rift', 'scud', 'seeder', 'sheep', 'silver', 'sky', 'sky', 'smoke', 'sneeze', 'stardust', 'steam', 'stratus', 'swarm', 'thunder', 'thunderhead', 'tornado', 'tornado', 'vapor', 'weather', 'white', 'above', 'air', 'apparatus', 'appearance', 'atmosphere', 'atmospheric_phenomenon', 'ball', 'bearer', 'billow', 'blemish', 'blocker', 'blue', 'bubble', 'candy', 'cirrus', 'color', 'component', 'condensation', 'condition', 'container', 'cotton', 'cotton_ball', 'cotton_candy', 'cover', 'cumulonimbus', 'cumulus', 'dark', 'days', 'dust', 'effect', 'element', 'feature', 'floating', 'floss', 'fluff', 'fog', 'formation', 'found', 'gathering', 'giver', 'gray', 'grey', 'haze', 'heaven', 'high', 'holder', 'home', 'inside', 'item', 'lining', 'maker', 'making', 'marshmallow', 'mass', 'mist', 'moisture', 'natural', 'nice', 'nimbus', 'nine', 'number', 'object', 'origin', 'overcast', 'phenomenon', 'pillow', 'precipitation', 'producer', 'puff', 'rain', 'shade', 'shape', 'sheep', 'sight', 'silver', 'silver_lining', 'single', 'sky', 'smoke', 'snow', 'source', 'steam', 'stuff', 'sun', 'thunder', 'vapor', 'water', 'water_vapor', 'weather', 'weather_map', 'white', 'whiteness', 'wool']}, {'exemplar_feature': 'cold', 'feature_properties': ['antipasto', 'arctic', 'baltic', 'blood', 'brass', 'brass_monkey', 'brim', 'burn', 'calorimetry', 'carol', 'cash', 'catarrh', 'chill', 'chill', 'coat', 'cold_cuts', 'complexion', 'cool', 'cool', 'cool', 'cooler', 'cooling', 'cryoanesthesia', 'cryocautery', 'deadeye', 'degree', \"dover's_powder\", 'dressing', 'drink', 'dungeon', 'fish', 'fog', 'freeze', 'freeze', 'freeze', 'freezing_mixture', 'frieze', 'frost', 'hare', 'hay_fever', 'heat', 'ice', 'iced_coffee', 'icicle', 'injection', 'iron', 'lizard', 'lord', 'milk', 'mist', 'moon', 'napkin', 'nip', 'north', 'pilomotor_reflex', 'rain', 'refrigerant', 'refrigerator', 'reptile', 'rheum', 'shrinkage', 'sick', 'sneeze', 'snow', 'snub', 'space', 'steel', 'temperance', 'temperature', 'temperature', 'terrine', 'tin', 'trouble', 'weather', 'whale', 'wind', 'winter', 'winter', 'wool', 'chill', 'climate', 'cool', 'description', 'extra', 'feel', 'feeling', 'fire', 'heat', 'ice', 'illness', 'like', 'little', 'low', 'north', 'north_pole', 'pole', 'relative', 'sickness', 'snow', 'temp', 'temperature', 'weather', 'winter', 'zero']}, {'exemplar_feature': 'cold_front', 'feature_properties': ['occluded_front', 'weather', 'warm_front']}, {'exemplar_feature': 'collective', 'feature_properties': ['board', 'body', 'cast', 'collectivization', 'colony', 'community', 'crowd', 'electorate', 'episteme', 'farm', 'grounds', 'group', 'herd', 'judiciary', 'justiciary', 'kolkhoz', 'machinery', 'magistracy', 'mass', 'meeting', 'pack', 'page', 'protest', 'syconium', 'weather', 'west_germany']}, {'exemplar_feature': 'condition', 'feature_properties': ['ability', 'absolute', 'adaptability', 'air_embolism', 'alignment', 'altitude_sickness', 'anemia', 'aphagia', 'apprenticeship', 'attack', 'attractive_nuisance', 'awayness', 'basis', 'basophilia', 'bellwether', 'bend', 'blood_pressure', 'boil', 'boundary_condition', 'burn', 'caffeinism', 'case', 'case', 'cause_of_action', 'cerebral_palsy', 'changeableness', 'cherry', 'cleanness', 'clear', 'clip', 'cloud', 'comedown', 'concealment', 'conditionality', 'conditioner', 'conditioning', 'conditions', 'conjunction', 'converter', 'cost', 'danger', 'dark', 'dead', 'deafness', 'decay', 'degree', 'dehydration', 'dentistry', 'depopulation', 'depression', 'derivation', 'descent', 'disease', 'dismemberment', 'drop', 'dry', 'dwarf', 'epilepsy', 'equilibrium', 'erythema_nodosum', 'essential_tremor', 'estate', 'exception', 'experiment', 'exposure', 'extenuation', 'extreme', 'failure', 'fast', 'fear', 'fellow', 'fever', 'fine', 'fit', 'flocculation', 'fog', 'footing', 'frail', 'friendship', 'frost', 'fruition', 'galvanometer', 'hairlessness', 'halitosis', 'health', 'health', 'heat', 'heaven', 'hitch', 'hood', 'humanness', 'hydrocephalus', 'hydrography', 'hygiene', 'hyperacidity', 'imminence', 'importance', 'incubator', 'indigestion', 'insolvency', 'ion', 'issue', 'keep', 'keratoderma', 'kilter', 'last', 'law', 'leukoderma', 'lie', 'lie', 'locus', 'logic_bomb', 'loop', 'loss', 'lug', 'malcontent', 'matter', 'mayonnaise', 'mint', 'mist', 'moon_blindness', 'multiplicity', 'natural_history', 'necrobiosis_lipoidica', 'nick', 'nitrogen_narcosis', 'notoriety', 'oligopoly', 'optimum', 'paraplegia', 'pin', 'plight', 'point', 'poise', 'potential_energy', 'poverty', 'precondition', 'predicament', 'prednisone', 'prefixation', 'premise', 'prerequisite', 'presence', 'preserve', 'presumption', 'qualification', 'quality', 'rain', 'reformation', 'repair', 'repair', 'reproducibility', 'request', 'rule', 'saddle_soap', \"saint_anthony's_fire\", 'salience', 'schizophrenia', 'second_string', 'secrecy', 'sepsis', 'sequela', 'shape', 'shock', 'silence', 'slope', 'snow', 'solubility', 'spin', 'status', 'status_epilepticus', 'stew', 'stimulation', 'stipulation', 'stroke', 'supernaturalism', 'survey', 'take', 'term', 'test_case', 'throw', 'thunder', 'torticollis', 'trouble', 'tunnel_vision', 'ulceration', 'ultimatum', 'uncertainty', 'varicose_vein', 'varicosis', 'verification', 'victory', 'way', 'weather', 'weather', 'wetness', 'whiteout', 'wind', 'ailment', 'air', 'being', 'bottle', 'circumstance', 'contract', 'current', 'diagnosis', 'disease', 'dish', 'factor', 'fair', 'general', 'hair', 'health', 'hospital', 'illness', 'mint', 'must', 'prerequisite', 'product', 'prognosis', 'quality', 'report', 'shampoo', 'shape', 'shower', 'situation', 'softening', 'stable', 'state', 'status', 'syndrome', 'term', 'treat', 'treatment', 'well']}, {'exemplar_feature': 'conditions', 'feature_properties': ['atmosphere', 'checklist', 'climate', 'concession', 'contract', 'escrow', 'fast_track', 'fine_print', 'hatchery', 'history', 'impossible', 'manifestation', 'rule', 'weather']}, {'exemplar_feature': 'current', 'feature_properties': ['abampere', 'aeolic', 'air_pocket', 'airstream', 'amperage', 'ampere', 'amplification', 'anode', 'arc', 'ballast_resistor', 'bias', 'blow', 'bluebeard', 'body_temperature', 'busbar', 'cathode', 'circuit', 'closed_circuit', 'club', 'condition', 'convection', 'cooling_tower', 'coulomb', 'countercurrent', 'currency', 'currentness', 'cursor', 'cutoff', 'diathermy', 'differential', 'diode', 'direct_current', 'distributor', 'douche', 'downdraft', 'drift', 'drift_ice', 'earth', 'eddy', 'electricity', 'electricity', 'electrode', 'electrolysis', 'electrometer', 'fashion', 'field_coil', 'flow', 'flue', 'ford', 'going', 'granule', 'ground_loop', 'grounding', 'henry', 'here', 'hook', 'incumbent', 'journalist', 'loop', 'malcontent', 'may', 'milliammeter', 'modern', 'modern', 'mood', 'mutual_induction', 'news', 'now', 'now', 'ocean', \"ohm's_law\", 'ohm', 'oscillograph', 'oscilloscope', 'overdraft', 'parallel', 'pilot_light', 'pitching', 'place', 'power', 'present', 'present', 'race', 'raceway', 'rage', 'rapid', 'rate', 'reading', 'relay', 'resistor', 'river', 'running', 'scratchpad', 'selsyn', 'series_circuit', 'shock', 'short_circuit', 'shunt', 'stasis', 'stopping', 'summer', 'superconductivity', 'switch', 'synchronous_motor', 'thermojunction', 'today', 'trace', 'transient', 'upcast', 'updraft', 'vibrator', 'vogue', 'volt', 'volt', 'wave', 'weather', 'whirlwind', 'wind', 'winnow', 'yield', 'adjective', 'affairs', 'air', 'alternation', 'ampere', 'contemporary', 'currant', 'date', 'description', 'eddy', 'electric', 'electricity', 'electron', 'energy', 'event', 'fast', 'flow', 'fluctuation', 'force', 'frame', 'going', 'happening', 'high', 'latest', 'like', 'liquid', 'measure', 'measurement', 'modern', 'modernity', 'motion', 'movement', 'news', 'news_event', 'newspaper', 'nothing', 'now', 'ocean', 'output', 'paper', 'path', 'power', 'present', 'pull', 'pulse', 'relevance', 'right', 'river', 'saying', 'sea', 'shock', 'speed', 'stream', 'strength', 'term', 'tide', 'time', 'time_frame', 'today', 'undertow', 'unit', 'voltage', 'water', 'wave', 'wind', 'yak']}, {'exemplar_feature': 'daily', 'feature_properties': ['apple', 'bedroom_community', 'blotter', 'bread', 'dalliance', 'daybook', 'diary', 'habit', 'interest', 'journal', 'monthly', 'morning', 'motel', 'news', 'newspaper', 'paper', 'per_diem', 'per_diem', 'periodical', 'play', 'prayer', 'ration', 'report', 'ritual', 'run', 'scrum', 'sick_call', 'strip', 'wash', 'weather', 'work', 'annual', 'monthly', 'weekly']}, {'exemplar_feature': 'day', 'feature_properties': ['acre', 'afternoon', 'age', 'apple', 'arbor', 'baby', 'bid', 'birth', 'birthday', 'born', 'boxing_day', 'burgoo', 'cake', 'calendar', 'canonical_hour', 'care', 'chocolate', 'christmas', 'chronological_age', 'clear', 'court', 'daily', 'date', 'david', 'days', 'days', 'diary', 'dog_days', 'dream', 'ember', 'equinox', 'evening', 'event', 'flag', 'gray', 'holiday', 'hour', 'hour', 'ides', 'independence', 'indian_summer', 'interval', 'journey', 'latter', 'leap_day', 'leap_year', 'light', 'lily', 'love', 'lunar_month', 'lunch', 'market_day', 'modern', 'month', 'month', 'morning', 'morning', 'morning_dress', 'morrow', 'morrow', 'new_moon', 'news', 'night', 'nones', 'occasion', 'office', 'ordinary', 'payday', 'per_diem', 'reckoning', 'rescue', 'rest', 'rest_day', 'school_day', 'schooldays', 'scorcher', 'shade', 'sidereal_day', 'sky', 'solstice', 'substitute', 'sun', 'sunburn', 'sunlight', 'sunrise', 'sunset', 'time', 'today', 'today', 'tomorrow', 'tonight', 'tree', 'twelfthtide', 'weather', 'week', 'week', 'work', 'workday', 'workweek', 'year', 'year', 'yesterday', 'yesterday', 'afternoon', 'blue', 'blue_sky', 'brightness', 'calendar', 'calender', 'cycle', 'earth', 'element', 'event', 'four', 'hour', 'hours', 'length', 'light', 'light_time', 'measure', 'measurement', 'minute', 'monday', 'month', 'morning', 'morrow', 'nice', 'night', 'part', 'period', 'present', 'rotation', 'routine', 'sabbath', 'section', 'segment', 'seven', 'seventh', 'sky', 'span', 'sun', 'sunday', 'sunlight', 'thirty', 'thursday', 'time', 'time_period', 'time_unit', 'tomorrow', 'tuesday', 'twelve', 'twenty', 'unit', 'wednesday', 'week', 'weekly', 'year']}, {'exemplar_feature': 'description', 'feature_properties': ['account', 'address', 'age', 'anemography', 'arteriography', 'arthrography', 'atom', 'beauty', 'bertillon_system', 'best', 'better', 'blotter', 'body', 'broad', 'catachresis', 'century', 'charade', 'chick', 'circular', 'clear', 'cold', 'color', 'company', 'corner', 'country', 'current', 'delineation', 'descriptivism', 'descriptor', 'detail', 'drink', 'duality', 'edge', 'extreme', 'farm', 'few', 'figure', 'filler', 'fit', 'formalism', 'geography', 'good', 'great', 'he', 'heat', 'heavy', 'heraldry', 'here', 'hydrography', 'i', 'identikit', 'job_description', 'least', 'little', 'low', 'manner', 'mean', 'minister', 'modern', 'month', 'motion', 'name', 'nothing', 'nugget', 'old', 'ordinary', 'outline', 'page', 'past', 'plain', 'plant', 'portrayal', 'position', 'prescription', 'price', 'quality', 'reading', 'report', 'republic', 'round', 'shape', 'size', 'sound', 'story', 'systems_analysis', 'ticket', 'topography', 'turn', 'unit', 'weather', 'week', 'interpretation', 'ra', 'ration']}, {'exemplar_feature': 'effects', 'feature_properties': ['cause', 'comfort', 'first_cause', 'flea', 'gamekeeper', 'rub', 'weather']}, {'exemplar_feature': 'elements', 'feature_properties': ['air', 'atom', 'chemistry', 'color', 'communicant', 'corporal', 'exposure', 'fire', 'oil', 'periodic_law', 'scare', 'science', 'stove', 'transactinide', 'weather']}, {'exemplar_feature': 'environment', 'feature_properties': ['abundance', 'adaptation', 'ambiance', 'atmosphere', 'behaviorism', 'biosphere', 'bird', 'chameleon', 'chaos', 'city', 'class', 'closure', 'conservation', 'conservation', 'context', 'convergence', 'country', 'culture', 'culture_shock', 'desert', 'diving_suit', 'ecology', 'ecosystem', 'ecoterrorism', 'environmentalism', 'environmentalist', 'environs', 'euthenics', 'extreme', 'fair_trade', 'farm', 'functionalism', 'gnome', 'goldfish_bowl', 'green_party', 'halophile', 'halophyte', 'heavy_metal', 'hereditarianism', 'heterostracan', 'home', 'homeostasis', 'hotbed', 'indicator', 'medium', 'membrane', 'mesophyte', 'milieu', 'modification', 'moonwalk', 'nature', 'nature', 'office', 'organic', 'orientation', 'outdoors', 'place', 'platform', 'poison', 'pollution', 'pollution', 'quantum', 'residence', 'respiration', 'sheltered_workshop', 'simulator', 'specialist', 'spontaneity', 'temperature', 'transition', 'utility_program', 'virtual_reality', 'weather', 'work']}, {'exemplar_feature': 'fog', 'feature_properties': ['clearing', 'cloud', 'damp', 'drizzle', 'fogbank', 'haze', 'mist', 'offing', 'precipitation', 'rift', 'rook', 'smoke', 'steam', 'weather', 'bad', 'cloud', 'cold', 'cold_weather', 'condition', 'gray', 'ground', 'haze', 'head', 'humidity', 'london', 'low', 'mass', 'mist', 'morning', 'ocean', 'precipitation', 'sight', 'smog', 'smoke', 'steam', 'tea', 'visibility', 'water', 'weather']}, {'exemplar_feature': 'forecaster', 'feature_properties': ['weather']}, {'exemplar_feature': 'four', 'feature_properties': ['a', 'air', 'animal', 'band', 'bass', 'bear', 'bed', 'board', 'body', 'boundary', 'box', 'button', 'camel', 'captain', 'car', 'card', 'carriage', 'case', 'cat', 'cell', 'chair', 'chicken', 'class', 'clover', 'college', 'common_time', 'count', 'cow', 'cross', 'crowd', 'cube', 'darkness', 'day', 'deck', 'deer', 'desk', 'dog', 'dollar', 'door', 'drive', 'eight', 'family', 'feline', 'finger', 'fire', 'five', 'fourth', 'gallon', 'general', 'gospel', 'hand', 'highway', 'home', 'horse', 'hour', 'house', 'ides', 'jeep', 'liter', 'lizard', 'lock', 'mammal', 'mark', 'mess', 'mile', 'mole', 'month', 'mule', 'napkin', 'nones', 'number', 'office', 'oil', 'olympiad', 'page', 'paper', 'picture', 'pie', 'pig', 'puppy', 'quadrennium', 'quadripara', 'quadruple', 'quadruplicate', 'quadruplicate', 'quarter', 'quartet', 'rabbit', 'rank', 'rectangle', 'rhombus', 'room', 'rotator_cuff', 'rule', 'seat', 'sheep', 'side', 'square', 'squirrel', 'stanza', 'stool', 'stop', 'string_quartet', 'table', 'tetra', 'tetrahedron', 'tetralogy', 'tetralogy_of_fallot', 'tetrameter', 'three', 'tractor', 'trapezoid', 'two', 'undergraduate', 'violin', 'wagon', 'wagon_wheel', 'wall', 'weather', 'wheel', 'window', 'year', 'five', 'fourth', 'number', 'three', 'two', 'value']}, {'exemplar_feature': 'front', 'feature_properties': ['address', 'arm', 'axle', 'back', 'back', 'barrage', 'bay', 'bomber_jacket', 'bosom', 'bow', 'brachycephaly', 'bumper', 'chest', 'coast', 'color', 'column', 'content', 'cover', 'diagonal', 'door', 'downstage', 'downstage', 'drive', 'entrance', 'facade', 'face', 'face', 'figurehead', 'flounder', 'forecastle', 'forefoot', 'forelock', 'foresight', 'foretop', 'frontage', 'frontal', 'garden', 'gate', 'grass', 'guard', 'head', 'home', 'hood', 'inaction', 'introduction', 'jacket', 'jet_engine', 'lawn', 'lead', 'leader', 'links', 'lip', 'lobby', 'mat', 'middle', 'motor', 'mug_shot', 'nose', 'pitch', 'pommel', 'porch', 'propeller', 'rear', 'rear', 'saddle_seat', 'shirtfront', 'side', 'sign', 'sinciput', 'stage', 'stick', 'tip', 'title_page', 'toe', 'vestibule', 'vowel', 'weather', 'wheelbase', 'windshield', 'yard', 'aspect', 'back', 'direction', 'facade', 'facing', 'forward', 'lead', 'line', 'position', 'positive', 'preposition', 'rear', 'side']}, {'exemplar_feature': 'general', 'feature_properties': ['acidity', 'admiral', 'air', 'alcohol', 'animal', 'area', 'army', 'art', 'ballpark', 'beverage', 'blanket', 'bone', 'captain', 'charade', 'child', 'circle', 'clock', 'coin', 'color', 'command', 'commander', 'common_good', 'company', 'composition', 'concrete', 'condition', 'conflagration', 'conflict', 'country', 'cover', 'creature', 'crowd', 'dam', 'deduction', 'digression', 'disease', 'distance', 'do', 'dog', 'dress', 'drink', 'english', 'estimate', 'event', 'exercise', 'experiment', 'faith', 'feline', 'fellow', 'fish', 'flower', 'fuel', 'furcula', 'furor', 'g', 'game', 'gen', 'generality', 'generalization', 'generalship', 'goddess', 'grain', 'ground', 'hannibal', 'heat', 'heavy', 'high', 'home', 'kill', 'lieutenant_general', 'liquor', 'living_room', 'local', 'machine', 'mammal', 'material', 'matter', 'mean', 'meridian', 'money', 'morning', 'motion', 'move', 'music', 'name', 'nation', 'noise', 'oil', 'operation', 'organ', 'outline', 'pandemic', 'party', 'paste', 'person', 'pet', 'philosophy', 'place', 'plant', 'play', 'produce', 'public', 'public', 'publication', 'rank', 'relation', 'religion', 'road', 'royal', 'science', 'seat', 'servant', 'shoe', 'size', 'song', 'sort', 'sound', 'specificity', 'spice', 'structure', 'surprise', 'synthesis', 'thing', 'time', 'toy', 'trade_book', 'transduction', 'trip', 'universal', 'urethane', 'vacation', 'vehicle', 'vessel', 'way', 'weather', 'wood', 'work', 'wound', 'xenophon', 'above', 'admiral', 'army', 'army_officer', 'authority', 'basic', 'battle', 'boss', 'captain', 'command', 'commander', 'eisenhower', 'five', 'flag', 'flag_officer', 'form', 'four', 'guy', 'high', 'leader', 'main', 'man', 'may', 'military', 'military_leader', 'military_officer', 'military_position', 'military_rank', 'nave', 'navy', 'nothing', 'officer', 'official', 'person', 'picture', 'position', 'rank', 'ranking', 'relativity', 'seating', 'soldier', 'standard', 'star', 'store', 'superior', 'top', 'uniform', 'veteran', 'war']}, {'exemplar_feature': 'hail', 'feature_properties': ['a', 'call', 'hailstone', 'herald', 'ice', 'meteor', 'precipitation', 'rain', 'salve', 'summer', 'thunderstorm', 'weather', 'ball', 'baseball', 'golf', 'golf_ball', 'ice', 'precipitation', 'rain', 'small', 'storm', 'weather', 'worship']}, {'exemplar_feature': 'happening', 'feature_properties': ['abyss', 'accidental', 'accidental', 'affair', 'chic', 'contingency', 'cooking', 'cry', 'current', 'danger', 'dream', 'event', 'hap', 'inevitable', 'news', 'now', 'now', 'occasion', 'occurrence', 'odds', 'party', 'proceeding', 'procession', 'rarity', 'result', 'surprise', 'thunder', 'trouble', 'wave', 'weather', 'writing']}, {'exemplar_feature': 'humidity', 'feature_properties': ['advection', 'air_conditioner', 'comfort_zone', 'damp', 'fog', 'fox', 'hygrometer', 'hygroscope', 'saturation', 'stickiness', 'weather', 'greenhouse_effect']}, {'exemplar_feature': 'hurricane', 'feature_properties': ['anticyclone', 'cyclone', 'depression', 'disaster', 'dust_devil', 'eye', 'landfall', 'monsoon', 'storm', 'storm', 'tornado', 'typhoon', 'typhoon', 'typhoon', 'weather', 'wind', 'wind', 'cyclone', 'destruction', 'disaster', 'event', 'florida', 'force', 'gale', 'high', 'natural', 'ocean', 'rain', 'storm', 'tornado', 'water', 'weather', 'wind']}, {'exemplar_feature': 'lightning', 'feature_properties': ['arc', 'attachment', 'bolt', 'bolt', 'electricity', 'energy', 'flash', 'fulminate', 'hurricane', 'meteor', 'nitrogen_cycle', 'opal', 'power', 'rod', 'shock', 'storm', 'thunder', 'thunder', 'thunderbolt', 'thunderclap', 'thunderstorm', 'volt', 'weather', 'whistler', 'electric', 'electricity', 'flash', 'storm', 'thunder', 'yellow']}, {'exemplar_feature': 'like', 'feature_properties': ['above', 'accord', 'affair', 'affect', 'air', 'allegory', 'alligator', 'aluminum', 'anticipation', 'apple', 'apricot', 'arm', 'army', 'art', 'asphalt', 'atom', 'avenue', 'average', 'banker', 'bar', 'bass', 'bat', 'battle', 'bay', 'bear', 'bed', 'belly', 'bill', 'birthday', 'biscuit', 'bit', 'bite', 'bitter', 'blood_brother', 'blow', 'blue', 'board', 'boat', 'bone', 'boulder', 'boy', 'branch', 'brass', 'break', 'brethren', 'broad', 'bronze', 'brook', 'brother', 'brush', 'bullet', 'burn', 'butter', 'butterfly', 'cabbage', 'cake', 'call', 'canine', 'capital', 'capsule', 'car', 'card', 'case', 'casket', 'cathedral', 'cell', 'century', 'chair', 'chapel', 'character', 'chemise', 'chew', 'chick', 'chicken', 'circle', 'circus', 'city', 'clarinet', 'class', 'clear', 'climb', 'clock', 'closer', 'club', 'coal', 'coast', 'coat', 'coil', 'coin', 'cold', 'college', 'colony', 'color', 'column', 'comfort', 'commonality', 'company', 'comparison', 'continent', 'cool', 'copy', 'corn', 'corporation', 'cost', 'cotton', 'count', 'country', 'cover', 'crab', 'creature', 'crop', 'crowd', 'crown', 'crush', 'cry', 'cucumber', 'current', 'cut', 'dad', 'dance', 'danger', 'darkness', 'date', 'daughter', 'deal', 'department', 'desert', 'desk', 'destroyer', 'dictionary', 'discipline', 'disease', 'disinfectant', 'dislike', 'dispute', 'dividend', 'division', 'dock', 'doctor', 'doll', 'dollar', 'door', 'dormer', 'double', 'draw', 'dream', 'dress', 'drink', 'drive', 'drop', 'dry', 'duck', 'due', 'earth', 'edge', 'ego', 'emerald', 'enemy', 'energy', 'enough', 'event', 'extermination', 'eye', 'fair', 'familiar', 'fanlight', 'fantasy', 'farewell', 'farm', 'fast', 'fear', 'feed', 'feel', 'feline', 'ferry', 'fetish', 'field', 'finger', 'firewood', 'fit', 'flea', 'flock', 'fly', 'foot', 'forklift', 'form', 'fraud', 'fury', 'game', 'garden', 'gin', 'give', 'glass', 'glutton', 'gold', 'grain', 'gravel', 'great', 'green', 'ground', 'habit', 'hamster', 'hand', 'handle', 'hang', 'harpsichord', 'hay', 'heat', 'heavy', 'hedge', 'highway', 'hill', 'history', 'hog', 'home', 'hope', 'horse', 'hour', 'house', 'hut', 'i', 'institution', 'interest', 'iron', 'jelly', 'jelly_bean', 'junction', 'keg', 'kill', 'kin', 'kind', 'klaxon', 'knitting', 'lake', 'large', 'laugh', 'laughter', 'law', 'leek', 'leg', 'let', 'lift', 'likeness', 'liking', 'lime', 'liquid', 'list', 'little', 'local', 'look', 'lord', 'love', 'love', 'machine', 'manner', 'maroon', 'mass', 'material', 'may', 'maze', 'mean', 'measles', 'meconopsis', 'might', 'mile', 'mimic', 'mind', 'minister', 'minute', 'mist', 'mole', 'moment', 'money', 'month', 'monument', 'moon', 'moth', 'mother', 'motor', 'mountain', 'movie', 'much', 'music', 'must', 'napkin', 'nation', 'native', 'nay', 'need', 'nerve', 'net', 'ninja', 'none', 'note', 'number', 'nutmeg', 'ocean', 'offer', 'oil', 'oil_shale', 'operation', 'organ', 'organization', 'otter', 'page', 'pain', 'paper', 'particular', 'paste', 'pear', 'permit', 'person', 'petal', 'phone', 'phrase', 'picture', 'pig', 'pigeon', 'pimple', 'pin', 'plant', 'plate', 'play', 'pliers', 'plug', 'plum', 'point', 'polish', 'pope', 'port', 'possible', 'post', 'pouch', 'power', 'predilection', 'preserve', 'press', 'price', 'print', 'proctoscope', 'produce', 'profession', 'projectile', 'protest', 'psychologist', 'punishment', 'purpose', 'push', 'quality', 'quarrel', 'quill', 'rabbit', 'rain', 'ram', 'raspberry', 'rat', 'rate', 'rate', 'rating', 'read', 'reading', 'reason', 'record', 'rectangle', 'regard', 'relation', 'religion', 'rent', 'reply', 'republic', 'rest', 'reward', 'rhombus', 'riddle', 'ring', 'river', 'road', 'robbery', 'rock', 'roll', 'round', 'royal', 'rub', 'rule', 'ruler', 'run', 'salt', 'sand', 'sapropel', 'say', 'school', 'science', 'scream', 'sea', 'seal', 'seat', 'servant', 'shade', 'sheep', 'shell', 'shilling', 'shower', 'sign', 'silk', 'silver', 'simile', 'sine', 'sister', 'size', 'slave', 'slip', 'slope', 'smash', 'smile', 'smoke', 'sneeze', 'snow', 'snub', 'sob', 'son', 'song', 'sound', 'soup', 'squirrel', 'staple', 'start', 'steam', 'steel', 'steel_blue', 'step', 'stew', 'stick', 'stitch', 'stone', 'story', 'street', 'stretch', 'string', 'structure', 'supper', 'surprise', 'sweet', 'sweetheart', 'table', 'taconite', 'talk', 'taste', 'terrestrial_planet', 'test', 'thong', 'thumb', 'thunder', 'tin', 'tornado', 'toy', 'trade', 'tree', 'trick', 'turn', 'twist', 'tyrant', 'underfelt', 'university', 'value', 'van', 'velvet', 'verse', 'vessel', 'violet', 'vitrification', 'volt', 'wall', 'walrus', 'war', 'wash', 'waste', 'watch', 'wave', 'wax', 'way', 'weather', 'web', 'weight', 'will', 'wind', 'window', 'wine', 'wishful_thinking', 'wood', 'wool', 'word', 'worm', 'writing', 'affection', 'affinity', 'appreciation', 'attraction', 'care', 'desire', 'emotion', 'enjoyment', 'feel', 'feeling', 'fondness', 'interest', 'kind', 'love', 'preference', 'resemblance', 'rubbish', 'similarity', 'simile', 'sort', 'term', 'way']}, {'exemplar_feature': 'local', 'feature_properties': ['academy', 'air_pocket', 'baal', 'branch', 'bylaw', 'cacique', 'chapter', 'city', 'city_desk', 'commune', 'community', 'consistency', 'consul', 'council', 'diplomatic_immunity', 'ferry', 'festival', 'fire_brigade', 'fire_department', 'ischemia', 'liberty', 'local_option', 'localism', 'location', 'locus', 'long_distance', 'manifold', 'native', 'news', 'numen', 'opalescence', 'phyle', 'resident', 'rule', 'sales_tax', 'school_district', 'shopper', 'soft_money', 'sun', 'tax_return', 'timekeeping', 'toll_call', 'town_hall', 'vicar', 'warlord', 'water_tower', 'weather', 'adjective', 'area', 'being', 'city', 'definition', 'domestic', 'general', 'government', 'here', 'home', 'inhabitant', 'like', 'location', 'locator', 'locus', 'native', 'neighborhood', 'news', 'place', 'term', 'town', 'vicinity']}, {'exemplar_feature': 'meteorology', 'feature_properties': ['aerology', 'aerology', 'agronomy', 'earth_science', 'geophysics', 'meteor', 'meteoroid', 'meteorologist', 'rain_gauge', 'spring', 'weather', 'aerology', 'beaufort_scale', 'rainbow']}, {'exemplar_feature': 'name', 'feature_properties': ['address', 'agent', 'alias', 'alias', 'alpha', 'animal', 'anomia', 'appellation', 'archery', 'arithmancy', 'ash', 'autograph', 'avenue', 'aviator', 'baptism', 'bill', 'binding', 'bloom', 'brandy', 'brassiere', 'bush', 'call', 'call', 'caller_id', 'canary', 'carol', 'carp', 'category', 'century', 'checklist', 'chick', 'chicken', 'child', 'china', 'coast', 'combustion', 'company', 'count', 'course', 'cranberry', 'crop', 'crystal', 'culture', 'dad', 'danger', 'date', 'deed_poll', 'denomination', 'department', 'descriptor', 'designatum', 'directory', 'drink', 'dub', 'duchess', 'earl', 'earth', 'end', 'enterprise', 'epithet', 'eponym', 'fellow', 'file', 'flower', 'form_genus', 'fortune', 'frank', 'ginger', 'girl', 'glory', 'hank', 'herd', 'highlight', 'homicide', 'horn', 'identity', 'initial', 'isle', 'jack', 'joy', 'junior', 'label', 'liberty', 'lily', 'little', 'lord', 'lorry', 'main', 'march', 'mark', 'mathematics', 'may', 'mercury', 'middle', 'mousse', 'nameplate', 'namer', 'namesake', 'naming', 'naming', 'naming', 'napoleon', 'nation', 'none', 'numeration', 'onomancy', 'onomasticon', 'onomastics', 'parcel', 'pat', 'paul', 'peg', 'pen_name', 'penicillin', 'person', 'personification', 'photograph', 'print', 'profession', 'professional', 'pseudonym', 'psychologist', 'quality', 'quarter', 'rabbit', 'raid', 'rattlesnake', 'respect', 'rhombus', 'rod', 'roll_call', 'rule', 'rumpelstiltskin', 'sabaoth', 'science', 'shape', 'sheepskin', 'sign', 'signature', 'sir', 'slug', 'smear', 'smoke', 'spike', 'spot', 'stone', 'street', 'stroke', 'sucker', 'sue', 'surname', 'synonym', 'tag', 'telegraph', 'telephone', 'tin', 'title', 'title', 'toponymy', 'trey', 'van', 'vehicle', 'violet', 'weather', 'west_germany', 'address', 'appellation', 'baby', 'baptism', 'birth', 'birth_certificate', 'bob', 'book', 'call', 'certificate', 'characteristic', 'david', 'description', 'designation', 'epithet', 'family', 'family_history', 'first', 'general', 'given', 'greeting', 'hancock', 'handle', 'history', 'id', 'identification', 'identity', 'individualism', 'information', 'initial', 'introduction', 'john', 'label', 'license', 'man', 'mane', 'michael', 'middle', 'mister', 'nick', 'nominative', 'parts', 'paul', 'people', 'person', 'personal', 'phone', 'pronoun', 'pseudonym', 'recognition', 'reference', 'ruth', 'signature', 'specific', 'thomas', 'title', 'tom', 'two']}, {'exemplar_feature': 'natural', 'feature_properties': ['absolute', 'accidental', 'acquired_taste', 'act_of_god', 'animism', 'antagonism', 'aptitude', 'avalanche', 'beauty', 'bird', 'bottled_water', 'bridge', 'camouflage', 'cavern', 'celestial_body', 'child', 'chrome_yellow', 'civil_death', 'clerestory', 'cloud', 'coal', 'cohort', 'cotton', 'cubism', 'culture', 'deposition', 'dharma', 'disaster', 'ecoterrorism', 'ethane', 'exploitation', 'fatty_acid', 'fertilizer', 'fire', 'flair', 'flat', 'form_genus', 'fuel', 'gas', 'gift', 'green_thumb', 'gymnosophy', 'hay', 'herb', 'hill', 'hot_spring', 'humus', 'hurricane', 'immunity', 'issue', 'landmark', 'mechanism', 'mitomycin', 'moon', 'mountain', 'nandrolone', 'natal', 'native', 'natural_language', 'naturalness', 'nature', 'nest', 'nest_egg', 'nitrogen_cycle', 'nitrogen_fixation', 'oil', 'organic', 'outdoors', 'plain', 'preservative', 'propagation', 'propane', 'proportional', 'puppy_fat', 'rain', 'resonance', 'river', 'rock', 'science', 'sea', 'second_nature', 'seismology', 'sex_change', 'shade', 'shaft', 'silicone_rubber', 'silk', 'skylight', 'smooth', 'sophisticate', 'stone', 'sublimate', 'sugar', 'supernatural', 'synthetic', 'teleology', 'temperance', 'terrace', 'thunder', 'totem', 'venus', 'watercourse', 'weather', 'wilderness', 'wind', 'wood', 'wool', 'yang', 'yin']}, {'exemplar_feature': 'natural_phenomenon', 'feature_properties': ['rain', 'thunder', 'weather']}, {'exemplar_feature': 'news', 'feature_properties': ['article', 'beat', 'break', 'brief', 'bulletin', 'column', 'correspondent', 'current', 'fact', 'feed', 'good_word', 'herald', 'history', 'hook', 'journalism', 'latest', 'local', 'local', 'magazine', 'news_agency', 'newscast', 'newscaster', 'newspaper', 'newspaper', 'newsreel', 'paper', 'post', 'press', 'print', 'propagator', 'report', 'reporter', 'roundup', 'scoop', 'sidebar', 'skeet', 'sound_bite', 'sportscast', 'story', 'syndication', 'think_piece', 'trouble', 'weather', 'word', 'affairs', 'affiliate', 'anagram', 'anchor', 'announcement', 'announcer', 'article', 'bad', 'boring', 'broadcast', 'bulletin', 'category', 'channel', 'chicago', 'clock', 'coffee', 'communication', 'content', 'contents', 'current', 'daily', 'date', 'day', 'days', 'east', 'election', 'evening', 'event', 'few', 'five', 'fodder', 'fox', 'freshness', 'giving', 'gossip', 'grey', 'happening', 'headline', 'information', 'jew', 'journal', 'journalism', 'journalist', 'latest', 'line', 'local', 'magazine', 'major', 'man', 'mass', 'material', 'morning', 'national', 'network', 'newspaper', 'north', 'notice', 'novel', 'now', 'paper', 'passing', 'people', 'periodical', 'pew', 'post', 'presenter', 'press', 'print', 'program', 'public', 'public_knowledge', 'radio', 'read', 'reading', 'relevance', 'report', 'scoop', 'section', 'service', 'show', 'six', 'source', 'south', 'spread', 'stand', 'story', 'stuff', 'tabloid', 'television', 'television_program', 'telling', 'times', 'today', 'type', 'update', 'washington', 'weather', 'weatherman', 'west', 'world', 'writing']}, {'exemplar_feature': 'nice', 'feature_properties': ['account', 'affair', 'affirmation', 'bar', 'beauty', 'bed', 'bosom', 'busybody', 'cake', 'capital', 'care', 'case', 'chick', 'child', 'clear', 'clock', 'cloud', 'coat', 'company', 'cover', 'crown', 'dance', 'day', 'deduction', 'department', 'dormitory', 'dream', 'dress', 'drop', 'farmer', 'fellow', 'figure', 'fine', 'flea', 'flower', 'friend', 'good', 'great', 'grocer', 'heat', 'horse', 'irritation', 'joy', 'kind', 'lady', 'last', 'lobster', 'manners', 'mean', 'mist', 'money', 'music', 'napkin', 'niceness', 'nose', 'office', 'pain', 'paint', 'paper', 'party', 'print', 'rest', 'ring', 'rise', 'scent', 'selection', 'semester', 'servant', 'shade', 'sheep', 'silk', 'sound', 'speaker', 'statue', 'steak', 'steam', 'stop', 'style', 'summer', 'surprise', 'tourist', 'toy', 'tree', 'view', 'weather', 'window', 'wool', 'france', 'kind']}, {'exemplar_feature': 'now', 'feature_properties': ['acre', 'air', 'bedpan', 'bog', 'bush', 'castle', 'charade', 'cloakroom', 'current', 'date', 'demand', 'dog_days', 'due', 'few', 'floor', 'former', 'future', 'game', 'gas', 'greek_alphabet', 'hand', 'here', 'high', 'hong_kong', 'john', 'leave', 'may', 'modern', 'moment', 'news', 'oil', 'okra', 'past', 'present', 'present', 'shade', 'signpost', 'smile', 'start', 'still', 'summer', 'then', 'time', 'type', 'weather', 'writing', 'xi', 'xian', 'yard', 'year', 'adjective', 'begin', 'current', 'definition', 'future', 'happening', 'here', 'immediacy', 'moment', 'national', 'organization', 'past', 'period', 'present', 'reference', 'right', 'signal', 'then', 'time', 'time_period', 'timing', 'today', 'urgency']}, {'exemplar_feature': 'outdoors', 'feature_properties': ['barbecue', 'bowling', 'camp', 'coat', 'farm', 'garden', 'ground', 'hot_tub', 'lawn_chair', 'marching_band', 'market', 'mountain', 'nature', 'outside', 'sky', 'squirrel', 'weather']}, {'exemplar_feature': 'outside', 'feature_properties': ['affair', 'atmosphere', 'bark', 'bird', 'body', 'bread', 'camp', 'coat', 'cookout', 'country', 'cover', 'crowd', 'deck', 'edge', 'evening', 'external', 'extra', 'farm', 'farmer', 'field', 'fish', 'garden', 'gate', 'gate', 'grass', 'ground', 'hall', 'inside', 'lantern', 'lip', 'market', 'nature', 'nest', 'night', 'out', 'outfield', 'peel', 'plant', 'play', 'porch', 'public', 'rain', 'saw', 'shade', 'shell', 'shutter', 'sideline', 'sky', 'snow', 'space', 'street', 'surface', 'tin', 'tramline', 'umbilical_cord', 'upstairs', 'veranda', 'view', 'weather', 'wind', 'window', 'winter', 'wool']}, {'exemplar_feature': 'overall', 'feature_properties': ['art', 'grade', 'health', 'slop', 'strategy', 'tout_ensemble', 'war', 'weather', 'welfare_state']}, {'exemplar_feature': 'overcast', 'feature_properties': ['ceiling', 'cloud', 'over', 'weather', 'whip']}, {'exemplar_feature': 'pattern', 'feature_properties': ['alternation', 'antiferromagnetism', 'arabesque', 'argyle', 'back', 'barring', 'beat', 'bond', 'box', 'breeder', 'camouflage', 'camouflage', 'capture', 'check', 'checkerboard', 'chicken_wire', 'concept', 'constellation', 'copperplate', 'crisscross', 'damascus_steel', 'damask', 'data_mining', 'denim', 'derailment', 'dermatoglyphics', 'design', 'design', 'diamondback', 'diaper', 'double_time', 'draft', 'drainage_system', 'drawing_room', 'example', 'fingerprint', 'flash', 'font', 'form', 'fur', 'gestalt', 'grid', 'ground_bass', 'guide', 'guilloche', 'harlequin', 'herringbone', 'indian_club', 'lace', 'lace', 'ladder', 'liquid_crystal_display', 'loam', 'lobe', 'mackerel_sky', 'major_scale', 'mask', 'meter', 'milk_snake', 'modality', 'mold', 'motif', 'muster', 'outlier', 'pane', 'pantograph', 'paper_tape', 'paradigm', 'paragon', 'pat', 'patron', 'patternmaker', 'phi', 'plain', 'platform', 'pompadour', 'print', 'print', 'prosody', 'protractor', 'rain', 'reflection', 'regular', 'repeat', 'repeater', 'reticulum', 'rhythm', 'sample', 'scansion', 'shaping', 'showerhead', 'signature', 'slicker', 'stencil', 'still_life', 'stitch', 'storm', 'strickle', 'stripe', 'stripe', 'stylization', 'swatch', 'swoosh', 'syndrome', 'synthesizer', 'target', 'template', 'territoriality', 'tessellation', 'thunder', 'tide', 'trade_secret', 'training', 'trope', 'tweed', 'twill', 'vein', 'vibrator', 'waffle', 'wave', 'weather', 'zigzag', 'checkers', 'clothing', 'design', 'polka', 'redundancy', 'sewing']}, {'exemplar_feature': 'phenomenon', 'feature_properties': ['antiferromagnetism', 'apparition', 'appearance', 'aurora', 'austrian', 'cause', 'cirrostratus', 'cloud', 'comet', 'cyclone', 'denial', 'effect', 'effect', 'exhalation', 'fad', 'ferromagnetism', 'flash', 'frequency', 'glory', 'hypothesis', 'isomerism', 'kymograph', 'mass_hysteria', 'mechanism', 'meteor', 'midnight_sun', 'mirage', 'noun', 'period', 'physicist', 'pleochroism', 'quantum', 'rain', 'razor', 'repeater', 'salve', 'self', 'snow', 'sound', 'theory', 'thunder', 'transient', 'typhoon', 'typhoon', 'unemployment', 'vanishing_point', 'weather', 'wind']}, {'exemplar_feature': 'precipitation', 'feature_properties': ['air_mass', 'cloud', 'drought', 'fog', 'front', 'hail', 'hail', 'hailstone', 'mist', 'platinum_black', 'precipitant', 'precipitant', 'precipitate', 'precipitator', 'rain', 'rain_shadow', 'runoff', 'sedimentary_rock', 'sheet', 'shower', 'sleet', 'snow', 'snow', 'stratus', 'tree', 'weather', 'weather', 'windstorm', 'global_warming', 'haste', 'monsoon', 'rain_gauge']}, {'exemplar_feature': 'prediction', 'feature_properties': ['augury', 'autotype', 'bracket', 'cassandra', 'dope_sheet', 'fortune', 'futurism', 'howler', 'napoleon', 'plan', 'presage', 'prevision', 'prognosis', 'prophecy', 'statistical_mechanics', 'weather', 'weather_forecast']}, {'exemplar_feature': 'program', 'feature_properties': ['acrobat', 'affirmative_action', 'algorithm', 'applet', 'aspect', 'assembler', 'assertion', 'assistant', 'audience', 'back_door', 'batch_processing', 'binding', 'boilerplate', 'bot', 'branch', 'classifier', 'code', 'command', 'compiler', 'compressor', 'copybook', 'countdown', 'database_management_system', 'deadlock', 'deforestation', 'disambiguator', 'door', 'drip', 'driver', 'dump', 'easter_egg', 'editor', 'emulation', 'escape', 'event', 'exchange', 'execution', 'expose', 'footprint', 'fork', 'game', 'gem', 'guard', 'indexer', 'interceptor', 'interpreter', 'jitter', 'listing', 'load', 'local', 'logic_diagram', 'macro', 'messenger', 'module', 'monitor', 'network', 'news', 'newsreader', 'nibbler', 'number_cruncher', 'oceanography', 'office', 'overlay', 'packer', 'perestroika', 'persecution', 'pinger', 'playbill', 'poke', 'port', 'portability', 'prelude', 'process', 'programmer', 'programming', 'programming', 'programming', 'pump', 'punter', 'racism', 'reply', 'rerun', 'rummage_sale', 'run', 'run', 'safety_net', 'sandbox', 'segment', 'series', 'server', 'service', 'shell', 'show', 'simulcast', 'situation_comedy', 'soap', 'software_package', 'spot', 'spyware', 'studio', 'tagger', 'tax', 'telecast', 'terminal', 'text_editor', 'theme', 'theme_song', 'time_bomb', 'toolbox', 'tosser', 'transcriber', 'transition', 'troubleshooter', 'view', 'viewer', 'virus', 'von_neumann_machine', 'weather', 'worm', 'wormhole']}, {'exemplar_feature': 'rain', 'feature_properties': ['boot', 'bucket', 'cloud', 'coal', 'coat', 'cry', 'downpour', 'downpour', 'draw', 'drip', 'drizzle', 'drizzle', 'drop', 'dry_season', 'flood', 'glaze', 'gutter', 'gutter', 'hail', 'hurricane', 'hurricane', 'ice_storm', 'jacket', 'kachina', 'lithophyte', 'louver', 'malaria', \"mare's_tail\", 'meteor', 'mist', 'moisture', 'monsoon', 'monsoon', 'nitrogen_cycle', 'pain', 'pelter', 'point', 'precipitate', 'precipitate', 'precipitation', 'puddle', 'pula', 'rainbow', 'raincoat', 'rainmaking', 'rainy_season', 'river_basin', 'scat', 'scud', 'seeder', 'shower', 'sleet', 'sleet', 'snow', 'soak', 'soprano', 'storm', 'thunder', 'thundershower', 'thunderstorm', 'umbrella', 'umbrella', 'virga', 'washout', 'water', 'water', 'weather', 'weather_radar', 'windshield_wiper', 'acid_rain', 'bad', 'bad_weather', 'clear', 'cloud', 'cold', 'condensation', 'condition', 'crying', 'down', 'downpour', 'drizzle', 'droplet', 'droppings', 'event', 'fall', 'global_warming', 'hail', 'like', 'liquid', 'making', 'moisture', 'monsoon', 'natural', 'natural_phenomenon', 'nature', 'outside', 'pattern', 'phenomenon', 'precipitation', 'produce', 'product', 'rain_gauge', 'season', 'shower', 'sky', 'sleet', 'snow', 'spring', 'storm', 'summer', 'thunder', 'thunderstorm', 'type', 'water', 'weather', 'weather_forecast', 'weather_radar', 'wetness']}, {'exemplar_feature': 'report', 'feature_properties': ['account', 'annual', 'article', 'blaze', 'brief', 'bulletin', 'call_up', 'claim', 'condition', 'debriefing', 'expense', 'eyewitness', 'failing', 'form', 'gunfire', 'hansard', 'news', 'news', 'position_paper', 'reporter', 'research', 'result', 'return', 'scoop', 'squawk', 'think_tank', 'voicer', 'weather', 'whistle_blower', 'accounting', 'announcement', 'assay', 'assignment', 'book', 'business', 'card', 'classroom', 'daily', 'data', 'description', 'document', 'documentary', 'essay', 'explanation', 'feedback', 'file', 'final', 'flash', 'gather', 'give', 'giving', 'grade', 'home', 'homework', 'information', 'journalism', 'journalist', 'material', 'message', 'news', 'office', 'paper', 'presentation', 'progress', 'project', 'refrigerator', 'research', 'result', 'review', 'school', 'school_assignment', 'short', 'statement', 'status', 'student', 'summary', 'take', 'tell', 'telling', 'title', 'update', 'work', 'writing']}, {'exemplar_feature': 'season', 'feature_properties': ['asparagus', 'bioclimatology', 'christmas', 'clip', 'condiment', 'costume', 'curry', 'deduction', 'devil', 'dionysia', 'double', 'eastertide', 'ember', 'fall', 'farrow', 'greenhouse', 'harvest', 'herb', 'hour', 'kitchen', 'leap_year', 'monsoon', 'monsoon', 'olive', 'pass', 'perennation', 'preseason', 'preseason', 'quarter', 'rain', 'revolution', 'salt', 'sauce', 'seasoner', 'seasoning', 'sneeze', 'snow', 'spice', 'spice', 'spring', 'spring', 'summer', 'summer', 'tide', 'turn', 'twelfthtide', 'vinegar', 'vintage', 'weather', 'winter', 'winter', 'annual', 'division', 'fall', 'section', 'spring', 'summer', 'winter', 'year']}, {'exemplar_feature': 'segment', 'feature_properties': ['act', 'android', 'annelid', 'arc', 'arthromere', 'article', 'battle', 'bone', 'chunk', 'classification', 'colon', 'cone', 'course', 'day', 'district', 'drop', 'episode', 'epoch', 'execution', 'great_circle', 'hour', 'inch', 'introduction', \"jacob's_ladder\", 'line', 'line', 'loment', 'lot', 'mediatrix', 'metamere', 'millipede', 'minute', 'month', 'note', 'part', 'petal', 'petiole', 'pie_chart', 'piece', 'room', 'scene', 'sector', 'slice', 'spot', 'stitch', 'stretch', 'suture', 'translocation', 'transposon', 'verse', 'weather', 'word', 'wraparound', 'part']}, {'exemplar_feature': 'sky', 'feature_properties': ['above', 'afterglow', 'air', 'airspace', 'altitude', 'anshar', 'atmosphere', 'aurora', 'bird', 'blue', 'blue', 'bridge', 'building', 'cirrostratus', 'clear', 'cloud', 'constellation', 'crane', 'cry', 'dark', 'day', 'drop', 'earth', 'equinox', 'ether', 'evening', 'evening_star', 'expanse', 'exposure', 'fall', 'fly', 'force', 'fox', 'god', 'ground', 'ground', 'hawk', 'heaven', 'heaven', 'high', 'horizon', 'horus', 'hyaline', 'kite', 'land', 'landscape', 'lift', 'loft', 'milky_way', 'moon', 'mountain', 'nature', 'nut', 'overcast', 'overhead', 'parhelion', 'pavilion', 'rain', 'rainbow', 'raindrop', 'rocket', 'skylark', 'skyline', 'skyscraper', 'snow', 'soar', 'space', 'star', 'star_chart', 'sun', 'sunrise', 'sunset', 'thunder', 'uranus', 'vault', 'water', 'weather', 'why', 'above', 'air', 'airplane', 'area', 'astrology', 'atmosphere', 'azure', 'big_blue', 'blue', 'ceiling', 'cloud', 'color', 'cry', 'earth', 'expanse', 'fly', 'fry', 'grey', 'ground', 'head', 'heaven', 'high', 'home', 'horizon', 'land', 'location', 'look', 'nothing', 'open', 'outdoors', 'outside', 'over', 'overhead', 'ozone', 'parachute', 'place', 'roof', 'room', 'sea', 'space', 'star', 'straight', 'sun', 'there', 'twinkle', 'vodka', 'why']}, {'exemplar_feature': 'sleet', 'feature_properties': ['precipitation', 'rain', 'snow', 'thunderstorm', 'weather', 'mix', 'precipitation', 'rain', 'snow', 'type']}, {'exemplar_feature': 'snow', 'feature_properties': ['apple', 'avalanche', 'avalanche', 'board', 'cavalcade', 'christmas', 'cloud', 'cold', 'cornice', 'cotton', 'crud', 'deposition', 'dogsled', 'footprint', 'frost', 'ice', 'icehouse', 'igloo', 'leopard', 'meltwater', 'meteor', 'mountain', 'mush', 'mush', 'paper', 'poison', 'posthole', 'powder', 'precipitate', 'precipitate', 'precipitation', 'rain', 'river_basin', 'salt', 'ski', 'ski_slope', 'skiff', 'sleet', 'sleet', 'slope', 'slush', 'slush', 'snowball', 'snowcap', 'snowfield', 'snowflake', 'snowmobile', 'spindrift', 'stall', 'stick', 'sugar', 'thaw', 'thunderstorm', 'virga', 'weather', 'white', 'white', 'winter', 'accumulation', 'alaska', 'base', 'blizzard', 'christmas', 'cocaine', 'cold', 'cold_water', 'cold_weather', 'coldness', 'condensation', 'condition', 'crystal', 'dandruff', 'december', 'drifting', 'event', 'fall', 'fields', 'fluff', 'freeze', 'frost', 'hailstorm', 'ice', 'like', 'liquid', 'making', 'marshmallow', 'material', 'mist', 'mountain', 'north', 'north_pole', 'outside', 'particle', 'people', 'phenomenon', 'pole', 'powder', 'precipitation', 'product', 'raid', 'rain', 'season', 'sight', 'ski', 'skiing', 'sky', 'sledding', 'sleet', 'solid', 'storm', 'stuff', 'surface', 'test', 'thirty', 'time', 'two', 'water', 'weather', 'wetness', 'white', 'white_water', 'whiteness', 'winder', 'winter', 'wonderland']}, {'exemplar_feature': 'spring', 'feature_properties': ['bath', 'bb_gun', 'bed', 'bilge', 'bloom', 'break', 'bunt', 'cam', 'centaurus', 'chloris', 'clockwork', 'coil', 'crater', 'crinkleroot', 'daffodil', 'equinox', 'fall', 'fauna', 'flower', 'font', 'fountain', 'fountain_of_youth', 'fountainhead', 'geyser', 'grass', 'groundhog_day', 'grus', 'hairspring', 'head', \"hooke's_law\", 'hot_spring', 'hydra', 'jumper', 'lynx', 'mainspring', 'march', 'mattress', 'mattress', 'may', 'microscopium', 'naiad', 'oasis', 'ozone_hole', 'phoenix', 'pond', 'potential_energy', 'prime_time', 'pussy_willow', 'pyxis', 'rain', 'roller_blind', 'run', 'sculptor', 'season', 'season', 'semester', 'shock_absorber', 'son', 'source', 'spring_break', 'sprinter', 'stocker', 'summer', 'sundress', 'switchblade', 'tide', 'tongs', 'tucana', 'tulip', 'upstart', 'vela', 'wall', 'wall', 'watering_place', 'weather', 'well', 'wellhead', 'wind', 'winker', 'winter', 'geyser', 'green', \"hooke's_law\", 'season', 'summer', 'well', 'winter']}, {'exemplar_feature': 'state', 'feature_properties': ['admissibility', 'adversity', 'affability', 'agony', 'airspace', 'alabama', 'alaska', 'alaskan', 'albany', 'ally', 'ambition', 'anarchism', 'annapolis', 'approval', 'arizona', 'arizonan', 'arkansan', 'arkansas', 'atlanta', 'attitude', 'attitude', 'audience', 'augusta', 'austin', 'awayness', 'barge', 'baton_rouge', 'bay_stater', 'beauty', 'beginning', 'being', 'bellingham', 'berlin', 'bill', 'bismarck', 'blip', 'blue_nile', 'boiling', 'boise', 'boyhood', 'brandenburg', 'break', 'california', 'californian', 'call', 'call', 'capital', 'capitalism', 'carson_city', 'case', 'cathedral', 'change_of_state', 'charleston', 'checkpoint', 'cheyenne', 'chihuahua', 'chin', 'china', 'circuit', 'circumstance', 'citizen', 'citizenship', 'city', 'claim', 'class', 'clip', 'colony', 'coloradan', 'colorado', 'columbia', 'columbus', 'comfort', 'commonwealth', 'commutation', 'concord', 'condemnation', 'condition', 'condition', 'confederation', 'confusion', 'connecticuter', 'containment', 'convert', 'core_dump', 'corporatist', 'corruption', 'country', 'crown', 'crown_jewels', 'crown_land', 'cruise_control', 'cry', 'cryptobiosis', 'danger', 'dead', 'decay', 'deity', 'delawarean', 'denver', 'department', 'dependence', 'des_moines', 'diarchy', 'discipline', 'disjunction', 'dismemberment', 'dissociation', 'district', 'divinity', 'dover', 'dream', 'drink', 'dry', 'duke', 'dysphoria', 'e', 'earl_marshal', 'easiness', 'east', 'economy', 'ecstasy', 'eden', 'electron_shell', 'emancipation', 'empire', 'empire', 'endearment', 'energy', 'entente', 'epiphenomenon', 'escheat', 'escheat', 'establishment', 'estate', 'evanescence', 'excitation', 'executive', 'exoneration', 'failure', 'fair', 'federal', 'federal_government', 'federalization', 'fettle', 'fit', 'fixture', 'flag', 'flip', 'florida', 'floridian', 'footing', 'former', 'frankfort', 'freeze', 'fulfillment', 'functionalism', 'furor', 'gas', 'georgian', 'germany', 'government', 'great_seal', 'grey_area', 'ground_state', 'hagerstown', 'hamas', 'han', 'han', 'hartford', 'hawaii', 'hawaiian', 'health', 'health', 'heat', 'heaven', 'helena', 'hesse', 'holiday', 'honolulu', 'hood', 'hyderabad', 'idahoan', 'illinoisan', 'imminence', 'impetuousness', 'incisiveness', 'indianapolis', 'individualism', 'innocence', 'insurance', 'interstate', 'interstate', 'inverse', 'ion', 'ionization', 'iowan', 'irredenta', 'isis', 'issue', 'jackson', 'jefferson_city', 'jersey', 'juneau', 'kachin', 'kansan', 'kansas', 'kentuckian', 'kentucky', 'keynesianism', 'king', 'lansing', 'latent_heat', 'law', 'legal_code', 'life', 'life', 'lincoln', 'line', 'liquid', 'litotes', 'little_rock', 'local_government', 'localization', 'louisiana', 'main', 'maine', 'mainer', 'malabsorption', 'malcontent', 'mam', 'manchuria', 'maoism', 'marylander', 'mass', 'mayhem', 'mercenary', 'mess', 'mexicali', 'michigander', 'mind', 'minnesota', 'minnesotan', 'mississippian', 'missourian', 'mode', 'monarchy', 'montana', 'montanan', 'montgomery', 'mood', 'motion', 'multiplicity', 'nashville', 'nation', 'nation', 'national_insurance', 'nationality', 'nature', 'nebraskan', 'nevadan', 'new_england', 'new_hampshirite', 'new_jersey', 'new_jerseyan', 'new_mexican', 'new_south_wales', 'new_york', 'north', 'north_carolina', 'north_carolinian', 'north_dakotan', 'northeast', 'nuncio', 'ohioan', 'oklahoma', 'oklahoma_city', 'oklahoman', 'old', 'olympia', 'oregon', 'oregonian', 'orizaba', 'ostracism', 'over', 'over', 'oxide', 'pacific_northwest', 'parenthood', 'particulate', 'peace', 'peacekeeping', 'penitentiary', 'pennsylvania', 'pennsylvanian', 'pennsylvanian', 'phase_space', 'phoenix', 'pierre', 'pin', 'pinning', 'pleasure', 'plight', 'poet_laureate', 'point', 'poise', 'policy', 'polity', 'predicate', 'prefixation', 'premise', 'presence', 'preserve', 'president', 'providence', 'public_law', 'public_property', 'puebla', 'purgatory', 'qin', 'quantum_leap', 'raleigh', 'ready', 'regression', 'reinstatement', 'relaxation_time', 'republic', 'republic', 'republicanism', 'reset', 'rest', 'restoration', 'restriction', 'reversible', 'rhode_islander', 'richmond', 'rollback', 'ruin', 'rush', 'sacramento', 'saint_paul', 'salem', 'sales_tax', 'salt_lake_city', 'satellite', 'saxony', 'sedition', 'separatism', 'shock', 'side_effect', 'singlet', 'slave_state', 'sleep', 'sleep', 'social_security', 'soft_money', 'south', 'south_carolinian', 'south_dakota', 'south_dakotan', 'sovereign_immunity', 'springfield', 'st', 'state_capital', 'state_capitalism', 'state_of_mind', 'state_socialism', 'statehouse', 'stater', 'statesman', 'stateswoman', 'status_quo', 'storm', 'sublimate', 'sublimation', 'sultan', 'sultanate', 'superposition', 'surgeon_general', 'suzerain', 'suzerainty', 'switch', 'syracuse', 'tallahassee', 'taxidermy', 'tennessean', 'territory', 'texan', 'texas', 'theocracy', 'toggle', 'topeka', 'totalitarian', 'trance', 'transcendence', 'transition', 'transportation', 'treasury', 'trenton', 'tribe', 'trinity', 'trust_territory', 'tyrol', 'ubiety', 'unbreakableness', 'union', 'united_kingdom', 'united_states', 'valence', 'vanity', 'variability', 'vermonter', 'vicinity', 'victorian', 'virginia', 'virginian', 'washingtonian', 'water', 'water_vapor', 'way', 'weather', 'west', 'west_virginian', 'white_heat', 'white_nile', 'whitey', 'wilderness', 'wisconsinite', 'world_power', 'wyomingite', 'yoga', 'zenith', 'zero_tolerance', 'zeta', 'america', 'area', 'being', 'country', 'county', 'department', 'division', 'estate', 'jersey', 'land', 'nation', 'new_jersey', 'province', 'statistics', 'status', 'unit', 'virginia']}, {'exemplar_feature': 'storm', 'feature_properties': ['adad', 'baal', 'barber', 'bastille_day', 'brewing', 'gale', 'hail', 'hurricane', 'hurricane', 'invention', 'lightning', 'lilith', 'loose_cannon', 'messenger', 'monsoon', 'operation', 'rain', 'rainstorm', 'rand', 'snow', 'squall', 'storm_cloud', 'storm_door', 'storminess', 'tempest', 'tempest', 'thunder', 'tornado', 'typhoon', 'weather', 'weather', 'wind', 'wind', 'windstorm', 'acid_rain', 'action', 'bad', 'bad_weather', 'blizzard', 'heavy', 'hurricane', 'lightning', 'pattern', 'rain', 'tempest', 'thunder', 'weather', 'wind']}, {'exemplar_feature': 'study', 'feature_properties': ['aerology', 'aerophilately', 'aesthetics', 'allergology', 'analysis', 'art', 'art', 'art_school', 'astronomy', 'bacteriology', 'biology', 'botany', 'botany', 'byway', 'cardiology', 'chemistry', 'class', 'classics', 'college', 'comparative', 'comparative_literature', 'con', 'concentration', 'conchology', 'cosmography', 'course', 'crammer', 'craniology', 'cryogenics', 'degree', 'dentistry', 'dermatoglyphics', 'desk', 'dictionary', 'diploma', 'electromagnetism', 'electronics', 'endocrinology', 'entomology', 'epigraphy', 'ethology', 'experiment', 'genealogy', 'geography', 'geography', 'glottochronology', 'group_dynamics', 'hagiography', 'harmony', 'heat', 'hematology', 'hermeneutics', 'histologist', 'historiography', 'history', 'history', 'horology', 'horse', 'humanism', 'hydrostatics', 'interpretation', 'jurisprudence', 'know', 'latinist', 'law', 'lesson', 'literature', 'logic', 'material', 'mathematics', 'mathematics', 'methodology', 'museum', 'mythology', 'oceanography', 'ornithology', 'orthography', 'paleoanthropology', 'paleography', 'penology', 'philately', 'phonics', 'phrontistery', 'plane_geometry', 'plodder', 'pneumatics', 'pore', 'posology', 'postdoctoral', 'probability_theory', 'psephology', 'psycholinguistics', 'psychology', 'psychology', 'reading', 'research', 'scatology', 'school', 'science', 'science', 'scrutiny', 'see', 'specialism', 'specialist', 'spectroscopy', 'statistician', 'stoichiometry', 'student', 'study_hall', 'summer_school', 'swot', 'swot', 'symbology', 'synagogue', 'take', 'teleology', 'test', 'thanatology', 'theology', 'theory', 'understudy', 'weather', 'zoologist', 'zoology']}, {'exemplar_feature': 'summer', 'feature_properties': ['aquila', 'badminton', 'break', 'breeze', 'cabin', 'caelum', 'camp', 'carina', 'coma_berenices', 'corn', 'cotton', 'cygnus', 'cymling', 'delphinus', 'dog_days', 'fall', 'fall_webworm', 'greenwood', 'halter', 'heat', 'hercules', 'labor_day', 'lemonade', 'lupus', 'lyra', 'madonna_lily', 'mensa', 'monsoon', 'northern_cross', 'ophiuchus', 'pictor', 'rain', 'reticulum', 'roe_deer', 'salad', 'sandal', 'school_day', 'season', 'season', 'seersucker', 'serpens', 'shade', 'sirius', 'soccer', 'spring', 'summer_stock', 'sunburn', 'sundress', 'thunder', 'trip', 'weather', 'winter', 'august', 'beach', 'climate', 'current', 'days', 'elephant', 'fall', 'green', 'hail', 'heat', 'hot_weather', 'hotel', 'hotness', 'july', 'june', 'may', 'middle', 'month', 'ms', 'nice', 'now', 'period', 'season', 'spring', 'sun', 'time', 'time_period', 'two', 'vacation', 'warmth', 'weather', 'winter', 'year']}, {'exemplar_feature': 'sun', 'feature_properties': ['afternoon', 'alpha_centauri', 'amaterasu', 'annular_eclipse', 'annulus', 'aphelion', 'astronomical_unit', 'aten', 'aurora', 'beam', 'bear', 'burn', 'celestial_body', 'circle', 'cloud', 'comet', 'dark', 'dawn', 'dawn', 'day', 'daylight', 'daylight', 'desert', 'digit', 'dry', 'earth', 'earth', 'east', 'eclipse', 'empire', 'energy', 'equinox', 'evening', 'exposure', 'filament', 'finger', 'fire', 'fixed_star', 'flower', 'full_moon', 'glare', 'granule', 'halo', 'hat', 'heat', 'heaven', 'heliograph', 'heliolatry', 'heliometer', 'heliopause', 'helios', 'horus', 'icarus', 'inferior', 'inferior_planet', 'ingress', 'insolation', 'light', 'liver_spot', 'lunar_year', 'lunisolar_calendar', 'macula', 'mercury', 'mercury', 'midnight_sun', 'minor_planet', 'moon', 'morning', 'nemesis', 'nergal', 'new_moon', 'node', 'noon', 'nutation', 'oort_cloud', 'parasol', 'parhelion', 'perihelion', 'photosphere', 'plage', 'planet', 'planet', 'precession', 'quadrature', 'ra', 'ray', 'red_giant', 'rise', 'shade', 'shadow', 'shamash', 'shamash', 'sidereal_year', 'sky', 'sol', 'solar_calendar', 'solar_eclipse', 'solar_energy', 'solar_flare', 'solar_prominence', 'solar_radiation', 'solar_system', 'solar_telescope', 'solar_year', 'spicule', 'star', 'star', 'starlight', 'stereo', 'summer', 'sun', 'sun_tea', 'sunburn', 'sunburn', 'sunhat', 'sunlight', 'sunlight', 'sunrise', 'sunset', 'sunset', 'sunspot', 'sunsuit', 'suntrap', 'superior_planet', 'supernova', 'syzygy', 'titan', 'transfiguration', 'tropic', 'tropic_of_cancer', 'tropic_of_capricorn', 'umbrella', 'weather', 'wu', 'year', 'year', 'yellow', 'yolk', 'zodiac', 'aphelion', 'ball', 'body', 'burning', 'celestial_body', 'center', 'central', 'circle', 'corona', 'culture', 'day', 'daylight', 'disk', 'earth', 'energy', 'fire', 'fusion', 'gas', 'give', 'heat', 'heating', 'hydrogen', 'light', 'local', 'maker', 'mass', 'mercury', 'million', 'molecule', 'moon', 'object', 'orbit', 'outer_space', 'parhelion', 'perihelion', 'planet', 'radiance', 'round', 'shining', 'sky', 'sol', 'solar_system', 'source', 'space', 'star', 'sun', 'system', 'tan', 'universe', 'warmth', 'way', 'yellow']}, {'exemplar_feature': 'sunlight', 'feature_properties': ['actinic_keratosis', 'chemosynthesis', 'day', 'greenhouse', 'heliograph', 'heliograph', 'morning', 'opalescence', 'ray', 'shade', 'shade', 'solar_cell', 'squint', 'sun_visor', 'sunbeam', 'sunbonnet', 'sunburst', 'sunray', 'vitamin_d', 'weather', 'day', 'sun', 'ultraviolet', 'yellow']}, {'exemplar_feature': 'system', 'feature_properties': ['ab', 'absolute_space', 'accounting', 'acre', 'adhocracy', 'age', 'airmail', 'animal', 'anticyclone', 'apoapsis', 'architecture', 'aristotelianism', 'back_door', 'binary', 'bionics', 'bitter', 'block_diagram', 'bone', 'boolean_logic', 'bot', 'branch', 'bulletin_board', 'bureaucracy', 'calendar', 'calisthenics', 'canal', 'canary', 'cartesian_plane', 'caste', 'catacomb', 'catharsis', 'centralism', 'challenge', 'chemical_weapon', 'circuitry', 'client', 'cohesion', 'collectivism', 'colonialism', 'communalism', 'compatibility', 'complex', 'consistency', 'constitution', 'containment', 'contention', 'conversation', 'court', 'cruise_control', 'democracy', 'descriptor', 'digestive_system', 'digit', 'disentangler', 'disorganization', 'door', 'doublet', 'duality', 'dumb_bomb', 'dump', 'dynamical_system', 'earth', 'economy', 'ecosystem', 'education', 'elitism', 'energy_level', 'environment', 'epinephrine', 'episteme', 'equilibrium', 'fan', 'fathom', 'federalism', 'fidelity', 'first_class', 'first_degree', 'frame_of_reference', 'galaxy', 'game', 'gavel', 'generative_grammar', 'ghetto_blaster', 'gold_standard', 'government', 'grade', 'ground_state', 'guidance', 'hair_cell', 'hawala', 'headroom', 'health', 'heartbeat', 'hieroglyph', 'histology', 'home_theater', 'homeopathy', 'homeostasis', 'hue', 'ignition', 'implementation', 'industrialism', 'inertial_guidance', 'information_technology', 'infrastructure', 'installation', 'institution', 'interference', 'interoperability', 'judge', 'judiciary', 'justice', 'justiciary', 'kink', 'laminar_flow', 'language', 'life_cycle', 'lifeline', 'linear_algebra', 'link', 'liter', 'logic', 'maintenance', 'man', 'matrix', 'memory', 'memory', 'merit', 'metrology', 'microcosm', 'mile', 'mixed_farming', 'model', 'module', 'moment', 'movement', 'national_insurance', 'native', 'nerve', 'nervous_system', 'net', 'network', 'neural_network', 'notation', 'number', 'omnirange', 'optimization', 'organization', 'palmistry', 'panic', 'panic', 'paradigm', 'patriot', 'peonage', 'periapsis', 'perturbation', 'philosophy', 'physical_chemistry', 'pipage', 'pipeline', 'planetary_gear', 'plaque', 'plexus', 'plumbing', 'polarization', 'portability', 'power_steering', 'primary_care', 'proaccelerin', 'provision', 'purkinje_fiber', 'rank', 'rate', 'religion', 'republic', 'resonance', 'revealed_religion', 'rhyming_slang', 'river', 'rule', 'scaffolding', 'scale', 'scaler', 'scheme', 'school', 'script', 'senate', 'septic_tank', 'sequencer', 'session', 'sewer', 'sewer_gas', 'signal_box', 'simulator', 'skeleton', 'slough', 'space', 'spark_gap', 'spreadsheet', 'statistical_mechanics', 'stele', 'streamer', 'stub', 'sun', 'sunnah', 'suspension', 'sweat', 'symbolic_logic', 'synchroscope', 'syncretism', 'systematism', 'systematization', 'taxation', 'taxonomy', 'telecommunication', 'telegraph', 'telerobotics', 'terminus', 'thermostat', 'thrash', 'throughput', 'thunk', 'toilet', 'tower', 'trade', 'transport', 'transport', 'tube', 'urinary_tract', 'urology', 'variety', 'ventilation', 'vibrator', 'victoria_cross', 'villeinage', 'visible_speech', 'voice_mail', 'wade', 'waterworks', 'weather', 'weight', 'welfare_state', 'wild_west', 'window', 'wire', 'wrinkle', 'yard', 'yoga', 'computer', 'method']}, {'exemplar_feature': 'temperature', 'feature_properties': ['absolute_zero', 'advection', 'air_conditioner', 'air_mass', 'body_temperature', 'boiling_point', \"boltzmann's_constant\", \"boyle's_law\", 'british_thermal_unit', 'calculus', 'calorie', 'candy_thermometer', 'celsius', 'celsius_scale', 'chill', 'cold', 'cold', 'cold', 'cold_fusion', 'coldness', 'comfort_zone', 'constantan', 'cool', 'cool', 'cooling', 'crucible', 'cryobiology', 'cryogenics', 'cryometer', 'cryostat', 'decalescence', 'deep_freeze', 'degree', 'degree', 'degree_centigrade', 'degree_fahrenheit', 'destructive_distillation', 'dew_point', 'digester', 'ethane', 'ethylene', 'eutectic', 'eutectic', 'fahrenheit', 'fahrenheit_scale', 'fata_morgana', 'ferrimagnetism', 'fever', 'freeze', 'freezing_point', 'front', 'frost', 'global_warming', 'growing_season', 'heat', 'heat_exhaustion', 'heat_pump', 'high', 'homeostasis', 'hot_spring', 'hydrogenation', 'hyperthermia', 'hypothermia', 'interferometer', 'isotherm', 'lapse', 'luminescence', 'mercury', 'metamorphic_rock', 'normothermia', 'oxyacetylene', 'propylene', 'pyroelectricity', 'pyrogen', 'pyrometer', 'pyrostat', 'radiation_pyrometer', 'radiomicrometer', 'red_giant', 'relative_density', 'retort', 'shade', 'solar_wind', 'solidus', 'steam', 'sunspot', 'superstrate', 'sweat', 'telethermometer', 'temp', 'temperance', 'therm', 'thermal', 'thermal', 'thermion', 'thermistor', 'thermocouple', 'thermodynamics', 'thermogram', 'thermograph', 'thermography', 'thermometer', 'thermometer', 'thermometry', 'thermoreceptor', 'thermos', 'thermostat', 'triiodothyronine', 'warmth', 'weather', 'weather', 'white_heat', 'winter', 'celsius', 'cold', 'coldness', 'fever', 'heat', 'hotness', 'measurement', 'number', 'reading', 'thermometer', 'warmth', 'weather']}, {'exemplar_feature': 'term', 'feature_properties': ['abbacy', 'abbreviation', 'account', 'affirmative', 'air', 'aisle', 'amplitude', 'animal', 'antecedent', 'art', 'atom', 'average', 'bank', 'beat', 'being', 'beloved', 'bill', 'bird', 'boarder', 'boarding_house', 'booster', 'boot', 'breach_of_contract', 'capital_expenditure', 'career', 'carrier', 'catachresis', 'cell', 'certificate_of_deposit', 'character', 'child', 'chord', 'city', 'climax', 'coefficient', 'coin', 'collection', 'color', 'column', 'company', 'compatriot', 'concession', 'concrete', 'condition', 'condition', 'conflict', 'conquest', 'consulate', 'consulship', 'continent', 'control', 'conversion', 'convertible', 'copy', 'coreference', 'correspondent', 'cosmological_constant', 'cost', 'country', 'course', 'cover', 'creature', 'croak', 'crop', 'crowd', 'cube', 'current', 'cut', 'degree', 'designatum', 'dictionary_definition', 'difference', 'disambiguator', 'disease', 'distance', 'divide', 'division', 'do', 'double', 'drink', 'entry', 'epithet', 'epithet', 'equivalence', 'event', 'evergreen', 'expense', 'experiment', 'express', 'extenuation', 'factor', 'feline', 'fellow', 'figure', 'final', 'finance', 'fish', 'flourish', 'force', 'friction', 'fuel', 'function', 'galaxy', 'game', 'gentleman', 'geography', 'geometric_series', 'glossary', 'grain', 'ground', 'half', 'health', 'heat', 'homicide', 'instructorship', 'inverse', 'john', 'joy', 'justiciary', 'land', 'language', 'lantern', 'legalism', 'lexeme', 'license', 'lift', 'like', 'limit', 'links', 'liquor', 'local', 'long_haul', 'lorry', 'machine', 'mass', 'mate', 'material', 'matrix', 'matter', 'mean', 'medium', 'melioration', 'memory', 'metalanguage', 'middle', 'midterm', 'miscarriage', 'money', 'motion', 'music', 'nation', 'noise', 'nome', 'note', 'noun', 'number', 'object', 'occasion', 'offer', 'organ', 'organization', 'ostensive_definition', 'party', 'person', 'pet', 'place', 'plant', 'plea', 'point', 'polynomial', 'presidency', 'profit', 'pronoun', 'property', 'protocol', 'punishment', 'quality', 'quantity', 'rate', 'recruit', 'recursive_definition', 'relation', 'relatum', 'religion', 'room', 'royal', 'run', 'schema', 'science', 'seat', 'secretaryship', 'semester', 'semester', 'servant', 'session', 'side', 'sir', 'size', 'slope', 'smash', 'sock', 'sound', 'square', 'stipulative_definition', 'stitch', 'structure', 'style', 'subsumption', 'subtraction', 'sue', 'sum', 'supply', 'surprise', 'surrender', 'tenure', 'termer', 'terminal', 'terminal', 'terminology', 'test', 'thread', 'time', 'toy', 'transpose', 'tree', 'trimester', 'trip', 'ultimatum', 'vacation', 'vessel', 'viceroyalty', 'viceroyship', 'way', 'weather', 'wood', 'word', 'work', 'wound', 'essay', 'length', 'limit', 'paper', 'school', 'semester', 'session', 'time', 'time_limit']}, {'exemplar_feature': 'thunder', 'feature_properties': ['bronte', 'cloud', 'flash', 'fulminate', 'hurricane', 'intonation', 'lightning', 'rain', 'rumble', 'rumble', 'set', 'seth', 'storm', 'thunderbolt', 'thunderer', 'thunderstorm', 'volt', 'weather', 'accompaniment', 'activity', 'air', 'bad', 'bad_weather', 'bang', 'black', 'bolt', 'boom', 'bowling', 'client', 'cloud', 'companion', 'condition', 'cousin', 'cracking', 'crash', 'dark', 'deep', 'disaster', 'downpour', 'echo', 'electric', 'electricity', 'element', 'event', 'feature', 'flash', 'follower', 'following', 'happening', 'heavy', 'light', 'lightening', 'lighting', 'lightning', 'like', 'load', 'natural', 'natural_phenomenon', 'noise', 'nose', 'nothing', 'partner', 'pattern', 'phenomenon', 'rain', 'rainstorm', 'ray', 'roar', 'rolling', 'rumble', 'situation', 'sky', 'slumber', 'spark', 'storm', 'summer', 'then', 'thor', 'thrill', 'type', 'weather', 'white', 'wind', 'zigzag']}, {'exemplar_feature': 'time', 'feature_properties': ['acceleration', 'acceptability', 'adventure', 'afternoon', 'age', 'alarm_clock', 'anachronism', 'angelus_bell', 'antecedent', 'appointment', 'apprenticeship', 'art', 'atom', 'attention_span', 'bandwidth', 'bastardization', 'batman', 'beat', 'bed', 'bedtime', 'beginning', 'bell', 'bell', 'big_bang', 'birdlime', 'birthday', 'biscuit', 'blotter', 'boarder', 'boondoggle', 'brahman', 'break', 'break_seal', 'calendar', 'camp', 'canonical_hour', 'carol', 'century', 'char', 'checkout', 'checkpoint', 'childhood', 'childhood', 'christmas', 'chronograph', 'chronology', 'chronometer', 'chronoscope', 'class', 'clock', 'clock', 'clock_watcher', 'clocking', 'closing_time', 'coincidence', 'companion', 'confinement', 'constant', 'contemporary', 'contemporary', 'convenience', 'countdown', 'crisis', 'crystal', 'cubit', 'curfew', 'curfew', 'current', 'dance', 'dark', 'date', 'date', 'date', 'dawn', 'dawn', 'day', 'debut', 'decimation', 'digit', 'dimension', 'dimension', 'dinner', 'dinnertime', 'disorientation', 'double', 'dream', 'due', 'duration', 'duty', 'election', 'employment', 'energy', 'energy', 'eon', 'epoch', 'eternity', 'eternity', 'evening', 'event', 'exposure', 'face_time', 'family_history', 'fast', 'fast', 'fast', 'fauna', 'femtosecond', 'field_day', 'first', 'fix', 'flash', 'following', 'force', 'former', 'forth', 'fourth_dimension', 'frequency', 'future', 'future', 'future_perfect', 'game', 'generation', 'glory', 'go', 'golf_widow', 'habit', 'hand', 'handicap', 'happy_hour', 'harvest', 'headspace', 'headway', 'heartbeat', 'heat', 'here', 'here_and_now', 'history', 'hobby', 'horology', 'hour', 'hour', 'humbug', 'hunt', 'idle', 'impulse', 'integrator', 'interest', 'interruption', 'interstice', 'interval', 'issue', 'jerk', 'jump_cut', 'lapse', 'latter', 'leave', 'leisure', 'life_expectancy', 'light', 'limitation', 'lord', 'lore', 'mace', 'manners', 'meal', 'meal', 'mealtime', 'mean_time', 'midnight', 'millennium', 'mine', 'minute', 'minute', 'modern', 'moment', 'moment', 'month', 'month_of_sundays', 'moonlight', 'morning', 'motion', 'music', 'nanosecond', 'niceness', 'night', 'none', 'now', 'now', 'number', 'occasion', 'occupancy', 'offer', 'offset', 'old', 'parking_meter', 'parole', 'party', 'pass', 'passage', 'past', 'past', 'perestroika', 'period', 'period', 'physics', 'pip', 'plate', 'play', 'posting', 'present', 'present_perfect', 'presentness', 'primer', 'procession', 'punishment', 'putz', 'reading', 'record', 'regression', 'reign', 'rem', 'rendezvous', 'reproducibility', 'rest', 'revel', 'rhythm', 'robbery', 'round', 'run', 'rush', 'sailing', 'sale', 'schedule', 'scheduling', 'second', 'second', 'see', 'seedtime', 'semester', 'settlement', 'sidereal_year', 'sleep', 'snap', 'snow', 'space', 'space', 'span', 'spectrogram', 'speed', 'split', 'spot_price', 'spring_break', 'st', 'stasis', 'step', 'stint', 'stitch', 'stop', 'stopwatch', 'story', 'stretch', 'string_theory', 'summer', 'sunburn', 'sunrise', 'sunset', 'supper', 'synchronization', 't', 'table', 'tachograph', 'tail', 'tango', 'tap', 'taximeter', 'term', 'terminal', 'termination', 'then', 'then', 'throw', 'thyme', 'tide', 'tidy', 'time_zone', 'timecard', 'timekeeper', 'timekeeping', 'timepiece', 'timer', 'times', 'timeserver', 'timetable', 'timework', 'timing', 'tonnage', 'transient', 'triple_time', 'turbulent_flow', 'turn', 'twilight', 'universe', 'vacation', 'vacation', 'vanishing_point', 'volta', 'waltz', 'war', 'waste', 'watch', 'watch', 'watch', 'weather', 'weather', 'wee', 'week', 'west_germany', 'while', 'wink', 'winter', 'work', 'workload', 'year', 'year', 'yore', 'zero_hour', 'zulu', 'accuracy', 'age', 'answer', 'arrow', 'being', 'calendar', 'celebration', 'change', 'chronology', 'clock', 'concept', 'constant', 'continuum', 'date', 'day', 'days', 'dimension', 'division', 'down', 'duration', 'einstein', 'era', 'eternity', 'fiction', 'fine', 'flies', 'fourth', 'fourth_dimension', 'function', 'general', 'generic', 'going', 'hands', 'history', 'hour', 'hourglass', 'hours', 'keeping', 'length', 'magazine', 'measure', 'measurement', 'metaphor', 'minute', 'minutes', 'money', 'month', 'nothing', 'now', 'numbers', 'out', 'output', 'passage', 'passing', 'past', 'period', 'physical_property', 'present', 'progression', 'prompt', 'property', 'purpose', 'quantity', 'reading', 'recording', 'relative', 'result', 'running', 'second', 'see', 'sequence', 'short', 'sixty', 'space', 'stop', 'tell', 'term', 'thirty', 'ticking', 'track', 'trait', 'unit', 'use', 'waste', 'watch', 'week']}, {'exemplar_feature': 'today', 'feature_properties': ['age', 'culture', 'current', 'date', 'future', 'modern', 'morning', 'news', 'now', 'phone', 'present', 'tomorrow', 'weather', 'yesterday', 'yesterday', 'yesterday', 'tonight', 'yesterday']}, {'exemplar_feature': 'type', 'feature_properties': ['adventure', 'agate', 'alfalfa', 'altitude', 'american', 'animal', 'antitype', 'apple', 'art', 'athlete', 'atom', 'axiology', 'band', 'bass', 'batter', 'beard', 'berry', 'bird', 'birthday', 'bite', 'blood', 'board', 'boat', 'body', 'bolt', 'bone', 'book', 'boot', 'bourgeois', 'bow', 'brand', 'bulldog', 'cafe', 'cake', 'canary', 'canoe', 'canon', 'card', 'carp', 'case', 'case', 'cast', 'castor', 'cathedral', 'cedar', 'cell', 'cent', 'channel', 'character', 'charm', 'chat_room', 'chick', 'chicken', 'chinchilla', 'chord', 'cicero', 'clam', 'coat', 'coin', 'color', 'column', 'combining_form', 'combustion', 'compositor', 'corn', 'corporation', 'cotton', 'council', 'country', 'course', 'crowd', 'crown', 'crucifix', 'dance', 'dell', 'democracy', 'dentition', 'department', 'desert', 'devotion', 'diamond', 'diamond', 'distribution', 'distributor', 'division', 'dollar', 'door', 'dress', 'drip', 'drizzle', 'drop', 'duck', 'duty', 'ear', 'edge', 'eidos', 'electricity', 'elm', 'emerald', 'emphasis', 'en', 'energy', 'english', 'excelsior', 'eye_chart', 'fair', 'fairy', 'farm', 'feline', 'fetish', 'fine_print', 'fir', 'firm', 'fit', 'flea', 'floor', 'flower', 'font', 'foot', 'form', 'form', 'franc', 'freight', 'galley', 'game', 'gem', 'german', 'gold', 'gospel', 'grain', 'grizzly', 'ground', 'haddock', 'hair_space', 'hand', 'hermit', 'herring', 'horror', 'hound', 'hour', 'house', 'inch', 'ink', 'iron', 'island', 'ivy', 'jargon', 'jet', 'jolt', 'kennel', 'keyboard', 'kidney', 'kind', 'kind', 'king', 'knitting', 'lady', 'lamb', 'lamp', 'landscape', 'lantern', 'lap', 'lead', 'like', 'lily', 'link', 'loafer', 'lyric', 'macaroni', 'macule', 'mahogany', 'main', 'manner', 'maple', 'mara', 'march', 'market', 'mash', 'merchant', 'meridian', 'might', 'mile', 'minion', 'mist', 'mister', 'model', 'money', 'motion', 'motor', 'mountain', 'nation', 'nerve', 'news', 'nick', 'nonpareil', 'novel', 'oak', 'occupation', 'office', 'oil', 'opal', 'organization', 'orphan', 'page', 'palm', 'paragon', 'particular', 'partner', 'pasta', 'pastor', 'pearl', 'peck', 'pet', 'phenomenon', 'pica', 'pie', 'pin', 'piston', 'place', 'plate', 'point', 'poison', 'polish', 'pony', 'porch', 'preserve', 'print', 'printing', 'property', 'quad', 'quail', 'question', 'quoin', 'race', 'rain', 'rank', 'rap', 'reading', 'red', 'reply', 'representative', 'republic', 'rest', 'revealed_religion', 'revolution', 'reward', 'rhapsody', 'rheumatism', 'rifle', 'rise', 'river', 'robbery', 'robin', 'rock', 'role', 'roll', 'round', 'rub', 'ruby', 'rule', 'rule', 'rum', 'rye', 'sail', 'sandwich', 'saxon', 'scooter', 'script', 'semicircle', 'servant', 'set', 'shade', 'shank', 'shepherd', 'shoulder', 'show', 'silk', 'sleet', 'slip', 'slur', 'smell', 'soap', 'son', 'song', 'sort', 'space', 'speaker', 'species', 'spike', 'squirrel', 'stab', 'statue', 'steam', 'steamer', 'steel', 'steel', 'stereotype', 'stitch', 'stop', 'street', 'suede', 'superscript', 'surprise', 'tap', 'taste', 'test', 'theme', 'thong', 'thunder', 'tin', 'touch', 'trout', 'tweed', 'twist', 'typewriter', 'typification', 'typing', 'typist', 'typography', 'typology', 'uniform', 'unit', 'van', 'veal', 'verb', 'verse', 'walnut', 'waltz', 'weather', 'widow', 'willow', 'wing', 'wood', 'wool', 'wound', 'wren', 'writing', 'yucca', 'action', 'activity', 'computer', 'form', 'impress', 'keyboard', 'now', 'print', 'stamp', 'typewriter']}, {'exemplar_feature': 'wind', 'feature_properties': ['aeolian', 'aeolian_harp', 'aeolic', 'aeolus', 'agglomerate', 'air', 'air', 'anemography', 'anemometer', 'anemometry', 'anticyclone', 'back', 'backstay', 'beat', 'beaufort_scale', 'blanket', 'blow', 'blow', 'bluster', 'boat', 'boreas', 'bottom', 'breath', 'breath', 'breeze', 'breeze', 'bunting', 'buster', 'capful', 'chop', 'clarinet', 'coil', 'corkscrew', 'crosswind', 'current', 'cyclone', 'direction', 'drift_ice', 'east', 'east', 'energy', 'enlil', 'exposure', 'fan', 'fart', 'feather', 'fire', 'firestorm', 'flag', 'flatulence', 'flurry', 'gale', 'ground_swell', 'gust', 'hasp', 'headwind', 'horn', 'hurricane', 'hurricane', 'isogon', 'katabatic_wind', 'khamsin', 'krummhorn', 'lap', 'lees', 'light_air', 'luff', 'lull', 'lute', 'meander', 'meteor', 'monsoon', 'oboe', 'pinwheel', 'pollination', 'reed', 'reel', 'reeler', 'rig', 'ripple_mark', 'room', 'sail', 'sailing', 'sailing_vessel', 'scarlet', 'scud', 'scud', 'serpent', 'skein', 'snake', 'sneeze', 'snowdrift', 'south_wind', 'southeaster', 'southwester', 'spindrift', 'spinning_frame', 'steam', 'storm', 'storm', 'swell', 'swift', 'tempest', 'thunder', 'thunderstorm', 'tongue', 'tornado', 'touch', 'trade', 'trade_wind', 'turban', 'twist', 'twist', 'typhoon', 'typhoon', 'vane', 'variable', 'vayu', 'wave', 'wear', 'weather', 'weather', 'weave', 'west', 'wind_instrument', 'windage', 'windburn', 'winder', 'winder', 'windmill', 'window', 'window', 'windshield', 'windsock', 'windstorm', 'wine', 'wound', 'zephyr', 'air', 'atmospheric_phenomenon', 'atmospheric_pressure', 'blow', 'breath', 'breathing', 'breeze', 'characteristic', 'chicago', 'clear', 'cold', 'condition', 'currant', 'current', 'earth', 'element', 'en', 'energy', 'fast', 'feature', 'flatulence', 'force', 'gale', 'gas', 'gust', 'heavy', 'hurricane', 'kite', 'light', 'light_breeze', 'like', 'mistral', 'motion', 'move', 'movement', 'natural', 'nature', 'nothing', 'outside', 'patter', 'phenomenon', 'power', 'pressure', 'propulsion', 'running', 'rustling', 'sailboat', 'speed', 'storm', 'strong_breeze', 'tornado', 'weather', 'zephyr']}, {'exemplar_feature': 'winter', 'feature_properties': ['antlia', 'auriga', 'baldwin', 'bear', 'boot', 'canis_major', 'canis_minor', 'cetus', 'christmas', 'circinus', 'coat', 'cold', 'columba', 'comforter', 'crux', 'eridanus', 'fall', 'flannel', 'fornax', 'freeze', 'frost', 'hydrus', 'icicle', 'jack_frost', 'jacket', 'lepus', 'madonna_lily', 'midwinter', 'perennation', 'produce', 'puppis', 'roe_deer', 'season', 'season', 'sedge_warbler', 'ski', 'slush', 'snow', 'soup', 'southern_cross', 'spring', 'spring', 'sprinter', 'stocker', 'summer', 'telescopium', 'triangulum_australe', 'uta', 'weather', 'white_stork', 'winesap', 'wool', 'yard', 'christmas', 'cold', 'cold_weather', 'coldness', 'december', 'fall', 'ice', 'north', 'outside', 'season', 'snow', 'sow', 'spring', 'station', 'summer', 'time', 'weather', 'white', 'wonderland']}]\n"
     ]
    }
   ],
   "source": [
    "# Collects all the features of each ex_feature\n",
    "ex_features_collection = []\n",
    "\n",
    "all_exemplar_features = exemplarfeatures['destination_features'] + exemplarfeatures['source_features']\n",
    "\n",
    "#Loop through each feature of the emotion\n",
    "for ex_feature in all_exemplar_features:\n",
    "    \n",
    "    # Dict for ex_feature\n",
    "    ex_features = dict(exemplar_feature = ex_feature, feature_properties = [])\n",
    "    \n",
    "    \n",
    "    # Retrieve features of said em_feature\n",
    "    query = '/c/en/' + ex_feature\n",
    "\n",
    "    # Pre-Processing below does Stemming for ConceptNet. Basically if the word doesn't exist, remove a character.\n",
    "    cursor = nodes.find({\"_id\": query})\n",
    "    \n",
    "    \n",
    "    # Checks if cursor is not empty\n",
    "    if(len(cursor[0]) > 0):\n",
    "\n",
    "            # Destination Node 'isd'\n",
    "            # Checks if Destination Node exists\n",
    "            if('isd' in cursor[0]):\n",
    "                ex_feature_isd = cursor[0]['isd']\n",
    "                # Checks if '/r/RelatedTo' exists in the node\n",
    "\n",
    "                if ('/r/RelatedTo' in ex_feature_isd.keys() and ex_feature_isd is not None):\n",
    "                    hasPropertyIsd = ex_feature_isd.get('/r/RelatedTo')\n",
    "\n",
    "                    # Checks if Destination Node is empty\n",
    "                    if(hasPropertyIsd is not None):\n",
    "\n",
    "                        for featureIsd in hasPropertyIsd:\n",
    "\n",
    "                            if(filterStr in featureIsd):\n",
    "                                \n",
    "                                retrieved_feature = featureIsd.split('/')\n",
    "                                if(retrieved_feature[3] in nouns):\n",
    "                                    ex_features['feature_properties'].append(retrieved_feature[3])\n",
    "                            \n",
    "                \n",
    "            # Checks if Source Node exists.\n",
    "            if('iss' in cursor[0]):\n",
    "                ex_feature_iss = cursor[0]['iss']\n",
    "                \n",
    "                if('/r/RelatedTo' in ex_feature_iss.keys() and ex_feature_iss is not None):\n",
    "                    hasPropertyIss = ex_feature_iss.get('/r/RelatedTo')\n",
    "\n",
    "                    # Checks if Source Node is empty\n",
    "                    if(hasPropertyIss is not None):\n",
    "\n",
    "                        for featureIss in hasPropertyIss:\n",
    "\n",
    "                            if(filterStr in featureIss):\n",
    "                                \n",
    "                                retrieved_feature = featureIss.split('/')\n",
    "                                if(retrieved_feature[3] in nouns):\n",
    "                                    ex_features['feature_properties'].append(retrieved_feature[3])\n",
    "                \n",
    "                \n",
    "            ex_features_collection.append(ex_features)\n",
    "\n",
    "\n",
    "print(len(ex_features_collection))\n",
    "print(ex_features_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc248b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baking\n",
      "break\n",
      "brunt\n",
      "camber\n",
      "carol\n",
      "clear\n",
      "clemency\n",
      "climate\n",
      "cloud\n",
      "coat\n",
      "cold\n",
      "cold_frame\n",
      "cold_wave\n",
      "convection\n",
      "cyclone\n",
      "elements\n",
      "exposure\n",
      "fair\n",
      "fair_weather\n",
      "fine\n",
      "flash\n",
      "fog\n",
      "foglamp\n",
      "freeze\n",
      "frontal\n",
      "frost\n",
      "growing_season\n",
      "grus\n",
      "hail\n",
      "heat\n",
      "heat_wave\n",
      "heaven\n",
      "hot_spell\n",
      "hovel\n",
      "hurricane\n",
      "indra\n",
      "isogon\n",
      "jacket\n",
      "luff\n",
      "meteorology\n",
      "mist\n",
      "news\n",
      "nip\n",
      "rain\n",
      "saprolite\n",
      "serve\n",
      "slip\n",
      "snow\n",
      "storm\n",
      "storm\n",
      "summer\n",
      "temperature\n",
      "thaw\n",
      "thermometer\n",
      "thunder\n",
      "tornado\n",
      "typhoon\n",
      "typhoon\n",
      "umbrella\n",
      "vane\n",
      "washboard\n",
      "weather_forecast\n",
      "weatherglass\n",
      "wetness\n",
      "whiteout\n",
      "wind\n",
      "windshield\n",
      "winter\n",
      "action\n",
      "activity\n",
      "air\n",
      "atmosphere\n",
      "atmospheric_phenomenon\n",
      "bad\n",
      "boring\n",
      "change\n",
      "channel\n",
      "circumstances\n",
      "climate\n",
      "cloud\n",
      "cold\n",
      "cold_front\n",
      "collective\n",
      "condition\n",
      "conditions\n",
      "current\n",
      "daily\n",
      "day\n",
      "description\n",
      "effects\n",
      "elements\n",
      "environment\n",
      "fog\n",
      "forecaster\n",
      "four\n",
      "front\n",
      "general\n",
      "hail\n",
      "happening\n",
      "humidity\n",
      "hurricane\n",
      "lightning\n",
      "like\n",
      "local\n",
      "meteorology\n",
      "name\n",
      "natural\n",
      "natural_phenomenon\n",
      "news\n",
      "nice\n",
      "now\n",
      "outdoors\n",
      "outside\n",
      "overall\n",
      "overcast\n",
      "pattern\n",
      "phenomenon\n",
      "precipitation\n",
      "prediction\n",
      "program\n",
      "rain\n",
      "report\n",
      "season\n",
      "segment\n",
      "sky\n",
      "sleet\n",
      "snow\n",
      "spring\n",
      "state\n",
      "storm\n",
      "study\n",
      "summer\n",
      "sun\n",
      "sunlight\n",
      "system\n",
      "temperature\n",
      "term\n",
      "thunder\n",
      "time\n",
      "today\n",
      "type\n",
      "wind\n",
      "winter\n"
     ]
    }
   ],
   "source": [
    "for i in ex_features_collection:\n",
    "    print(i['exemplar_feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b43ade",
   "metadata": {},
   "source": [
    "# Fuzzy Match w/ Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2941893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe(matrix, tokens):\n",
    "\n",
    "    doc_names = ['em_features', 'ex_features']\n",
    "    df = pd.DataFrame(data=matrix, index=doc_names, columns=tokens)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0da78a",
   "metadata": {},
   "source": [
    "# Cosine Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db90804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tfid_vectorize_cosine(featurelist1, featurelist2):\n",
    "    \n",
    "    Tfidf_vect = TfidfVectorizer()\n",
    "    \n",
    "    # Stringify List to String to vectorize\n",
    "    emotion_features_str = ' '.join(featurelist1)\n",
    "    exemplar_features_str = ' '.join(featurelist2)\n",
    "    \n",
    "    # Convert to list to vectorize\n",
    "    data = [emotion_features_str, exemplar_features_str]\n",
    "    \n",
    "    vector_matrix = Tfidf_vect.fit_transform(data)\n",
    "    \n",
    "     # Convert Vector Matrix to arrayc\n",
    "    vector_matrix.toarray()\n",
    "\n",
    "\n",
    "    # Generate Cosine Similarity score\n",
    "    cosine_similarity_matrix = cosine_similarity(vector_matrix)\n",
    "    \n",
    "    \n",
    "    return cosine_similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e58c2",
   "metadata": {},
   "source": [
    "# Retrieve Cosine Similarity Score of all Associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c60a53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue\n",
      "blues\n",
      "cry\n",
      "depression\n",
      "depressive_disorder\n",
      "despair\n",
      "disappointment\n",
      "dolefulness\n",
      "downheartedness\n",
      "dump\n",
      "forlornness\n",
      "frown\n",
      "frown\n",
      "gloom\n",
      "grief\n",
      "heaviness\n",
      "lament\n",
      "melancholic\n",
      "melancholy\n",
      "melancholy\n",
      "melancholy\n",
      "misery\n",
      "moroseness\n",
      "sigh\n",
      "sob\n",
      "sorrow\n",
      "unhappiness\n",
      "woe\n",
      "woe\n"
     ]
    }
   ],
   "source": [
    "# List of all the scores\n",
    "scoreList = []\n",
    "\n",
    "\n",
    "\n",
    "# Collect the Cosine Similarity Scores of each Association\n",
    "for em_feature in em_features_collection:\n",
    "    print(em_feature['emotion_feature'])\n",
    "    \n",
    "    for ex_feature in ex_features_collection:\n",
    "        \n",
    "        # Pass Feature Properties to compare in Cosine Similarity\n",
    "        \n",
    "        # Checks if Feature Properties are not empty. If empty no association can be made..\n",
    "        if(ex_feature['feature_properties'] and em_feature['feature_properties']):\n",
    "            cos_similarity = tfid_vectorize_cosine(em_feature['feature_properties'], ex_feature['feature_properties'])\n",
    "        \n",
    "            # Append to scorelist\n",
    "            scoreList.append(dict(emotion_feature = em_feature['emotion_feature'], exemplar_feature = ex_feature['exemplar_feature'], emotional_properties = em_feature['feature_properties'], exemplar_properties =  ex_feature['feature_properties'], score = cos_similarity))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b844ed12",
   "metadata": {},
   "source": [
    "# HeapSort to find most similar Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e47f3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Python program for implementation of heap Sort\n",
    " \n",
    "# To heapify subtree rooted at index i.\n",
    "# n is size of heap\n",
    " \n",
    " \n",
    "def heapifyCosine(arr, n, i):\n",
    "    largest = i  # Initialize largest as root\n",
    "    l = 2 * i + 1     # left = 2*i + 1\n",
    "    r = 2 * i + 2     # right = 2*i + 2\n",
    " \n",
    "    # See if left child of root exists and is\n",
    "    # greater than root\n",
    "    if l < n and arr[largest]['score'][0][1] < arr[l]['score'][0][1]:\n",
    "        largest = l\n",
    " \n",
    "    # See if right child of root exists and is\n",
    "    # greater than root\n",
    "    if r < n and arr[largest]['score'][0][1] < arr[r]['score'][0][1]:\n",
    "        largest = r\n",
    " \n",
    "    # Change root, if needed\n",
    "    if largest != i:\n",
    "        arr[i], arr[largest] = arr[largest], arr[i]  # swap\n",
    " \n",
    "        # Heapify the root.\n",
    "        heapifyCosine(arr, n, largest)\n",
    " \n",
    "# The main function to sort an array of given size\n",
    " \n",
    " \n",
    "def heapSortCosine(arr):\n",
    "    n = len(arr)\n",
    " \n",
    "    # Build a maxheap.\n",
    "    for i in range(n//2 - 1, -1, -1):\n",
    "        heapifyCosine(arr, n, i)\n",
    " \n",
    "    # One by one extract elements\n",
    "    for i in range(n-1, 0, -1):\n",
    "        arr[i], arr[0] = arr[0], arr[i]  # swap\n",
    "        heapifyCosine(arr, i, 0)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e072a",
   "metadata": {},
   "source": [
    "# Retrieve Largest Scoring Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58f6d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call HeapSort for O(nlogn) time Complexity\n",
    "heapSortCosine(scoreList)\n",
    "\n",
    "# List to collect all combinations\n",
    "combinations = []\n",
    "\n",
    "# Index to determine whether CriterionQ has been met\n",
    "criterIndex = 0\n",
    "\n",
    "# Retrieve the Top Criterion Q Highest Scoring Combinations \n",
    "for combination in reversed(scoreList):\n",
    "    if(criterIndex == criterionQ):\n",
    "        break\n",
    "    \n",
    "    if(combination['score'][0][1] < 1):\n",
    "        criterIndex = criterIndex + 1\n",
    "        combinations.append(combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72ceb70",
   "metadata": {},
   "source": [
    "# Print out all Combinations according to Criterion (Cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "768f25fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadness and weather\n",
      "\n",
      "\n",
      "sob is wetness \n",
      "score: 0.08768681980142447\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'cry'}\n",
      "\n",
      "\n",
      "unhappiness is wetness \n",
      "score: 0.05629715757507138\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'cry'}\n",
      "\n",
      "\n",
      "blue is sky \n",
      "score: 0.05216196668370564\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'azure', 'earth', 'cloud', 'rainbow', 'day', 'sea', 'dark', 'ozone', 'clear', 'color', 'water'}\n",
      "\n",
      "\n",
      "blue is mist \n",
      "score: 0.05212931506020751\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'light', 'ocean', 'cloud', 'night', 'smoke', 'cool', 'sea', 'white', 'like', 'water'}\n",
      "\n",
      "\n",
      "sigh is wind \n",
      "score: 0.050768414599248295\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'breathing', 'breath', 'air'}\n",
      "\n",
      "\n",
      "sigh is wind \n",
      "score: 0.050768414599248295\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'breathing', 'breath', 'air'}\n",
      "\n",
      "\n",
      "unhappiness is bad \n",
      "score: 0.04969320245516195\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'misery', 'depression'}\n",
      "\n",
      "\n",
      "blue is like \n",
      "score: 0.04862157578869077\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'shade', 'blow', 'velvet', 'sea', 'boy', 'color', 'green', 'smoke', 'emotion', 'ocean', 'raspberry', 'clear', 'river', 'eye', 'earth', 'violet', 'feeling', 'lake', 'royal', 'steel_blue', 'cool'}\n",
      "\n",
      "\n",
      "heaviness is collective \n",
      "score: 0.04722035612860628\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'mass'}\n",
      "\n",
      "\n",
      "sob is happening \n",
      "score: 0.04602459262732953\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'cry'}\n",
      "\n",
      "\n",
      "despair is wetness \n",
      "score: 0.04467742044818329\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'cry'}\n",
      "\n",
      "\n",
      "lament is wetness \n",
      "score: 0.04467742044818329\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'cry'}\n",
      "\n",
      "\n",
      "blue is clear \n",
      "score: 0.04438548256627281\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'windows', 'river', 'day', 'sky', 'like', 'color', 'water'}\n",
      "\n",
      "\n",
      "dump is overall \n",
      "score: 0.04407959946749869\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'slop'}\n",
      "\n",
      "\n",
      "blue is cloud \n",
      "score: 0.04407654658814986\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'shade', 'smoke', 'sky', 'white', 'altostratus', 'dark', 'color', 'water'}\n",
      "\n",
      "\n",
      "blue is cloud \n",
      "score: 0.04407654658814986\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'shade', 'smoke', 'sky', 'white', 'altostratus', 'dark', 'color', 'water'}\n",
      "\n",
      "\n",
      "blue is sunlight \n",
      "score: 0.04313404788408361\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'shade', 'day', 'yellow'}\n",
      "\n",
      "\n",
      "forlornness is activity \n",
      "score: 0.04294413089916346\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'loneliness'}\n",
      "\n",
      "\n",
      "melancholic is sky \n",
      "score: 0.04244592768873775\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'blue'}\n",
      "\n",
      "\n",
      "cry is rain \n",
      "score: 0.042286922156808966\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'wetness', 'crying', 'liquid', 'making', 'moisture', 'sky', 'pain', 'produce', 'like', 'water'}\n",
      "\n",
      "\n",
      "cry is rain \n",
      "score: 0.042286922156808966\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'wetness', 'crying', 'liquid', 'making', 'moisture', 'sky', 'pain', 'produce', 'like', 'water'}\n",
      "\n",
      "\n",
      "blue is fog \n",
      "score: 0.042152731632214294\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'water', 'smoke', 'ocean', 'cloud'}\n",
      "\n",
      "\n",
      "blue is fog \n",
      "score: 0.042152731632214294\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'water', 'smoke', 'ocean', 'cloud'}\n",
      "\n",
      "\n",
      "sob is rain \n",
      "score: 0.04209215908094723\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'like', 'cry', 'crying'}\n",
      "\n",
      "\n",
      "sob is rain \n",
      "score: 0.04209215908094723\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'like', 'cry', 'crying'}\n",
      "\n",
      "\n",
      "blue is sun \n",
      "score: 0.04170303147948685\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'light', 'cloud', 'earth', 'shade', 'day', 'yellow', 'sky', 'dark'}\n",
      "\n",
      "\n",
      "blue is heaven \n",
      "score: 0.041481961070938426\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'sky', 'white', 'earth', 'cloud'}\n",
      "\n",
      "\n",
      "sob is sky \n",
      "score: 0.04110686856911747\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'cry'}\n",
      "\n",
      "\n",
      "blues is sky \n",
      "score: 0.04007645663129125\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'blue', 'color'}\n",
      "\n",
      "\n",
      "cry is thunder \n",
      "score: 0.0398126701311029\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'activity', 'rain', 'sky', 'happening', 'like', 'noise', 'roar'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(predicted_emotion['label'], 'and', exemplar)\n",
    "print('\\n')\n",
    "\n",
    "for metaphor in combinations:\n",
    "    print(metaphor['emotion_feature'], 'is', metaphor['exemplar_feature'], '\\nscore:', metaphor['score'][0][1])\n",
    "    print( '\\n Matching Properties between Exemplar & Emotion:', set(metaphor['exemplar_properties']) & set(metaphor['emotional_properties']) )\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a6da7",
   "metadata": {},
   "source": [
    "# Fuzzy Match w/ Jaccard Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda6ec4b",
   "metadata": {},
   "source": [
    "# Jaccard Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f39c6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(doc1, doc2): \n",
    "    \n",
    "    # List the unique words in a document\n",
    "    words_doc1 = set(doc1) \n",
    "    words_doc2 = set(doc2)\n",
    "    \n",
    "    # Find the intersection of words list of doc1 & doc2\n",
    "    intersection = words_doc1.intersection(words_doc2)\n",
    "\n",
    "    # Find the union of words list of doc1 & doc2\n",
    "    union = words_doc1.union(words_doc2)\n",
    "        \n",
    "    # Calculate Jaccard similarity score \n",
    "    # using length of intersection set divided by length of union set\n",
    "    return float(len(intersection)) / len(union)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793fb053",
   "metadata": {},
   "source": [
    "# Heapsort edited w/ Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf8c2534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program for implementation of heap Sort\n",
    " \n",
    "# To heapify subtree rooted at index i.\n",
    "# n is size of heap\n",
    " \n",
    " \n",
    "def heapifyJaccard(arr, n, i):\n",
    "    largest = i  # Initialize largest as root\n",
    "    l = 2 * i + 1     # left = 2*i + 1\n",
    "    r = 2 * i + 2     # right = 2*i + 2\n",
    " \n",
    "    # See if left child of root exists and is\n",
    "    # greater than root\n",
    "    if l < n and arr[largest]['score'] < arr[l]['score']:\n",
    "        largest = l\n",
    " \n",
    "    # See if right child of root exists and is\n",
    "    # greater than root\n",
    "    if r < n and arr[largest]['score'] < arr[r]['score']:\n",
    "        largest = r\n",
    " \n",
    "    # Change root, if needed\n",
    "    if largest != i:\n",
    "        arr[i], arr[largest] = arr[largest], arr[i]  # swap\n",
    " \n",
    "        # Heapify the root.\n",
    "        heapifyJaccard(arr, n, largest)\n",
    " \n",
    "# The main function to sort an array of given size\n",
    " \n",
    " \n",
    "def heapSortJaccard(arr):\n",
    "    n = len(arr)\n",
    " \n",
    "    # Build a maxheap.\n",
    "    for i in range(n//2 - 1, -1, -1):\n",
    "        heapifyJaccard(arr, n, i)\n",
    " \n",
    "    # One by one extract elements\n",
    "    for i in range(n-1, 0, -1):\n",
    "        arr[i], arr[0] = arr[0], arr[i]  # swap\n",
    "        heapifyJaccard(arr, i, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3258a94",
   "metadata": {},
   "source": [
    "# Retrieve Jaccard Score for each Association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ab3983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue\n",
      "blues\n",
      "cry\n",
      "depression\n",
      "depressive_disorder\n",
      "despair\n",
      "disappointment\n",
      "dolefulness\n",
      "downheartedness\n",
      "dump\n",
      "forlornness\n",
      "frown\n",
      "frown\n",
      "gloom\n",
      "grief\n",
      "heaviness\n",
      "lament\n",
      "melancholic\n",
      "melancholy\n",
      "melancholy\n",
      "melancholy\n",
      "misery\n",
      "moroseness\n",
      "sigh\n",
      "sob\n",
      "sorrow\n",
      "unhappiness\n",
      "woe\n",
      "woe\n"
     ]
    }
   ],
   "source": [
    "# List of all the scores\n",
    "scoreListJaccard = []\n",
    "\n",
    "\n",
    "\n",
    "# Collect the Cosine Similarity Scores of each Association\n",
    "for em_feature in em_features_collection:\n",
    "    print(em_feature['emotion_feature'])\n",
    "    \n",
    "    for ex_feature in ex_features_collection:\n",
    "        \n",
    "        # Pass Feature Properties to compare in Cosine Similarity\n",
    "        \n",
    "        # Checks if Feature Properties are not empty. If empty no association can be made..\n",
    "        if(ex_feature['feature_properties'] and em_feature['feature_properties']):\n",
    "            jacc_similarity = jaccard_similarity(em_feature['feature_properties'], ex_feature['feature_properties'])\n",
    "        \n",
    "            # Append to scorelist\n",
    "            scoreListJaccard.append(dict(emotion_feature = em_feature['emotion_feature'], exemplar_feature = ex_feature['exemplar_feature'], emotional_properties = em_feature['feature_properties'], exemplar_properties =  ex_feature['feature_properties'], score = jacc_similarity))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146caa15",
   "metadata": {},
   "source": [
    "# Retrieve Largest Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5544166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call HeapSort for O(nlogn) time Complexity\n",
    "heapSortJaccard(scoreListJaccard)\n",
    "\n",
    "# List to collect all combinations\n",
    "combinationsJaccard = []\n",
    "\n",
    "# Index to determine whether CriterionQ has been met\n",
    "criterIndex = 0\n",
    "\n",
    "# Retrieve the Top Criterion Q Highest Scoring Combinations \n",
    "for combination in reversed(scoreListJaccard):\n",
    "    if(criterIndex == criterionQ):\n",
    "        break\n",
    "    \n",
    "    if(combination['score'] < 1.0):\n",
    "        criterIndex = criterIndex + 1\n",
    "        combinationsJaccard.append(combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c4378f",
   "metadata": {},
   "source": [
    "# Print out all combinations according to criterion (Jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af7378da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sadness and weather\n",
      "\n",
      "\n",
      "unhappiness is wetness \n",
      "score: 0.06666666666666667\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'cry'}\n",
      "\n",
      "\n",
      "dump is overall \n",
      "score: 0.05555555555555555\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'slop'}\n",
      "\n",
      "\n",
      "blue is mist \n",
      "score: 0.055248618784530384\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'light', 'ocean', 'cloud', 'night', 'smoke', 'cool', 'sea', 'white', 'like', 'water'}\n",
      "\n",
      "\n",
      "blue is sky \n",
      "score: 0.05314009661835749\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'azure', 'earth', 'cloud', 'rainbow', 'day', 'sea', 'dark', 'ozone', 'clear', 'color', 'water'}\n",
      "\n",
      "\n",
      "cry is rain \n",
      "score: 0.05128205128205128\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'wetness', 'crying', 'liquid', 'making', 'moisture', 'sky', 'pain', 'produce', 'like', 'water'}\n",
      "\n",
      "\n",
      "cry is rain \n",
      "score: 0.05128205128205128\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'wetness', 'crying', 'liquid', 'making', 'moisture', 'sky', 'pain', 'produce', 'like', 'water'}\n",
      "\n",
      "\n",
      "despair is wetness \n",
      "score: 0.05\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'cry'}\n",
      "\n",
      "\n",
      "sob is wetness \n",
      "score: 0.045454545454545456\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'cry'}\n",
      "\n",
      "\n",
      "cry is mist \n",
      "score: 0.044444444444444446\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'wetness', 'liquid', 'rain', 'moisture', 'watering', 'do', 'like', 'water'}\n",
      "\n",
      "\n",
      "lament is wetness \n",
      "score: 0.043478260869565216\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'cry'}\n",
      "\n",
      "\n",
      "sob is storm \n",
      "score: 0.041666666666666664\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'action', 'heavy'}\n",
      "\n",
      "\n",
      "sob is storm \n",
      "score: 0.041666666666666664\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'action', 'heavy'}\n",
      "\n",
      "\n",
      "sob is storm \n",
      "score: 0.041666666666666664\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'action', 'heavy'}\n",
      "\n",
      "\n",
      "cry is thunder \n",
      "score: 0.03867403314917127\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'activity', 'rain', 'sky', 'happening', 'like', 'noise', 'roar'}\n",
      "\n",
      "\n",
      "cry is thunder \n",
      "score: 0.03867403314917127\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'activity', 'rain', 'sky', 'happening', 'like', 'noise', 'roar'}\n",
      "\n",
      "\n",
      "cry is hurricane \n",
      "score: 0.038461538461538464\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'eye', 'rain', 'gale', 'depression', 'water'}\n",
      "\n",
      "\n",
      "disappointment is freeze \n",
      "score: 0.038461538461538464\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'frost'}\n",
      "\n",
      "\n",
      "cry is hurricane \n",
      "score: 0.038461538461538464\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'eye', 'rain', 'gale', 'depression', 'water'}\n",
      "\n",
      "\n",
      "cry is clear \n",
      "score: 0.03825136612021858\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'action', 'rain', 'making', 'sky', 'see', 'like', 'water'}\n",
      "\n",
      "\n",
      "blue is clear \n",
      "score: 0.03763440860215054\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'windows', 'river', 'day', 'sky', 'like', 'color', 'water'}\n",
      "\n",
      "\n",
      "unhappiness is hurricane \n",
      "score: 0.03571428571428571\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'depression'}\n",
      "\n",
      "\n",
      "unhappiness is tornado \n",
      "score: 0.03571428571428571\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'depression'}\n",
      "\n",
      "\n",
      "unhappiness is hurricane \n",
      "score: 0.03571428571428571\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'depression'}\n",
      "\n",
      "\n",
      "blue is like \n",
      "score: 0.03494176372712146\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'shade', 'blow', 'velvet', 'sea', 'boy', 'color', 'green', 'smoke', 'emotion', 'ocean', 'raspberry', 'clear', 'river', 'eye', 'earth', 'violet', 'feeling', 'lake', 'royal', 'steel_blue', 'cool'}\n",
      "\n",
      "\n",
      "sob is thunder \n",
      "score: 0.03488372093023256\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'deep', 'heavy', 'like'}\n",
      "\n",
      "\n",
      "sob is thunder \n",
      "score: 0.03488372093023256\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'deep', 'heavy', 'like'}\n",
      "\n",
      "\n",
      "misery is umbrella \n",
      "score: 0.034482758620689655\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'bad'}\n",
      "\n",
      "\n",
      "depression is fog \n",
      "score: 0.03418803418803419\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'low', 'bad', 'damp', 'condition'}\n",
      "\n",
      "\n",
      "depression is fog \n",
      "score: 0.03418803418803419\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'low', 'bad', 'damp', 'condition'}\n",
      "\n",
      "\n",
      "blue is cloud \n",
      "score: 0.03389830508474576\n",
      "\n",
      " Matching Properties between Exemplar & Emotion: {'shade', 'smoke', 'sky', 'white', 'altostratus', 'dark', 'color', 'water'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(predicted_emotion['label'], 'and', exemplar)\n",
    "print('\\n')\n",
    "\n",
    "for metaphor in combinationsJaccard:\n",
    "    print(metaphor['emotion_feature'], 'is', metaphor['exemplar_feature'], '\\nscore:', metaphor['score'])\n",
    "    print( '\\n Matching Properties between Exemplar & Emotion:', set(metaphor['exemplar_properties']) & set(metaphor['emotional_properties']) )\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceed5cc",
   "metadata": {},
   "source": [
    "# Additional Theory to choose\n",
    "\n",
    "Comparison between two approaches\n",
    "\n",
    "Take Average of all combinations\n",
    "\n",
    "Make additional theory explicit.\n",
    "\n",
    "Weighted Features\n",
    "\n",
    "Theory to explain Intersection\n",
    "\n",
    "Compare Knowledge Base with ConceptNet\n",
    "\n",
    "Association is weird.\n",
    "\n",
    "Crossover between Literals & Figurative features. Quality of all those features.\n",
    "\n",
    "Allow user to adjust settings of the system, select what is literal (downright description) & figurative (anything symbolic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1bf78a",
   "metadata": {},
   "source": [
    "# Calculate Fuzzy Intersection, \n",
    "\n",
    "# Then look into relationships of LL FF LF FL\n",
    "\n",
    "# No pre-defining criteria, give User choice to choose.\n",
    "\n",
    "\n",
    "# Select based on Rank-Order (most LF, FL)\n",
    "\n",
    "# Take Chained Associations as a single line.\n",
    "\n",
    "# Spearman Rank Order Test\n",
    "\n",
    "# From Prof Johan to Everyone 02:20 PM\n",
    "https://statistics.laerd.com/spss-tutorials/spearmans-rank-order-correlation-using-spss-statistics.php#:~:text=The%20Spearman%20rank%2Dorder%20correlation,letter%20%CF%81%2C%20pronounced%20rho).\n",
    "\n",
    "# Rank Metaphors from best to worst.\n",
    "\n",
    "# Selection Criteria User-Input (Threshold for )\n",
    "\n",
    "# Extension of ConceptNet to show how it actually works. \n",
    "# ConceptNet is the variable that should be improved. Impaired Conceptnet to show what it does.\n",
    "# Robotic Metaphor Production is the Theory - what we are implementing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930735e6",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "# Define Gambling Threshold (25%) (4 categories, 0.25 have it right can be gambling)\n",
    "\n",
    "# Add 1 point when more than 25% of people get the correct classificaiton of sentence. (every 7.5% added to 25%, 1 point)\n",
    "\n",
    "# Score ranging from 1 to 10\n",
    "\n",
    "# https://www.statisticssolutions.com/free-resources/directory-of-statistical-analyses/sign-test/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4e2f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
